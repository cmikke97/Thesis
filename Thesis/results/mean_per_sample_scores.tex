\newcommand{\meanPerSampleScores}{
    \begin{table}[H]
        \centering
        \begin{tabular}{|p{3,2cm}||p{1,8cm} p{1,8cm} p{1,8cm} p{1,8cm} p{1,8cm}|}
            \hline
            Mean per-sample & \multicolumn{5}{c|}{\textbf{FPR}} \\
            tagging scores & $10^{-5}$ & $10^{-4}$ & $10^{-3}$ & $10^{-2}$ & $10^{-1}$ \\
            \hline
            \multicolumn{6}{|c|}{\textbf{Jaccard Similarity}} \\
            \hline
            ALOHA & \textBF{0.718$\pm$0.000} & \textBF{0.718$\pm$0.000} & 0.715$\pm$0.001 & \textBF{0.686$\pm$0.003} & \textBF{0.470$\pm$0.013} \\
            Joint Embedding & \textBF{0.718$\pm$0.000} & \textBF{0.718$\pm$0.000} & \textBF{0.715$\pm$0.000} & 0.684$\pm$0.007 & 0.442$\pm$0.021 \\
            Proposed Model & \textBF{0.718$\pm$0.000} & \textBF{0.718$\pm$0.000} & 0.714$\pm$0.000 & 0.678$\pm$0.002 & 0.429$\pm$0.012 \\
            \hline
            \multicolumn{6}{|c|}{\textbf{Mean per-Sample Accuracy}} \\
            \hline
            ALOHA & \textBF{0.718$\pm$0.000} & \textBF{0.718$\pm$0.000} & 0.714$\pm$0.001 & \textBF{0.683$\pm$0.003} & \textBF{0.452$\pm$0.014} \\
            Joint Embedding & \textBF{0.718$\pm$0.000} & \textBF{0.718$\pm$0.000} & \textBF{0.714$\pm$0.000} & 0.680$\pm$0.007 & 0.422$\pm$0.020 \\
            Proposed Model & \textBF{0.718$\pm$0.000} & \textBF{0.718$\pm$0.000} & 0.713$\pm$0.000 & 0.675$\pm$0.002 & 0.409$\pm$0.012 \\
            \hline
        \end{tabular}
        \caption{Mean and standard deviation of mean per-sample tagging results (\textit{Jaccard simialrity} and \textit{mean per-sample accuracy}) for the different models. Results were aggregated over \textBF{3} training runs with different weight initializations and minibatch orderings. Best results are shown in \textbf{bold}.} \label{tab:meanPerSampleScores}
    \end{table}
}