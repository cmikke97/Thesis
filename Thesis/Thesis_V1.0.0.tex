% !TEX encoding = IsoLatin

% La riga soprastante serve per configurare gli editor TeXShop, TeXWorks
% e TeXstudio per gestire questo file con la codifica IsoLatin o Latin 1
% o ISO 8859-1.

% per commentare una riga mettere % al suo inizio
% per s-commentare una riga (ossia attivarla) togliere il % al suo inizio
%
\documentclass[pdfa% formato PDF/A, obbligatorio per l'archiviazione delle tesi di Polito
,cucitura%lascia margine per la rilegatura
%,twoside% per stampa fronte-retro (fortemente consigliato per tesi voluminose, opzionale per le altre)
%,12pt% font più grande (12pt) rispetto a quello normalmente usato (11pt)
]{toptesi}
%
\usepackage{hyperref}
\hypersetup{%
    pdfpagemode={UseOutlines},
    bookmarksopen,
    pdfstartview={FitH},
    colorlinks,
    linkcolor={blue},
    citecolor={red},
    urlcolor={blue}
  }
% \documentclass[11pt,twoside,oldstyle,autoretitolo,classica,greek]{toptesi}
% \usepackage[or]{teubner}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Esempio di composizione di tesi di laurea.
%
% Questo esempio e' stato preparato inizialmente 13-marzo-1989
% e poi e' stato modificato via via che TOPtesi andava
% arricchendosi di altre possibilita'.
%
% Nel seguito laurea "quinquennale" sta anche per "specialistica" o "magistrale"

% Cambiare encoding a piacere; oppure non caricare nessun encoding se si usano
% solo caratteri a 7 bit (ASCII) nei file d'entrata.
%
\usepackage[latin1]{inputenc}% IMPORTANTE! usare codifica ISO-8859-1 per le lettere accentate

% temporaneo
\usepackage[dvipsnames]{xcolor}

\input{commands.tex}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{blue},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstdefinelanguage{YARA}{
	morekeywords=[1]{rule, meta, strings, condition},
	morekeywords=[2]{import, ascii, wide, nocase, and, or, all, at, in, of, fullword},
	keywordstyle=[1]\color{Blue},
	keywordstyle=[2]\color{Red},
	sensitive=false,
	morecomment=[l]{//},
	morecomment=[s]{/*}{*/},
	morestring=[b]",
	morestring=[d]',
}

\usepackage{xcolor}

\begin{document}
	
\selectlanguage{english}

\ateneo{Politecnico di Torino}

%%% scegliere la propria facoltà (solo PRIMA dell'AA 2012-2013)
%
%\facolta[III]{Ingegneria dell'Informazione}
%\facolta[IV]{Organizzazione d'Impresa\\e Ingegneria Gestionale}
%\Materia{Remote sensing}% uso sconsigliato

%\monografia{Gestione informatizzata di un magazzino ricambi}% per la laurea triennale
\titolo{Automatic Malware Signature Generation}% per la laurea quinquennale e il dottorato
%\sottotitolo{Metodo dei satelliti medicei}% NON obbligatorio, per la laurea quinquennale e il dottorato

%%% scegliere il proprio corso
%
%\corsodilaurea{Ingegneria dell'Organizzazione d'Impresa}% per la laurea di primo e secondo livello
%\corsodilaurea{Ingegneria Logistica e della Produzione}% per la laurea di primo e secondo livello
%\corsodilaurea{Ingegneria Gestionale}% per la laurea di primo e secondo livello
\corsodilaurea{Ingegneria Informatica}% per la laurea di primo e secondo livello
%\corsodidottorato{Meccanica}% per il dottorato

\candidato{Michele \textsc{Crepaldi}}% per tutti i percorsi
%\secondocandidato{Evangelista \textsc{Torricelli}}% per la laurea magistrale solamente
%\direttore{prof. Albert Einstein}% per il dottorato
%\coordinatore{prof. Albert Einstein}% per il dottorato
\relatore{prof.\ Antonio Lioy}% per la laurea e il dottorato
\secondorelatore{ing.~Andrea Atzeni}% per la laurea magistrale
%\terzorelatore{{\tabular{@{}l}dott.\ Neil Armstrong\\prof. Maria Rossi\endtabular}}% per la laurea magistrale
%\tutore{ing.~Andrea Atzeni}% per il dottorato
%\tutoreaziendale{dott.\ ing.\ Giovanni Giacosa} % solo per la laurea di secondo livello con tesi svolta in azienda
%\NomeTutoreAziendale{Supervisore aziendale\\Centro Ricerche FIAT}
%\sedutadilaurea{Agosto 1615}% per la laurea quinquennale
%\esamedidottorato{Novembre 1610}% per il dottorato
%\sedutadilaurea{\textsc{Novembre} 2017}% per la laurea triennale
\sedutadilaurea{\textsc{Anno~accademico} 2020-2021}% per la laurea magistrale
%\annoaccademico{1615-1616}% solo con l'opzione classica
%\annoaccademico{2006-2007}% idem
%\ciclodidottorato{XV}% per il dottorato
\logosede{logopolito}
%
%\chapterbib %solo per vedere che cosa succede; e' preferibile comporre una sola bibliografia
%\AdvisorName{Supervisors}
%\newtheorem{osservazione}{Osservazione}% Standard LaTeX

%\usepackage[a-1b]{pdfx}
%\hypersetup{%
%    pdfpagemode={UseOutlines},
%    bookmarksopen,
%    pdfstartview={FitH},
%    colorlinks,
%    linkcolor={blue},
%    citecolor={green},
%    urlcolor={blue}
%  }

%
% per numerare e far comparire nell'indice anche le sezioni di quarto livello
% SCONSIGLIATO! da usarsi solo in caso di estrema necessità
%\setcounter{secnumdepth}{4}% section-numbering-depth
%\setcounter{tocdepth}{4}% TOC-numbering-depth (TOC=Table-Of-Content)

%\setbindingcorrection{3mm}

\errorcontextlines=9

\frontespizio
\paginavuota
\newpage
%per sfruttare meglio lo spazio nella pagina
\advance\voffset -5mm
\advance\textheight 30mm

% opzionale, solo se si vuole dedicare la tesi a delle persone care
\begin{dedica}
	
Thanks...

\end{dedica}

\sommario

Summary...

\ringraziamenti

Aknowledgments...

%% inserire sempre nella tesi per la laurea di I livello, perché il nome dei tutori non è indicato sul frontespizio.
%Il lavoro descritto in questa monografia è stato svolto sotto la supervisione
%del Prof. Antonio Lioy (tutore accademico)% inserire sempre il nome del tutore accademico
% e dell'Ing. Mario Rossi (tutore aziendale)% inserire solo se la monografia è relativa ad un tirocinio.
%.

%\tablespagetrue % normalmente questa riga non serve ed e' commentata
%\figurespagetrue % normalmente questa riga non serve ed e' commentata

\indici

\mainmatter

\chapter{Introduction}
\color{Gray}
While working on this document, I will mark with the colour \textcolor{Red}{red} the parts containing drafts and information got from outside sources. I will use the colour \textcolor{Orange}{orange} for parts under active modification, and the colour  \textcolor{Green}{green} for comments (apart from this one).

\color{Red}
The accelerating rate of malware incidents on daily basis indicates the magnitude of the problem in malware analysis. While malware analysts detect many malware attacks and incidents, keeping pace with the number and different types of attacks poses a significant challenge to malware analysts. There is no silver bullet with respect to malware, as there is no single malware analysis technique with the capability to treat all malware incidents, as a result analysts select the most suitable malware analysis technique for the specific security incident under consideration \cite{NaikEAGYRETE}.
\color{Black}

\chapter{Background}

\section{Malware}
\textbf{Malware}, short for \textbf{\textit{malicious software}}, is a general term for all types of programs designed to perform harmful or undesirable actions on a system. In fact in the context of IT security the term \textit{malicious software} commonly means \cite{SharpAIM}:

\begin{quote}
	\textit{Software which is used with the aim of attempting to breach a computer system's security policy with respect to Confidentiality, Integrity and/or Availability.}
\end{quote}

Malware consists of programming artefacts (code, scripts, active content, and other software) designed to disrupt or deny operation, gain unauthorized access to system resources, gather information that leads to loss of privacy or exploitation, and other abusive behaviour.
Malware is not (and should not be confused with) defective software - software that has a legitimate purpose but contains harmful bugs (programming errors).

Different companies, organizations and people describe malware in various ways. For example \textbf{Microsoft} defines it in a generic way as:

\begin{quote}
	\textit{Malware is a catch-all term to refer to any software designed to cause damage to a single computer, server, or computer network} \cite{MoirDM}.
\end{quote}

The \textbf{National Institute of Standards and Technology} (\textbf{NIST}), on the other hand, presents multiple definitions for malware, describing it as "hardware, firmware, or software that is intentionally included or inserted in a system for a harmful purpose" \cite{nistM}.

In another more specific definition \textbf{NIST} affirms that Malware is:

\begin{quote}
	\textit{A program that is inserted into a system, usually covertly, with the intent of compromising the confidentiality, integrity, or availability of the victim's data, applications, or operating system or of otherwise annoying or disrupting the victim} \cite{nistM}.
\end{quote}

Notice that, since the attacker can use a number of different means - such as executable code, interpreted code, scripts, macros etc. - to perpetrate its malicious intents, the term \textbf{\textit{software}} should be understood in a broader sense in the above definitions.\\
Moreover, the computer system whose security policy is attempted to be breached is usually known as the \textbf{\textit{target}} for the malware. Instead, the cybercriminal who originally launched the malware with the purpose of attacking one or more targets is generally referred to as the "\textit{initiator} of the malware". Furthermore, depending on the malware type, the initiator may or may not exactly know what the set of targets is \cite{SharpAIM}.\\
According to the above definitions software is defined as malicious in relation to an attempted breach of the target's \textbf{\textit{security policy}}.
In other words, software is often identified as malware based on its \textit{intended use}, rather than the particular technique or technology used to build it.

\subsection{Why is Malware used}
Generally, cybercriminals use malware to access targets' sensitive data, extort ransoms, or simply cause as much damage as possible to the affected systems.

More generally malware serves a variety of purposes. For example, the most common cybercriminals' uses of malware are: \cite{CraneWIM}

\begin{itemize}
	\item \textbf{To profit financially (either directly or through the sale of their products or services)}.
	For example, attackers may use malware to infect targets' devices with the purpose of stealing their credit account information or cryptocurrency. Alternatively, they may sell their malware to other cybercriminals or as a service offering (\textit{malware-as-a-service}).
	
	\item \textbf{As a means of revenge or to carry out a personal agenda}.
	For example, Brian Krebs of Krebs on Security was struck by a big DDoS attack in 2016 after having talked about a DDoS attacker on his blog.
	
	\item \textbf{To carry out a political or social agenda}.
	Nation-state actors (like state-run hacker groups in China and North Korea) and hacker groups such as Anonymous are a perfect example.
	
	\item \textbf{As a way to entertain themselves}.
	Some cybercriminals enjoy victimizing others.
\end{itemize}

Obviously there are also reasons for non-malicious actors to create and/or deploy some types of malware too - for example it can be used to test a system's security.

\subsection{Malware types}
There are numerous different ways of categorizing malware; one way is by \textit{how} the malicious software spreads. Another one is by what it \textit{does} once it has successfully infected its victim's computers (i.e. what is its payload, how it exploits or makes the system vulnerable).

\subsubsection{By how they spread}
Terms like \textit{trojan}, \textit{virus} and \textit{worm} are commonly used interchangeably to indicate generic malware, but they actually describe three subtly different ways malware can infect target computers \cite{SymantecDVWT}:

\begin{itemize}
	\item \textbf{\textit{Trojan horse}}. Generally speaking, a \textit{Trojan Horse}, commonly referred to as a "Trojan", is any program that disguises itself as legitimate and invites the user to download and run it, concealing a malicious payload. When executed, the payload - malicious routines - may immediately take effect and cause many undesirable effects, such as deleting the user files or installing additional malware or PUAs (Potentially Unwanted Apps).
	
	Trojans known as \textit{droppers} are often used to start a worm outbreak, by injecting the worm into users' local networks \cite{MullinsMT}.
	
	Trojans may hide in games, apps, or even software patches, or they may rely on social engineering and be embedded in attachments included in phishing emails.
	
	Trojan horses cannot self-replicate. They rely on the system operators to activate. However, they can grant the attacker remote access permitting him to then perform any malicious activity that is in their interest. Trojan horse programs can affect the host in many different ways, depending on the payload attached to them \cite{NamanyaTWM}.
	
	\item \textbf{\textit{Virus}}. The term "computer virus" is used for describing a passive self-replicating malicious program. Usually spread via infected websites, file sharing, or email attachment downloads, it will lie dormant until the infected host file or program is activated. At that point it spreads to other executables (and/or boot sectors) by embedding copies of itself into those files. A virus, in fact, in order to spread from one computer to another, usually relies on the infected files possibly ending up, by some means or another, in the target system. Viruses are therefore passive. The mean of transport (file, media file, network file, etc.) is often referred to as the virus \textit{vector}. Depending on how complex the virus code is, it may be able to modify its copies upon replication. For the transport of the infected files to the target system(s), the virus may rely on an unsuspecting human user (who for example uses a USB drive containing the infected file) or initiate itself the transfer (for example, it may send the infected files as an e-mail attachment) \cite{SharpAIM}.
	
	Viruses may also perform other harmful actions other than just replicating, such as creating a backdoor for later use, damaging files, stealing information, creating botnets, render advertisements or even damaging equipment.
	
	\item \textbf{\textit{Worm}}. On the other hand, a worm is a self-replicating, active malicious program that exploits various system vulnerabilities to spread over the network. Particularly, it relies on vulnerabilities present in the target's operating system or installed software. Worms usually consume a lot of bandwidth and processing resources due to continuous scanning and may render the host unstable, sometimes causing the system to crash. Computer worms may also contain "payloads" to damage the target systems. Payloads are pieces of code written to perform various nefarious actions on the affected computers among which stealing data, deleting files or creating bots - which can lead the infected systems to become part of a botnet \cite{NamanyaTWM}.
	
\end{itemize}

These definitions lead to the observation that viruses require \textit{user intervention} to spread, whereas a worm spreads itself automatically. A virus, however, cannot execute or reproduce unless the application it infected is running. This dependence on a host program makes viruses different from trojans, which require users to download them, and worms, which do not use applications to execute.

Furthermore, attackers can also install malware "manually" on a computer, either by gaining physical access to the target system or by using privilege escalation methods to obtain remote administrator access \cite{FruhlingerME}.

\subsubsection{By what they do}
There are a wide range of potential attack techniques used by malware, here are some of them:

\begin{itemize}
	\item \textbf{\textit{Adware}}. \textit{Adware}, or "Advertising supported software", is any software package which automatically plays, displays, or downloads advertisements to a computer. Some adware may also re-direct the user's browser to dubious websites. These advertisements can be in the form of a pop-up ads or ad banners in websites, or advertisements displayed by software, that lure the user into making a purchase. The goal of Adware is to generate revenue for its author.
	
	Often times software and application authors offer "free", or discounted, versions of their creations that come bundled with adware. Adware, in fact, is usually seen by the developers as a way to recover development costs. The income derived from ads may motivate the developer to continue developing, maintaining and upgrading his software product. On the other hand users may see advertisements as annoyances, interruptions, or as distractions from the task at hand \cite{MullinsMT}.
	
	Adware, by itself, is annoying but somewhat harmless, since it is solely designed to deliver ads; however, adware often comes bundled with spyware (such as keyloggers), and/or other privacy-invasive software that is capable of tracking user activity and steal information. Adware-spyware bundles are therefore much more dangerous then adware on its own \cite{DuPaulCMT}.
	
	\item \textbf{\textit{Backdoor}}. A \textit{backdoor}, also called Remote Access Trojan (RAT), is a vulnerability deliberately buried into software's code that allows to bypass typical protection mechanisms, like credentials-based login authentication. In other words, it is a method of circumventing normal authentication procedures. Once a system has been compromised (by others types of malware or other methods), one or more backdoors may be installed. This is done with the purpose of allowing the attacker easier access in the future without alerting the user or the system's security programs. Moreover, backdoors may also be installed before other malicious software, to allow attackers entry \cite{MullinsMT}.
	
	Many device or software manufacturers ship their products with intentionally hidden backdoors to allow company personnel or law enforcement to access the system when needed \cite{IngallsTOM}. Alternatively, backdoors are sometimes hidden in programs also by intelligence services. For example, Cisco network routers, which process large volumes of global internet traffic, in the past were equipped with backdoors intended for US Secret Service use \cite{MyraSecurityWIM}.
	
	However, when used by malicious actors, backdoors grant access to attackers without the user knowledge, thus putting the system in real danger.
	
	\item \textbf{\textit{Browser Hijacker}}. A \textit{Browser Hijacker}, also called "hijackware", is a type of malicious program which considerably modifies the behaviour of the victim's web browser. For example it can force the browser to send the user to a new search page, slow down the loading, change the victim's home page, install unwanted toolbars, redirect the user to specific sites, and display unwanted ads without the user consent.\\
	It can be used to make money off ads, to steal information from users, or to infect the systems with other malware by redirecting users to malicious websites \cite{IngallsTOM}.
	
	\item \textbf{\textit{Bots}/\textit{Botnet}}. In general, \textit{bots} (short for 'robots') are software programs designed to automatically perform specific operations. Bots were originally developed to programmatically manage chat IRC channels - Internet Relay Chat: a text-based communication protocol appeared in 1989.\\
	Some bots are still being used for legitimate and harmless purposes such as video programming, video gaming, internet auctions and online contest, among other functions. It is however becoming increasingly common to see bots being used maliciously. Malicious bots can be (and usually are) used to form botnets. A botnet is defined as a network of host computers (zombies/bots) that is controlled by an attacker - the \textit{bot-master} \cite{NamanyaTWM}. Botnets are frequently used for DDoS (Distributed Denial of Service) attacks, but there are other ways that botnets can be useful to cybercriminals: \cite{CraneWIM}
	
	\begin{itemize}
		\item \textbf{Brute force \& credential stuffing} - Bots can be used to carry out different types of brute force attacks on websites. For example they can use a pre-configured list of usernames and passwords combinations on website login pages with the hope of finding a winning combination, after enough tries.
		
		\item \textbf{Data and content scraping} - Botnets can be used as web spiders to scour websites and databases to gather useful information - such as site content, pricing sheets, etc. - which can be used to obtain an unfair advantage against the competition.
		
		\item \textbf{Botnet-as-a-service opportunities} - Botnets are sometimes rented out by their creators to all kinds of malicious users - including less tech-savvy ones. Doing so, even inexperienced attackers can carry out attacks, such as taking down a target's servers and networks with a DDoS, using these mercenary bots. This service model is sometimes called malware-as-a-service.
		
		\item \textbf{Spambot} - A botnet can also be used to act as a spambot and render advertisements on websites.
		
		\item \textbf{Malware distributor} - Finally Botnets can even be used for distributing malware disguised as popular search items on download sites.
	\end{itemize}
	
	\item \textbf{\textit{Crypto-miner}}. Crypto-miners are a relatively new family of malware. Cybercriminals employ this type of malicious tools to mine Bitcoin and/or other bitcoin-alike digital currencies on the target machine. The victim system's computing power is used for this, without the owner realising it. The mined coins end up in the attackers' digital crypto wallets.
	
	Recently, a more modern method of crypto-mining that works within browsers (also called crypto-jacking), has become quite popular.
	
	In some cases, the use of crypto-miners may be deemed legal. For example they could be used to monetize websites, granted that the site operator clearly informed visitors of the use of such tools \cite{MyraSecurityWIM}.
	
	Finally, according to ESET, most crypto-miners focus mostly on \textit{Monero} as target crypto-currency because it offers anonymous transactions and can be mined with regular CPUs and GPUs instead of expensive, specialized hardware \cite{CraneWIM}.
	
	\item \textbf{\textit{File-less malware}}. File-less malware is a type of memory-resident malware that uses legitimate code already existing within the target computer or device to carry out attacks. As the term suggests, it is malware that operates from a victim's computer memory, not from files on the hard drive, taking advantage of legitimate tools and software (known as "LOLBins" \cite{CraneWIM}) that already exist within the system. File-less malware attacks leave no malware files to scan and no malicious processes to detect. Since there are no files to scan, it is harder to detect and remove than traditional malware; this makes them up to ten times more successful than traditional malware attacks \cite{BakerMCTM}. Furthermore, it also renders forensics more difficult because when the victim's computer is rebooted the malware disappears.
	
	\item \textbf{\textit{Keylogger}}. Keystroke logging (often called \textit{keylogging}) is the action of secretly tracking (or logging) keystrokes on a keyboard, without the person using the keyboard knowing that its actions are being monitored. The collected information is stored and then sent to the attacker who can then use the data to figure out passwords, usernames and payment details, for example. There are various methods used to perform keylogging, ranging from hardware and software-based approaches to the more sophisticated electromagnetic and acoustic analysis \cite{MullinsMT}. Key loggers can be inserted into a system through phishing, social engineering or malicious downloads.
	
	There are various methods used to perform keylogging, ranging from hardware and software based approaches to electromagnetic and acoustic analysis.
	
	To this extent keyloggers can be considered as a sub-category of spyware.
	
	Keylogging also has legitimate uses, in fact it is often used by law enforcement, parents, and jealous or suspicious spouses. The most common use, however, is in the workplace, where employers monitor employee use of company computers.
	
	\item \textbf{\textit{RAM Scraper}}. \textit{RAM scraper} malware, also known as \textit{Point-of-Sale (POS)} malware, targets POS systems like cash registers or vendor portals, harvesting data temporarily stored in RAM (Random Access Memory). Doing so the attacker can access unencrypted credit card numbers \cite{IngallsTOM}.
	
	\item \textbf{\textit{Ransomware}}. \textit{Ransomware}, also known as "encryption" or "crypto" Trojan, is a malicious program that, after having infected a host or network, holds the system captive and requests a ransom from the host/network users. In particular it encrypts data on the infected system (or anyway locks down the system so that the users have no access) and only unblocks it when the correct password - decryption key - is entered. The latter is not given to the victims until after they have paid the ransom to the attacker. Messages informing the system user of the attack and demanding a ransom are usually displayed. Without the correct decryption key, it's mathematically impossible for victims to decrypt and regain access to their files.
	
	Digital currencies such as Bitcoin and Ether are the most common means of payment, making it difficult to track the cybercriminals. Moreover, paying the ransom does not guarantee the user to receive the necessary decryption key or that the one provided is correct and functions properly. Additionally, some forms of ransomware threaten victims to publicize sensitive information within the encrypted data.
	
	Ransomware is one of the most profitable, and therefore one of the most popular, and dangerous kinds of malware programs of the past few years.
	
	The "Five Uneasy E's" of ransomware, according to Tim Femister \cite{FemisterEHL} - vice president of digital infrastructure at ConvergeOne - are:
	
	\begin{itemize}
		\item \textbf{Exfiltrate}: Capture and send data to a remote attacker server for later leverage.
		\item \textbf{Eliminate}: Identify and delete enterprise backups to improve odds of payment.
		\item \textbf{Encrypt}: Use leading encryption protocols to fully encrypt data.
		\item \textbf{Expose}: Provide proof of data and threaten public exposure and a data auction if payment is not made.
		\item \textbf{Extort}: Demand an exorbitant payment paid via cryptocurrency.
	\end{itemize}

	\item \textbf{\textit{Rogue Security Software}}. \textit{Rogue Security Software} can be considered as a from of scareware. This type of malware program presents itself as a security tool to remove risks from the user's system. In reality, this fake security software installs more malware onto their system \cite{IngallsTOM}.
	
	\item \textbf{\textit{Rootkit}}. A \textit{rootkit} is generally thought as a type of malicious software, or a collection of software tools, designed to remotely access or control a computer without being detected by users or security programs. An attacker who has installed a rootkit on a system is able to remotely execute files, log user activities, access/steal information, modify system configurations, alter software (including security software), install hidden malware, mount attacks on other systems or control the computer as part of a botnet. Since a rootkit operates stealthily and continually hides its presence, its prevention, detection and removal can be difficult; in fact, typical security product are often not effective in detecting rootkits. Rootkit detection therefore often relies on manual methods such as monitoring the computer's behaviour for irregular activity, scanning system file signatures, and analysing storage dumps \cite{DuPaulCMT}.
	
	More recently, the term "rootkit" has also often been used to refer to concealment routines in a malicious program. These routines are highly advanced and complex and are written to hide malware within legitimate processes on the infected computer. In fact, once a malicious program has been installed on a system, it is essential that it remains hidden, to avoid detection and disinfection. The same is true when a human attacker directly breaks into a computer. Techniques known as rootkits allow for this concealment by modifying the host's operating system so that malware is hidden from the user. They can prevent a malicious process from being visible in the system's process list or prevent its files from being read \cite{MullinsMT}.
	
	Traditionally, rootkits can install themselves in kernel level (ring 0), although some sources state that they can install themselves all the way up to user level (ring 3). This means that they can get as much (or as little) access as necessary.
	
	There are different types of rootkits, which are typically categorized by the reach of the system they affect: \cite{IngallsTOM}
	
	\begin{itemize}
		\item \textbf{\textit{User-level/application level rootkits}} - User-mode rootkits run in Ring 3, along with other applications as user. They can alter security settings, allowing the attacker to replace executables and system libraries.
		
		\item \textbf{\textit{Kernel-level rootkits}} - Kernel-mode rootkits run in ring 0, the highest operating system privileges (Ring 0). They manage to do so by modifying the core functionality of the operating system - the kernel. They usually add code or replace portions of the core operating system, including both the kernel and associated device drivers.
		
		\item \textbf{\textit{Bootkit rootkits}} - A Bootkit rootkit is a type of kernel-mode rootkit which infects startup code like the Master Boot Record (MBR), Volume Boot Record (VBR), or boot sector, subverting the kernel upon computer start up.
		
		\item \textbf{\textit{Virtualization rootkits}} - This type of rootkit, also called \textit{Hypervisor rootkit}, runs in Ring -1 (before the kernel) and hosts the target operating system as a virtual machine. It manages to do so by exploiting hardware virtualization features. This in turn enables the rootkit to intercept hardware calls made by the original OS.
		
		\item \textbf{\textit{Hardware/firmware rootkits}} - A firmware rootkit uses device or platform firmware to create a persistent malware image in hardware. The rootkit hides in firmware, because the latter is not usually inspected for code integrity.
	\end{itemize}

	\item \textbf{\textit{Scareware}}. Scareware is a generic term for malware that uses social engineering to frighten and manipulate a user, inducing him into thinking their system is vulnerable or has been attacked.
	However, in reality no danger has actually been detected: it is a scam.	The attack succeeds when the user purchases unwanted - and potentially dangerous - software in an attempt to eliminate the "threat". Generally, the suggested software is additional malware or allegedly protective software with no value whatsoever \cite{MyraSecurityWIM}.
	
	Both Rogue Security Software and Ransomware can be considered as scareware, together with other scam software.

	Some versions of scareware act as a sort of shadow version of ransomware; they claim to have taken control of the victim's system and demand a ransom. However they are actually just using tricks - such as browser redirect loops - to fool the victim into thinking they have done more damage than they really have \cite{FruhlingerME}.
	
	\item \textbf{\textit{Spyware}}. 
	
	\textit{Spyware}, another name for \textit{privacy-invasive software}, is a type of malicious software that uses functions in the infected host's operating system with the aim of spying on the user activity. Specifically it can collect various types of personal information about users, such as Internet browsing habits, credit card details and passwords, without their knowledge. The information gathered is then sent back to the responsible cybercriminal(s). The presence of spyware is typically hidden from the user, and can be difficult to detect.
		
	However, the functions of spyware often go far beyond simple activity monitoring and information gathering. In fact, they may also interfere with the user's control of the computer in other ways, such as installing additional software and redirecting web browser activity. Spyware is known to change computer settings, often resulting in slow connection speeds, different home pages, and/or loss of Internet connection or functionality of other programs. They spread by attaching themselves to legitimate software, Trojan horses, or even by exploiting known software vulnerabilities \cite{MullinsMT}.
	
	Law enforcement, government agencies and information security organizations often use spyware to monitor communications in a sensitive environment or during an investigation. Spyware is however also available to private consumers, allowing them to spy on their employees, spouse and children \cite{McAfeeWIM}.
\end{itemize}

\subsubsection{Other cyber-threats}
Other cyber threats which are not strictly malware are, for example:

\begin{itemize}
	\item \textbf{\textit{Software Bug}}.
	A software bug is an error, or flaw, in a computer program code or system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. Usually, most of these defects arise from human errors made in the program's source code. Some bugs may be caused by compilers or operating systems component used by the program.
	
	Minor bugs only slightly affect the behaviour of a program. Therefore it can be a long time before they are discovered. On the other hand, more significant bugs can cause crashes or freezes. It is safe to say that almost all software has bugs and most bugs go unnoticed or have a slight impact on the user.
	
	However, other bugs qualify as security bugs. These are the most serious type of bugs since they can allow attackers to bypass access controls such as user authentication, override access privileges, or steal data.
	
	The frequency of bugs can be reduced through developer training, quality control, and code analysis tools \cite{DuPaulCMT}.
	
	\item \textbf{\textit{Malvertising}}. Malvertising is the use of legitimate ads or ad networks to covertly deliver malware to unsuspecting users' computers.
	
	For example, a cybercriminal might pay to place an ad on a legitimate website. When a user clicks on the ad, code in the ad either redirects them to a malicious website or installs malware on their computer.
	
	In some cases, the malware embedded in an ad might execute automatically without any action from the user, a technique referred to as a "drive-by-download".
	
	\item \textbf{\textit{Phishing}}. Phishing is a type of social engineering attack commonly used to perform cyber attacks. Particularly in a phishing attack, the attacker attempts, through email messages, to trick users into divulging passwords (or anyway personal and financial information), downloading a malicious attachment or visiting a website that installs malware on their systems.
		
	Some phishing emails are highly sophisticated and can deceive even experienced users, especially if the attacker has successfully compromised a known contact's email account and uses it to spread phishing attacks or malware such as worms. Others are less sophisticated and simply spam as many emails as possible with messages such as "Check your bank account details" \cite{ComtactWDYM}.
		
	There are different types of Phishing. Here are mentioned some of them: \cite{IngallsTOM}
	
	\begin{itemize}
		\item \textit{Deceptive Phishing} - The most common type. It uses an email headline with a sense of urgency from a know contact. This attack blends legitimate links with malicious code, modifies brand logos, and evades detection with minimal content.
		
		\item \textit{Spear Phishing} - Spear phishing targets specific users or organizations by researching the victim to maximise trick potential. For example the attacker may explore social media, record out-of-office notifications, compromise API tokens etc. in order to better fool the target user.
		
		\item \textit{Whaling} - Whaling is similar to spear phishing, but even more targeted. In fact, it targets chief officers of organizations using various social engineering tricks such as impersonating employees or co-workers and using phone calls - to name a few - to give a sense of legitimacy to malicious emails.
		
		\item \textit{Vishing} - Vishing targets phone users. It uses the Voice over Internet Protocol (VoIP), technical jargon, and ID spoofing to trick a caller into revealing sensitive information.
		
		\item \textit{Smishing} - Smishing also targets phone users. It uses, however malicious text messages (SMS).
		
		\item \textit{Pharming} - Pharming leverages cache poisoning against the DNS with the objective of redirecting users to fake websites.
	\end{itemize}

	\item \textbf{\textit{Spam}}.
	
	In cybersecurity, unsolicited emails are generally referred to as \textit{spam}. Typically, spam includes emails carrying unsolicited advertisements, fraud attempts, links to malicious websites or malicious attachments. Most spam emails contain one or more of the following: \cite{IngallsTOM}
	
	\begin{itemize}
		\item Poor spelling and grammar
		\item Unusual sender address
		\item Unrealistic claims
		\item Suspicious links
	\end{itemize}

	Spam might be one of the most universally understood forms of malicious attacks. As billions of users enable email for their everyday lives, it makes sense that malicious actors try to sneak into their inbox. Some of the most common types of spam emails include fake responses, PayPal, returned mail, and social media. All of which are disguised as legitimate but contain malware.
\end{itemize}

\subsubsection{General considerations on malware types}
Malware samples are usually categorised both by a means of infection and a behavioural category: for instance, WannaCry is a ransomware worm.\\
Moreover, a particular piece of malware may have various forms with different attack vectors: e.g., the banking malware called \textit{Emotet} has been spotted in the wild as both a trojan and a worm \cite{FruhlingerME}.\\
Finally, many instances of malware fit into multiple categories: for example Stuxnet is both a worm, a virus and a rootkit.

Furthermore, in recent years, targeted attacks on mobile devices have also become increasingly popular.
In fact, among the huge amount of available apps, an increasing quantity is not desirable; the problem is even worse when considering third-party app stores. Even when app store providers impose filters and manual checks to prevent the malicious apps from being available, some inevitably slip through.
These mobile malware threats are as various as those targeting desktops and include Trojans, Ransomware, Advertising click fraud and more. They are mostly distributed through phishing and malicious downloads and are a particular problem for jail-broken phones, which tend to lack the default protections that were part of those devices' original operating systems.

\subsection{Malware History}
Malware history began in the 1960s. Then, hackers used to design computer viruses mainly for fun, as an exciting prank/experiment; their creations would generally display harmless messages and then spread to other computers \cite{ReganWIM}.
There are numerous examples of malware created at that time within a laboratory setting: for example the \textbf{\textit{Darwing game}} in 1962, \textbf{\textit{Creeper}} in 1971, \textbf{\textit{Rabbit Virus}} in 1974 and \textbf{\textit{Pervading Animal}} in 1975.

In particular, the malware called \textbf{\textit{Creeper}} was designed to infect mainframes on ARPANET. The program did not alter the machines' functions, nor it stole or deleted data. It only displayed the message "I'm the creeper: Catch me if you can" while illegitimately spreading from one mainframe to another. This malware was later upgraded with the ability to self-replicate and became the first known computer worm \cite{LutkevichM}.

In the early 1980s, the concept of malware caught on in the technology industry, and numerous examples of viruses and worms appeared both on Apple and IBM personal computers. With the introduction of the World Wide Web and the commercial internet in the 1990s it eventually became widely popularized, so much that Yisreal Radai coined the term \textbf{malware} in 1990.

The previously mentioned 1960s and 1970s malware were all kept within a laboratory environment and never managed to escape to the wild. \textbf{\textit{Elk Cloner}} (1981) was the first known virus to have been able to escape its creation environment. Then, following the success of that prank gone wild, the first Microsoft PC virus, called \textbf{\textit{Brain}}, was created in 1986. Again, like \textit{Elk Cloner}, Brain was mostly annoying rather than harmful, but it was also the first known virus capable of concealing its presence on the disk thus evading detection. In 1988 the first worm, called \textbf{\textit{Morris}} worm, an experimental, self-propagating, self-replicating program was released on the internet \cite{NamanyaTWM}. In 1988 made its appearance also the first example of intentionally harmful virus, the \textbf{\textit{Vienna}} virus, which encrypted data and destroyed files. This led to the creation of the first antivirus tool ever \cite{ReganWIM}.

In the following decades malware has evolved both regarding its complexity and malware sample numbers.

The growth in malware complexity can be divided 5 different malware generations \cite{NamanyaTWM}:

\begin{itemize}
	\item \textit{First generation}: (DOS Viruses) malware mainly replicate with the assistance of human activity
	\item \textit{Second generation}: malware self-replicate without help and share the functionality characteristics of the first generation. They propagate through files and media.
	\item \textit{Third generation}: malware utilise the capabilities of the internet in their propagation vectors leading to big impact viruses.
	\item \textit{Fourth generation}: malware are more organization-specific and use multiple vectors to attack mainly anti-virus software or systems due to the commercialisation of malware.
	\item \textit{Fifth generation}: malware is used in cyberwarfare and the now popular malware as-a-service makes its appearance.
\end{itemize}

Each jump in generation is linked to an increase in malware complexity and more propagation vectors being available. Newer generations of malware always re-utilise older techniques while introducing newer ones. Finally newer generations are more and more evasive due to the commercial value in having access to exploited systems.

In the appendix, section \ref{NotableMalwareExamples}, a list of the most famous examples of malware attacks/incidents of recent history can be found.

\section{Detection evasion}
From the creation of the first malware in 1970 \cite{Szor_P}, there has been a strong competition between attackers and defenders. To defend from malware attacks, anti-malware groups have been developing increasingly complex (and clever) new techniques. On the other hand, malware developers have conceived and adopted new tactics/methods to avoid the malware detectors.

The first type of anti-malware tools were mostly based on the assumption that malware structures do not change appreciably during time. In fact, initially, the malware machine code was completely unprotected. This allowed analysts to exploit opcode sequences to recognise specific malware families. 
Recently, however, a big advancement led to the so-called "second generation" malware \cite{Sharma_2014} which, to evade such opcode signatures, employs several obfuscation techniques and can create variants of itself. This posed a challenge to anti-malware developers.

The first time a malware has been recognised to exhibit detection avoidance behaviour was in 1986 with the \textit{Brain} virus \cite{SkoudisFMC}. In fact, such malware managed to conceal the infected disk section whenever the user attempted to read it, forcing the computer to display clean data instead of the infected part. From that moment on, the ever increasing popularity of detection evasion techniques among malware writers has shown that malware survival has become the number one priority: the longer the malware remains undetected, the more harm it can do and the more profitable it is to its writer \cite{NamanyaTWM}.

\subsection{Reverse-Engineering}
\textit{Reverse engineering}, in broad terms, indicates the process of extracting knowledge, ideas, design philosophy etc. from anything man-made \cite{EilamRSRE}.

Software reverse engineering is, of course, the application of reversing methodologies and techniques to extract knowledge from a software product to better understand its inner workings.

Reversing is used extensively by both malicious actors and investigators but with opposing purposes. Malware developers often use it to discover vulnerabilities in systems or programs, while analysts and antivirus software developers use it to analyse malicious programs to understand how they work, what damages they can cause, how they infect the system and reproduce, how they can be removed, detected and avoided.

\subsection{Malware analysis}
Malware analysis is the process of extracting as much information as possible from malicious samples discovered in the wild, which usually are in the form of machine code executables (compiled executables), in order to determine their purpose and functionality (and threats associated). This process allows security teams to develop effective detection techniques against the analysed malicious code, contain its damage, reverse its effects on the system, develop removal tools that can delete it from infected machines (to cleanly remove a piece of malware from an infected machine it is usually not enough to delete the binary itself) and design methods to guard systems against future infections \cite{BayerDAMC}.

Initially malware analysts/researchers had to manually analyse each malware sample. This process is however complex, requires high expertise, and is time-intensive. Moreover, the number of malware samples that need to be analysed on a daily basis is nowadays of the order of hundreds. This implies that the analysis of malware samples can no longer be done exclusively manually. Several analysis tools have been developed in recent years to facilitate analysts in analysing malware samples.

Traditionally, there are two main types of analysis: \textit{static} and \textit{dynamic}. Moreover, these two types can be, and frequently are, combined together (\textit{hybrid} analysis) in various stages of malware analysis to optimize results \cite{NamanyaTWM}.

\subsubsection{Static analysis}
\textit{Static analysis} consists of examining an executable file's code without actually executing it. Static analysis techniques usually extract peculiar features from malicious samples in order to be able to recognise them and distinguish them from benign ones. The features usually extracted are, for example, string signatures, byte-sequence n-grams, library or API calls, opcode frequency distributions, peculiar attributes found in the executable header etc. However, this approach, being based on signatures/features extracted from already analysed samples, is not much effective on zero-day and evolutionary malware.

A malware analyst performing manual static analysis usually disassembles the binary first, meaning that he 'translates' the program's machine code instructions back into assembly language ones generating a more human-interpretable code listing. On the latter, control flow, data flow analysis, and many others static techniques can be employed to try understating the program functionality and inner workings, among other useful information \cite{BayerDAMC}.

Static analysis advantages are, among others, that it takes into account the entire program code and it is also usually faster (and safer) than the dynamic one. However, a general disadvantage of static analysis is that many times the information collected during this type of analysis is very simple and not always sufficient for a conclusive decision on the malicious intent of a file. It is, however, good practice to start the analysis of a suspicious executable file extracting as much information as possible through various static techniques before passing to the dynamic counterpart. The information statically extracted may in fact provide useful knowledge to better apply dynamic techniques and enhance the final results.

Additionally, another common problem to deal with when using static analysis is that, since malicious code is written directly by the adversary, it can be purposefully designed to be hard to analyse statically. For example, analysis evasion techniques like packing, encryption and obfuscation can be exploited by malware authors to hinder both disassembly and code analysis steps typical of static analysis approaches, ultimately leading to incorrect or useless information \cite{NamanyaTWM}.

\subsubsection{Dynamic analysis}
Contrary to static analysis, \textit{dynamic techniques} analyse the program's code while or after execution in a controlled environment. These techniques, while being non-exhaustive, they have the significant advantage that they analyse only those instructions that are actually executed by the running process. This implies that dynamic analysis is less susceptible to anti-analysis attempts like code obfuscation or anti-disassembly \cite{BayerDAMC}. Moreover, dynamic analysis is also more effective in terms of malicious behaviour detection, since it doesn't look at the disassembled code but, through the use of monitoring tools, it tracks the operations that the code performs on the file system, registry, network etc. It is however, computationally more expensive and time consuming.

Basic dynamic analysis consists of observing the sample under analysis interacting with the system. For example, this can be done taking a snapshot of the original system state, introducing the malware into the system, executing it and finally comparing the new system state with the original one. The changes detected can then be used for infection removal on infected systems and/or for modelling effective signatures/features.

Advanced dynamic analysis, on the other hand, consists of directly examining the executed malware internal state while it is being run. This is done typically by monitoring the APIs and OS function calls invoked, the files created and/or deleted, the registry changes and the data processed by the program under analysis during its interaction with the system. The information extracted in this way can be used to understand the malware behaviour and functionality \cite{NamanyaTWM}.

When using dynamic techniques, however, malware analysts don't simply run malware executables on their own computer, which most probably is even connected to Internet, as they could easily escape the analysis environment and infect other hosts/networks. It is, in fact, advised to deploy dynamic techniques on "safe" and controlled (isolated) environments such as dedicated stand-alone (and isolated) hosts, virtual machines or emulators.

The use of clean dedicated hosts, reinstalled after each dynamic analysis run, is however not the most efficient solution due to the environment re-installation process overheads. On the other hand, using virtual machines (for example VMware) to perform dynamic analysis is more efficient. In fact, in this case, since the malware only affects the virtual machine environment, it is enough, after a dynamic analysis run, to simply discard the infected hard disk image and replace it with a clean one. Unfortunately, a significant drawback is that the malware being analysed may determine it is running in a virtualized environment and, as a result, modify its behaviour. To counter this last problem one could make use of emulators, which are theoretically undetectable by analysed malware. These tools, however, run the code under analysis significantly slower and are therefore sometimes detectable using specially crafted time-related code.

\subsubsection{Hybrid analysis}
Hybrid Analysis is the combination of static and dynamic analysis. It is a technique that integrates run-time information extracted through dynamic analysis with information extracted  through static analysis in order to have a complete view of the malware's behaviour while avoiding the problems posed by anti-analysis techniques as much as possible.

\subsection{Anti-reversing}
\textit{Anti-reversing} techniques are techniques originally meant to make the reverse engineering process difficult for a hacker or any malicious user. The main objective of various anti-reverse engineering techniques is simply to complicate the process of reversing as much as possible. For example an attacker could use the disassembly of a binary in order to get an insight of the logic of the code as well as getting hidden information.

Recently anti-reversing techniques are, however, extensively used also by malware authors in order to make their creations difficult to analyse in an attempt to postpone detection as much as possible.

There exist several anti-reversing approaches, each with its own advantages and disadvantages. However it is common practice to use a combination of more than one of them. In the next sections some of the more common anti-reversing techniques are discussed.

\subsection{Anti-disassembly}
\textit{Anti-disassembly} techniques use specially crafted code and/or data in a program to cause disassembly analysis tools to generate an incorrect program listing \cite{SikorskiPMA}. The attackers' usage of these techniques thus implies a time-consuming analysis for malware analysts, ultimately preventing the retrieval of the source code in a reasonable time.

Any executable code can be reverse engineered, but by armouring their code with anti-disassembly and anti-debugging techniques, attackers increase the skill level required by analysts.
Furthermore, anti-disassembly techniques may also inhibit various automated analysis tools and heuristic-based engines which take advantage of disassembly analysis to identify or classify malware.

These techniques exploit the inherent weaknesses present in disassembler algorithms. Moreover, disassemblers, in order to work properly, make certain assumptions on the code being analysed. However, when these assumptions are not met, there is an opportunity for malware authors to deceive the analyst.

For example, while disassembling a program, sequences of executable code can have multiple disassembly representations, some of which may be invalid and obscure the real purpose of the program.
Thus, the malware authors, in order to add anti-disassembly functionality to their creations, can produce sequences of code that deceive the disassembler into outputting a list of instructions that differs from those that would be executed \cite{SikorskiPMA}.

There are two types of disassembler algorithms: linear and flow-oriented (recursive).
The linear one is easier to implement, but it is also more simplistic and error-prone.

\subsubsection{Linear Disassemblers}
The \textit{linear} disassembly strategy is based upon the basic assumption that the program's instructions are organized one after the other, linearly. In fact, this type of disassemblers iterates over a block of code, disassembling one instruction at a time, sequentially, without deviating. More specifically, the tool uses the size of the currently disassembled instruction to figure out what bytes to disassemble next, without accounting for control-flow instructions \cite{SikorskiPMA}.

Linear disassemblers are easy to implement and work reasonably well when working with small sections of code. They introduce, however, occasional errors even with non-malicious binaries. The main drawback of this technique is that it blindly disassembles code until the end of the section, assuming the data is nothing but instructions packed together, without being able to distinguish between code, data and pointers.

In a PE-formatted executable file, for example, the executable code is typically contained inside a single ".text" section. However, for almost all binaries, this code section contains also data, such as pointer values. These pointers will be blindly disassembled and interpreted by the linear disassembler as instructions.

Malware authors can exploit this weakness of linear-disassembly algorithms implanting data bytes that form the opcodes of multi-byte instructions in the code section.

\subsubsection{Flow-Oriented Disassemblers}
The \textit{flow-oriented} (or \textit{recursive}) disassembly strategy is more advanced than the previous one and is, in fact, the one used by most commercial disassemblers like \textit{IDA Pro} \cite{SikorskiPMA}.

Differently form the linear strategy, the flow oriented one examines each instruction, builds a list of locations to disassemble (the ones reached by code) and keeps track of the code flow.

This implies that, if disassembling a code section we find a JMP instruction, this type of disassembler will not blindly parse the bytes immediately following the JMP instruction?s ones, but it will disassemble the bytes at the jump destination address.

This behaviour is more resilient and generally provides better results, but also implies a greater complexity.

In fact, while a linear disassembler has no choices to make about which instructions to disassemble at any given time, flow-oriented disassemblers have to make choices and assumptions, in particular when dealing with conditional branches and call instructions.\\
Particularly, in the case of conditional branches, the disassembler needs to follow both the false branch (most flow-oriented disassemblers will process the false branch of any conditional jump first) and the true one. In typical compiler-generated code there would be no difference in output if the disassembler processes first one branch or the other. However, in handwritten assembly code and anti-disassembly code, taking first one branch or the other can often produce different disassembly for the same block of code, leading to problems in analysis.

\subsubsection{Anti-Disassembly Techniques}

\paragraph{Jump Instructions with the Same Target}
One of the most used anti-disassembly techniques consists of two consecutive conditional \textit{jump} instructions both pointing to the same target \cite{SikorskiPMA}.

Here is an example:
\begin{lstlisting}[caption={Jump Instructions with the Same Target}, label=JumpSameTarget, language={[x86masm]Assembler}, style=mystyle]
	74 03		jz 	loc
	75 01		jnz	loc
	
	loc:
\end{lstlisting}

In this case, the conditional jump '\textbf{jz loc}' is immediately followed by a jump to the same target but with opposite condition: '\textbf{jnz loc}'. This implies that the location \textbf{loc} will always be jumped to.
Consequently, the combination of \textbf{jz} with \textbf{jnz} acts, in this case, like an unconditional \textbf{jmp} instruction. A disassembler, however, since it disassembles just one instruction at a time, won't recognize this combination as being an unconditional branch. During the disassembly process, in fact, if a \textbf{jnz} instruction is encountered, the disassembler will take the false branch of the instruction and will continue disassembling, even though this branch will never be executed in practice.

\paragraph{Jump Instructions with a Constant Condition}
Another common anti-disassembly technique is composed of a single conditional \textit{jump} instruction with an always true (or false) condition \cite{SikorskiPMA}.

Example:
\begin{lstlisting}[caption={Jump Instructions with a Constant Condition example}, label=JumpConstant, language={[x86masm]Assembler}, style=mystyle]
	33 C0		xor	eax, eax
	74 01		jz 	loc
	
	loc:
\end{lstlisting}

The first instruction in the example code, \textbf{xor eax, eax}, sets the \textbf{EAX} register to zero and, consequently, it sets the zero flag. The next instruction, \textbf{jz} (jump if zero flag is set), appears to be a conditional jump but in reality is not conditional at all. In fact the the zero flag will always be set at this point in the program execution. The disassembler, however, will process the false branch first, even if in reality it would never trigger.

\paragraph{Impossible Disassembly}
The simple anti-disassembly techniques mentioned above are frequently coupled with the use of a, so called, \textit{rogue byte}. A \textit{rogue byte} is a data byte strategically placed after a conditional \textit{jump} instruction in order to trick the disassembler. The byte inserted usually is the opcode for a multi-byte instruction, therefore disassembling it prevents the real following instruction from being properly disassembled. This byte is called \textit{rogue byte} because it is not part of the program logic flow and it is inserted in the code with the only purpose of fooling the disassembler \cite{SikorskiPMA}.

In all these cases, however, a reverse engineer is able to properly disassemble the code with the use of interactive disassemblers like IDA Pro, ignoring the \textit{rogue bytes}.

However, there are some conditions in which no traditional assembly listing can accurately represent the instructions that are executed. Exploiting these conditions we obtain what are called \textit{impossible disassembly} techniques. The code produced using these techniques can however be disassembled, but only using a vastly different representation of the code than what is provided by currently available disassemblers.

The core idea behind these techniques is to make the \textit{rogue byte} part of a legitimate instruction that is executed at runtime. This way the \textit{rogue byte} becomes not ignorable during disassembly. In this scenario any given byte may be a part of multiple instructions that are executed. This is done using \textit{jump} instructions. The processor, while running the code, will interpret and execute the bytes following the logical flow of the program, so there is no limitation on the number of instructions the same byte can be part of; a disassembler, however, has such limitations since it will usually represent a single byte as being part of a single instruction.

Example:
\begin{lstlisting}[caption={Impossible Disassembly example}, label=ImpossibleDisassembly, language={[x86masm]Assembler}, style=mystyle]
	EB 
				JMP -1
	FF
				INC EAX
	C0
	48		DEC EAX
\end{lstlisting}

In this simple example the first instruction is a 2-byte \textit{jmp -1} instruction (\textbf{EB FF}). Its target is the its own second byte. At run time this causes no errors because the \textbf{FF} byte is the first byte of the next instruction \textit{inc eax} (\textbf{FF C0}).

However, when disassembling, if the disassembler interprets the \textbf{FF} byte as part of the \textit{jmp} instruction, it won't be able to interpret it also as the beginning of the \textit{inc eax} instruction. While the \textbf{FF} byte is in reality part of both instructions that actually execute, the disassembler is not able to recognise this.

The 4-byte example code increments the \textbf{EAX} register, and then decrements it, therefore it is essentially a complex \textbf{NOP} sequence. Being a simple, and small, sequence it could be inserted at any location in a program code in order to fool disassemblers. However this sequence it is also easily recognisable by reverse engineers and substituted with \textbf{NOP} instructions using IDA Pro or other instruments and/or scripts. Another alternative is to interpret this sequence as data bytes forcing the disassembler to skip it.

However this was only a simple example sequence. More complex and ingenious sequences can be made to fool disassemblers while being harder to detect.

\subsubsection{Obscuring Flow Control}
Control-flow analysis (CFA) is a static-code-analysis technique for determining the control flow of a program. Modern disassemblers like IDA Pro are able to correlate function calls and extract high-level information about the program knowing how functions are related to each other \cite{SikorskiPMA}.

Control-flow analysis can however be easily defeated by malware authors.

\paragraph{The Function Pointer Problem}
Function pointers are a common programming idiom present in programming languages such as \textbf{C}, while being extensively used in the background in object oriented languages like \textbf{C++} and \textbf{Java} \cite{SikorskiPMA}.

As opposed to referencing a data value, a function pointer points to executable code within memory. Dereferencing the function pointer yields the referenced function, which can be invoked and passed arguments to as in a normal function call. Since, doing so, the function is being invoked indirectly through a variable instead of directly through a fixed identifier or address, such invocation is also known as an "indirect" call. In assembly code this corresponds to a \textit{call} instruction with a function pointer as argument.

Function pointers, however, greatly reduce the information that can be automatically extracted by the disassembler about the program control flow. Moreover, if function pointers are used in specially crafted, or non-standard code, the resulting code can be difficult to reverse-engineer without the use of dynamic analysis techniques.

As a result, function pointers, in combination with other anti-disassembly techniques, can greatly increase the complexity and difficulty of reverse-engineering.

\paragraph{Return Pointer Abuse}
Among the instructions capable of transferring control within a program we already mentioned the \textit{call} and \textit{jmp} instructions, however there are more \cite{SikorskiPMA}.

The counterpart to the \textit{call} instruction is \textit{retn}. When a call instruction is reached during program execution, a return pointer is pushed on the stack, before jumping to the call instruction target. This return pointer in the stack will point to the address of the instruction immediately following the end of the \textit{call} instruction itself.
Therefore a \textit{call} instruction can be seen as the combination of a \textit{jmp} and \textit{push}; a \textit{retn} instruction, on the other hand, is the combination of \textit{pop} and \textit{jmp}.

The \textit{retn} instruction pops the last value pushed to the stack and jumps to it; it is therefore typically used to return from a function call, but it could also be used for other purposes. When used for such other reasons the disassembler is generally fooled, because it still will interpret it as a return from a function call. Therefore it won't show any code cross-reference to the target being jumped to. As added benefit the disassembler will also prematurely terminate the function being analysed.

\paragraph{Misusing Structured Exception Handlers}\label{MisusingStructuredExceptionHandlers}
Another powerful anti-disassembly technique exploits the Structured Exception Handling (\textbf{SEH}) mechanism. Performing program flow control using this mechanism is able to fool both disassemblers and debuggers \cite{SikorskiPMA}.

\textbf{SEH} provides programs a way to handle error conditions intelligently. \textit{C++} and other programming languages heavily rely on exception handling (and therefore on \textbf{SEH}) when compiled for x86 systems.

Exceptions can be triggered for numerous reasons: for example when dividing by zero or accessing an invalid memory region. Moreover, software exception can also be raised by the code itself by calling the \textit{RaiseException} function.

When an exception is raised it makes its way through the \textbf{SEH} chain, which is a list of functions specifically designed to handle exception, until it is caught by one exception handler in the chain. Each function in the list can either handle the exception (a.k.a. \textit{catch} it) or pass it to the next handler in the list. \textit{Unhandled exceptions} are the ones that make their way to the last handler. The last exception handler is the code responsible for triggering the 'unhandled exception' message to the user. 

Exception handling is used in almost all programs and exceptions happen regularly in most processes (and are handled silently). A malicious actor could, however, exploit this mechanism to achieve covert flow control by adding his own specially crafted handler on top of the \textbf{SEH} chain.

This can be done at runtime simply pushing some specific values on the stack, effectively adding a new entry in the Exception handling chain. This procedure, however, is subject to the constraints imposed by the Software Data Execution Prevention (\textbf{Software DEP}), which is a security feature that prevents the addition of third-party exception handlers at runtime. However various workarounds to this protection can be used in the case of handwritten assembly code.

\subsection{Anti-debugging}
Another popular anti-analysis technique, besides anti-disassembly, is \textit{anti-debugging}. Malware authors use anti-debugging techniques to recognise when their malicious program is under the control of a debugger or to interfere with the debugger behaviour. This is done in an attempt to slow down the malware analysts who use debuggers to understand how the malware operates. A malware using these techniques usually alter its normal control flow paths or causes crashes if it detects it is running in a debugger, thus interfering with analysis \cite{SikorskiPMA}.

\subsubsection{Windows Debugger Detection}
In Windows OS various techniques can be used to detect if a process is being run in a debugger: from exploiting the Windows API itself, to manually checking memory structures for debugging artefacts \cite{SikorskiPMA}.


\paragraph{Using the Windows API}
One of the most obvious, and simple, ways to know if a debugger is attached to a process is by using Windows API functions. Inside the Windows API there are, in fact, functions that were specifically designed to detect debuggers; moreover some functions that were originally created with other purposes can also be used for debugger detection \cite{SikorskiPMA}.

Malware analysts can counter this technique by manually modifying the malware code during execution modifying the resulting flag after the call to make sure the desired path is taken, or by straight up removing/skipping the function call.

Here are some examples of common Windows API functions used for \textit{anti-debugging}:
\begin{itemize}
	\item \textbf{IsDebuggerPresent}
	This is the simplest API function that can be used for debugger detection. It determines whether the \textbf{current} process is being debugged by a user-mode debugger. It does so by getting the value of the field \textit{IsDebugged} from the Process Environment Block (\textbf{PEB}) structure. In particular this functions returns zero if the process is not running within a debugger context and a non-zero value otherwise.
	
	\item \textbf{CheckRemoteDebuggerPresent}
	This API function is similar to the previously described one (\textit{IsDebuggerPresent}). This function checks for a 'remote' debugger on the specified process. The term 'remote' in the name CheckRemoteDebuggerPresent does not imply that the debugger necessarily resides on a different machine; instead, it indicates that the debugger resides in a separate and parallel process. This function takes a process handle as argument, and will check if that process has a debugger attached. It can however be used also to check the current process by passing its handle.
	
	\item \textbf{NtQueryInformationProcess}
	This function can retrieve different kinds of information from a process. The first argument for this function is the process handle, the second one is the ProcessInformationClass parameter which specifies the information you want to get. When using the value \textit{ProcessDebugPort} for this parameter, for example, the function will return a zero if the process is not currently being debugged; a non-zero value representing the debugger port number will instead be returned otherwise.
	
	\item \textbf{OutputDebugString}
	This function, originally designed to just send a string to a debugger for display, can be used to detect the presence of a debugger. In fact, in there is no debugger attached, the function will internally set the last-error code. In a few lines of code it is thus possible to know if a debugger is present or not:
	
	\begin{lstlisting}[caption={OutputDebugString debugger detection}, label=OutputDebugString, language=C, style=mystyle]
	DWORD errorValue = 12345;
	// set custom last error code
	SetLastError(errorValue);
	
	// try outputting string on debugger;
	// if no debugger is present, it will set
	// the last-error code to a new value
	OutputDebugString("Test for Debugger");
	
	if(GetLastError() == errorValue){
		// a debugger is present
		ExitProcess();
	}
	else{
		// no debugger was detected
		RunMaliciousPayload();
	}
	\end{lstlisting}
	
\end{itemize}

\paragraph{Manually Checking Structures}
Malware authors usually don't exploit the Windows API functions for detecting the presence of a debugger, but they prefer checking the PEB structure (and others) by themselves. One of the reasons why they usually don't like using Windows API functions is that API calls can be easily hooked by a rootkit to return false information, thus thwarting this technique \cite{SikorskiPMA}.

\begin{itemize}
	\item \textbf{Checking the BeingDebugged Flag}
	The Windows PEB structure contains all user-mode parameters associated with a process, including the process's environment data such as environment variables, addresses in memory and debugger status, among other things.
	
	Malware can 'manually' check the \textit{BeingDebugged} flag within the PEB structure to understand if a debugger is attached its process. More precisely if this flag is zero it means that no debugger is attached.
	
	Example of code listing performing 'manual' \textit{BeingDebugged} check:
	\begin{lstlisting}[caption={BeingDebugged manual check}, label=BeingDebuggedManual, language={[x86masm]Assembler}, style=mystyle]
	mov		eax,	dword ptr fs:[30h]	; get PEB address
	mov		ebx,	byte ptr [eax+2]		; get BeingDebugged flag value
	test	ebx,	ebx									; test if the value is 0
	jz		NoDebuggerDetected				; if 0, no debugger was detected
	\end{lstlisting}
	
	Malware analysts can counter this technique detecting this code sequence in the code and then wither manually changing the \textit{BeingDebugged} flag to zero, or forcing the jump to be taken (or not) by manually modifying the zero flag before the jump instruction.
	
	\item \textbf{Checking the ProcessHeap Flag} 
	The \textit{ProcessHeap}, which is an undocumented location within a reserved array inside the PEB structure, contains the location of the first heap of a process allocated by the loader. This heap can be used for debugger detection since it contains some information telling if it was created within a debugger or not. In particular malware usually check the values of the fields called \textit{ForceFlags} and \textit{Flags}.
	
	To overcome this technique, malware analysts can change the \textit{ProcessHeap} flags manually or use a hide-debug plug-in for their debugger.
	
	\item \textbf{Checking NTGlobalFlag}
	Processes started within a debugger run slightly differently than others, therefore they create memory heaps differently. The information needed to determine how to create heap structures is stored at an undocumented location in the PEB. Practically, a value of \textit{0x70} at this location indicates that the process is running within a debugger.
	
	Again, in order to counter this technique, malware analysts can change the flags manually or use a hide-debug plug-in for their debugger.
	
\end{itemize}

\paragraph{Checking for System Residue}
Debugging tools typically leave traces of their presence on the system. Malicious programs can therefore be designed to search for these traces in the system in order to determine when it is being analysed. For example malware can search for references to debuggers in the registry keys \cite{SikorskiPMA}.

Moreover, malware can also be designed to search the system for files and directories commonly related to debuggers, such as debugger program executables.

Furthermore, malware can also detect debugger residues in live memory, by viewing the current process listing or, more commonly, by performing a \textit{FindWindow} in search for a debugger.

\subsubsection{Identifying Debugger Behaviour}
Debuggers are very useful to malware analysts because they can be used to set breakpoints in the code or even to single-step through a process running code to ease the reverse-engineering process. These operations, however, modify the process code and are therefore easily detectable \cite{SikorskiPMA}.

\paragraph{INT Scanning}
A common anti-debugging technique used by malware authors consists in making the process scan its own code in search for an \textbf{INT 3} (opcode \textit{0xCC}). \textbf{INT 3} is, in fact, a software interrupt used by debuggers: when setting a breakpoint the debugger replaces the target instruction in the running program with the opcode \textit{0xCC} (INT 3) which causes the process to call the debug exception handler \cite{SikorskiPMA}.

Malware analysts can counter this technique exploiting hardware breakpoints instead of software ones.

\paragraph{Performing Code Checksums}
Another anti-debugger technique consists in calculating the checksum of a section of the process' own code. This has the same net effects as scanning the code for software interrupts. However, instead of explicitly searching for a specific opcode (\textit{0xCC}) in the process code, this check performs a cyclic redundancy check (CRC) or a MD5 checksum of the malware code \cite{SikorskiPMA}.

Again this technique can be countered by using hardware breakpoints instead of software ones, or by modifying the program's control flow at runtime with a debugger.

\paragraph{Timing Checks}
One of the most widespread techniques for debugger detection is to perform \textit{timing checks}. Processes, in fact, tend to run substantially slower when executed within a debugger context. Moreover analysts usually run programs in single steps in order to better understand the code behaviour, this in turn greatly increases execution time \cite{SikorskiPMA}.

Using timing checks it is possible to detect a debugger in different ways:
\begin{enumerate}
	\item Recording 2 timestamps before and after the execution of some operations and then comparing them. If the lag is greater than a specified threshold then a debugger is probably being used.
	\item Recording 2 timestamps before and after raising an exception. If the current process is being debugged then the exception will be handled by the debugger itself more slowly than normal. Moreover, by default, debuggers ask for human intervention when an exception occurs, thus causing huge delays.
\end{enumerate}

\begin{itemize}
	\item \textbf{Using the \textit{rdtsc} Instruction}
	The most common timing check method uses the \textit{rdtsc} instruction. This instruction returns the number of ticks since the last system reboot. Malware authors thus use it as described above: rdtsc is called twice, once before and once after some other operations, and then the difference between the results is calculated. If too much time has elapsed between the two calls it means that a debugger is probably being used.
	
	\item \textbf{Using \textit{QueryPerformanceCounter} and \textit{GetTickCount}}
	These are two Windows API functions that can be used similarly to \textit{rdtsc} for debugger detection.
	
	More precisely \textit{QueryPerformanceCounter} can be called to query a high-resolution counter available to processors which stores counts of activities performed by the processor.
	
	The function \textit{GetTickCounter}, on the other hand, returns the number of milliseconds that have elapsed since the last reboot, very similarly to what the \textit{rdtsc} instruction does.
	
	Both of those functions, when used as described above, allow the malware to detect the presence of a debugger.
\end{itemize}

Anti-debugging though the use of timing checks can be discovered by malware analysts during debugging or static analysis by identifying specific sequences of instructions. Moreover, these checks usually detect debuggers only when the analyst is single-stepping though the code or setting a breakpoint between the two time related instruction calls.
This implies that, to counter this technique, malware analysts could avoid setting breakpoints and single-stepping in those regions of code, or modify the result of the timestamps comparison as needed.

\subsection{Anti-virtual machine}
Malware analysts often use virtual machines (VMs) or other isolated environments like sandboxes, to analyse malware samples. With the purpose of evading analysis and bypassing security systems malware authors often design their code to detect isolated environments. The techniques used with such purpose are called \textit{Anti-virtual machine} techniques (Anti-VM). Once a virtual machine is detected the evasion mechanism may alter the malware?s behaviour, or it may even prevent the malicious code from running altogether \cite{SikorskiPMA}.

\subsubsection{VMware Artefacts}
Virtual machines are designed to emulate real hardware functionality. To achieve that, however, some artefacts inevitably remain on the system, which can reveal that a virtual machine is indeed being used. These kind of artefacts can be specific files, processes, registry keys, services, network device adapters etc. \cite{SikorskiPMA}.

Here are some examples of anti-virtual machine techniques applied to detect VMware virtualization software:
\begin{itemize}
	\item \textbf{Checking for Processes Indicating a VM}.
	When a VMware virtual machine is running and VMware tools is installed, three VMware-related processes can be found in the system process listing: \textit{VMwareService.exe}, \textit{VMwareTray.exe} and \textit{VMwareUser.exe}. A malicious software can therefore easily detect if VMware is being run searching through the process listing for the \textit{VMware} string.
	
	\item \textbf{Checking for Existence of Files Indicating a VM}.
	The VMware default installation path usually also contains artefacts. Searching for the string \textit{VMware} in such location may reveal the use of a virtualized environment.
	
	\item \textbf{Checking for Registry Keys}.
	VMware Tools may leave some artefacts also in the registry. More specifically the presence of specific registry entries may reveal the use of VMware.
	
	\item \textbf{Checking for Known Mac Addresses}.
	In order to connect a virtual machine to a network it needs to have its own virtual network interface card (NIC). This implies that VMware needs to create a MAC address for the virtual machine, to associate to its NIC. However, depending on VMware configuration, this may lead to the network adapter being able to identify VMware usage. VMware utilises, in fact, addresses with a specific starting sequence which depends on its current version. Therefore a malicious software just needs to check the system MAC address against common VMware values.
\end{itemize}

In order to counter anti-virtual machine techniques, malware analysts need to apply a two step process: identify the check for VMware artefacts and then 'manually' patch it. For example, depending on the anti-VM technique used, they may patch the malware code while debugging to artificially make all checks pass, or modify the name of VMware processes in order to make them undetectable by the malicious software.

\subsubsection{Vulnerable Instructions}
The virtual machine monitor program, which monitors the virtual machine execution, has some security weaknesses that may allow malware to detect its usage. In particular, in order to avoid performance issues deriving from fully emulating all instructions, VMware allows certain instructions to execute without being properly virtualized. This in turn means that certain instruction sequences may return different results when running within a VMware virtualized environment than they do on native hardware. This discrepancy can be used by malware authors to detect VMware usage \cite{SikorskiPMA}.

However, those instructions previously mentioned are not typically used within a malicious program unless it is specifically performing VMware detection, because they are useless if executed in user mode. Therefore avoiding this type of anti-VM technique can be as easy as patching the malicious code to prevent it calling these instructions.

\subsection{Packers and unpacking}
Packing programs, commonly known as \textit{packers}, are software programs that take an \textit{executable file} or \textit{dynamic link library (DLL)}, compresses and/or encrypts its contents and then packs it into a new executable file \cite{SikorskiPMA}.

When packers are used on malicious programs, the malicious code appearance is changed as a consequence of the compression and/or encryption. The packed file will thus hinder basic static analysis and malware detection. Moreover, a packer specifically designed to make the file difficult to analyse may even employ anti-reverse-engineering techniques, such as anti-disassembly, anti-debugging or anti-VM on the resulting compressed version; on top of that some packers, using randomization, are also able to generate different variants of a single file every time it is packed \cite{LiPRTCMP}.

Malware authors have thus increasingly been using these tools to hide their creations from anti-malware solutions and malware analysts. In order to analyse packed malware, in fact, it must be unpacked first. Properly unpacking a packed program generally is, however, not easy.

A packed file usually contains two basic components:
\begin{itemize}
	\item A number of data blocks containing the compressed and/or encrypted original executable file.
	
	\item An unpacking stub able to dynamically recover the original executable file at runtime.
\end{itemize}

When the packed file is executed, the unpacking stub is loaded by the OS and begins unpacking the original executable code in memory. When the unpacking has been fully completed the control flow is transferred, with a \textit{jmp}, \textit{call} or the more stealthy \textit{retn} instruction (also referred to as the \textit{tail jump}), to the original file entry point (OEP). This implies that someone attempting to perform static analysis on the packed program, would actually analyse the unpacking stub and not the original code.

\subsubsection{Packer types}
Commercial and custom made packers can be divided in several levels of complexity depending on the packing techniques used and the additional features they have.
The authors of \cite{PedreroDPI} identified 6 packer main types with increasing complexity.
Packer types from 1 to 5 allow, sooner or later at runtime, to have a complete view over the original (unpacked) malicious code, meaning that the unpacker stub unpacks all the code at once. However, what makes them differ is the amount and complexity of the encryption (and obfuscation) methodologies used during packing. On the other hand, type 6 packers unpack only a slice of code at a time in memory, never revealing the whole original code altogether. This implies that malware analysts need to take several memory dumps, instead of only one, if they want to get the complete unpacked code.

Another possible classification of packers can be made based on their purposes and behaviours. Following this idea packers can be broadly classified into four categories \cite{WeiRPM}:

\begin{itemize}
	\item \textbf{Compressors} utilise compression to shrink files while exploiting few or no anti-unpacking tricks. Popular compressors include the Ultimate PE Packer (UPack), Ultimate Packer for Executables (\href{https://upx.github.io/}{UPX}), and \href{http://www.aspack.com/}{ASPack}.
	
	\item \textbf{Crypters} encrypt and obfuscate the original file contents. No compression is usually done. Malware developers widely use crypters such as \href{https://sourceforge.net/projects/yodap/}{Yoda's Crypter} and PolyCrypt PE.
	
	\item \textbf{Protectors} combine features from both compressors and crypters. Some popular commercial protectors are Armadillo and \href{https://www.oreans.com/Themida.php}{Themida}.
	
	\item \textbf{Bundlers} are used to pack a software package of multiple executable files into a single bundled executable file. These files within the package can then be unpacked and accessed without extracting them to disk. Some common PE bundlers are \href{https://www.bitsum.com/pebundle.asp}{PEBundle} and \href{https://www.molebox.com}{MoleBox}.
\end{itemize}

\subsubsection{Packers detection}
Packed executables can be detected through a heuristic approach known as \textit{Shannon Entropy Calculation}. Entropy is, generally speaking, a measure of uncertainty, disorder, in a system or program. The idea behind this approach is that compressed or encrypted executables tend to resemble random data, thus they have higher entropy than unencrypted/uncompressed programs. This approach, however, does not tell any information about the packer used to obtain the packed sample \cite{SikorskiPMA}.

One common way to tackle this problem is through packer signatures checking. Tools like \href{https://www.aldeid.com/wiki/PEiD}{PEiD} and Sigbuster use such method. These tools are, however, not always successful due to the huge number of packer variations and evolutions present in the wild, and the fact that malware authors frequently modify commercially available packers code or create their own packers so that their packed malicious programs do not match any known signature.

\subsubsection{Unpacking}
Unpacking is the process of restoring the original contents from packed executables in order to allow AV programs and security researchers to analyse the original executable code. There are three different techniques to unpack a packed executable: \textit{automated static unpacking}, \textit{automated dynamic unpacking} and \textit{manual unpacking} (\cite{SikorskiPMA}, \cite{WeiRPM}).

Automated static unpacking programs are dedicated routines designed to decompress and/or decrypt executables packed by specific packers, without actually executing the suspicious programs. This method, when it works, is the fastest and most secure method to unpack an executable. Automatic static unpackers are, however, specific to a single packer. Moreover, they are not able to unpack packed samples that were created with the intention to hinder analysis.

Automated dynamic unpackers, instead, use programs to run or emulate the packed executable allowing the unpacking stub to unpack the original executable code in memory. Once the original executable is unpacked, the in-memory program's code is written on disk, and the automated unpacker reconstructs the original import table.

Most often security researchers prefer to perform manual unpacking. The two most common approaches used  to manually unpack a program are:
\begin{itemize}
	\item Discover what packing algorithm has been used to pack a sample and then write a program/script to revert it. This process is however time consuming.
	
	\item Manually run the packed program to allow the unpacking stub to unpack the original code in memory, then dump the process on disk and finally manually modify the PE header so that the program is complete. This process is more efficient than the previous one. 
\end{itemize}

\subsection{Code Obfuscation}
Obfuscation is a technique that generally makes programs harder to understand \cite{Balakrishnan2005CodeOL}, both for humans and automatic tools. To do so, it transforms a program into a new (structurally different) and more difficult to analyse version while retaining the same functionality as the original (the new version of the program is said to be \textit{computationally equivalent} to the original one) \cite{YouMOT}.

Originally, this technology was conceived for legitimate purposes to protect the intellectual property of software developers; however it has been widely exploited by malware authors to evade detection \cite{KonstantinouMV}. Particularly, in order to elude anti-malware scanners, malware can, using obfuscation techniques, evolve their body into new generations \cite{YouMalwareOT}, which eventually can be even harder to disassemble and analyse.

Obfuscation techniques can be broadly divided into 2 main sub-categories:
\begin{itemize}
	\item \textit{Data-based} obfuscation
	\item \textit{Control-based} obfuscation
\end{itemize}

However, malware authors usually combine those 2 types of obfuscation techniques in complex and difficult ways to strengthen the resulting obfuscation \cite{DangPRE}.

\subsubsection{Data-Based Obfuscation}
Data-based obfuscation techniques focus on modifying data values and non-control computations. In the following paragraphs some common data-based obfuscation techniques will be discussed.

\paragraph{Constant Unfolding}
\textit{Constant folding} is a technique commonly used by compilers to optimize a program's code. It does so by replacing expressions with results known at compile time with the results themselves \cite{DangPRE}.

For example, a compiler usually transforms the following expression \ref{ConstantFoldingBefore}, into \ref{ConstantFoldingAfter}.
\begin{lstlisting}[caption={Before constant folding}, label=ConstantFoldingBefore, language=C, style=mystyle]
	x = 4 * 5;
\end{lstlisting}

\begin{lstlisting}[caption={After constant folding}, label=ConstantFoldingAfter, language=C, style=mystyle]
	x = 20;
\end{lstlisting}

\textit{Constant unfolding} is, instead, an obfuscation technique that performs the exact inverse operation: it replaces the constants in the program's code with some expressions having the constant as a result.

For example, the listing \ref{ConstantUnfoldingBefore}, after \textit{Constant unfolding} may become \ref{ConstantUnfoldingAfter}. The two listings are equivalent. Moreover, there is an infinite amount of listings equivalent to \ref{ConstantUnfoldingBefore} that can be generated following this principle.
\begin{lstlisting}[caption={Before constant unfolding}, label=ConstantUnfoldingBefore, language={[x86masm]Assembler}, style=mystyle]
	push	0h
\end{lstlisting}

\begin{lstlisting}[caption={After constant unfolding}, label=ConstantUnfoldingAfter, language={[x86masm]Assembler}, style=mystyle]
	push	0F9CBE47Ah
	add		dword ptr [esp],	6341B86h
\end{lstlisting}

\paragraph{Data-Encoding Schemes}
The previously described technique is, however, easily defeated by simply applying the standard compiler's constant folding optimization. This is possible because both the data encoding and decoding functions ($f(x)=x-6341B86h$ and $f_{-1}(x)=x+6341B86h$ respectively) were present in the code one after the other. The use of \textit{fully Homomorphic} mappings (operation-preserving mappings) allow us to perform some operations on the encoded data before decoding it back, thus overcoming the previous technique's flaw. \textit{Fully Homomorphic} mappings are however still not widely used because still too inefficient \cite{DangPRE}.

\paragraph{Dead Code Insertion}
\textit{Dead code elimination} is another common compiler optimization technique. Its objective is to remove program statements/expressions that nave no real effects on the program operation and final results \cite{DangPRE}.

For example, the listing \ref{DeadCodeEliminationBefore}, using \textit{dead code elimination} would become \ref{DeadCodeEliminationAfter}.
\begin{lstlisting}[caption={Before dead code elimination}, label=DeadCodeEliminationBefore, language=C, style=mystyle]
	int f(){
		int x, y;
		x = 1;		// this assignement is useless, here x is dead
		y = 2;		// y is never used, it is thus dead.
		x = 3;
		return x;	// x is live
	}
\end{lstlisting}

\begin{lstlisting}[caption={After dead code elimination}, label=DeadCodeEliminationAfter, language=C, style=mystyle]
	int f(){
		return 3;
	}
\end{lstlisting}

Obfuscators, on the other hand, use the so-called \textit{dead code insertion} technique in an attempt to make the code harder to follow. This technique performs the inverse operation with respect to \textit{dead code elimination}, adding dead code in the original program's code.

However, when used alone, this techniques produces an obfuscated program that can be efficiently de-obfuscated by using the compiler's dead code elimination optimization.

\paragraph{Arithmetic Substitution via Identities}
This technique aims at replacing certain operators with combinations of other operators with equal net result. Exploiting the equivalence between different combinations of different operators the code can be changed arbitrarily without changing the effective program operation and final result \cite{DangPRE}. Here are some examples of operators equivalences:

\begin{lstlisting}[caption={Operators equivalences}, label=OperatorEquivalences, language=C, style=mystyle]
	-x == ~x + 1
	
	x-1 == ~-x
	
	x+1 == -~x
	
	rotate_left(x,y) == (x << y) | (x >> (bits(x) - y))
	
	rotate_right(x,y) == (x >> y) | (x << (bits(x) - y))
\end{lstlisting}

\paragraph{Register Reassignment}
Another simple obfuscation technique is called \textit{register reassignment}. An obfuscator using this technique switches the registers used throughout the code at every application, while keeping the same program code and behaviour \cite{YouMalwareOT}.

An analyst/attacker using wildcard searching, however, easily defeats this technique.

\paragraph{Instruction Substitution}
\textit{Instruction substitution} creates variants of a program's original code by replacing some instructions with other equivalent ones \cite{YouMalwareOT}.

\paragraph{Pattern-Based Obfuscation}
\textit{Pattern-based} obfuscation is another commonly used technique similar in principle to \textit{instruction substitution}, but more complex. It consists in constructing \textit{patterns} (transformations) that map single or multiple adjacent instructions into a more complex, computationally equivalent, sequence of instructions \cite{DangPRE}.

For example, the sequence \ref{PatternObfuscationOriginalSequence} might be converted into \ref{PatternObfuscationPattern1}, as well as into \ref{PatternObfuscationPattern2} or even \ref{PatternObfuscationPattern3}.

\begin{lstlisting}[caption={Original sequence}, label=PatternObfuscationOriginalSequence, language={[x86masm]Assembler}, style=mystyle]
	push	reg32
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation using pattern 1}, label=PatternObfuscationPattern1, language={[x86masm]Assembler}, style=mystyle]
	push	imm32
	mov		dword ptr [esp],	reg32
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation using pattern 2}, label=PatternObfuscationPattern2, language={[x86masm]Assembler}, style=mystyle]
	lea		esp,	[esp-4]
	mov		dword ptr [esp],	reg32
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation using pattern 3}, label=PatternObfuscationPattern3, language={[x86masm]Assembler}, style=mystyle]
	sub		esp,	4
	mov		dword ptr [esp],	reg32
\end{lstlisting}

Moreover, patterns can be arbitrarily complicated. For example a listing such as \ref{PatternObfuscationOriginalSequence2}, could be substituted by the more complex \ref{PatternObfuscation2Pattern}.

\begin{lstlisting}[caption={Original sequence \#2}, label=PatternObfuscationOriginalSequence2, language={[x86masm]Assembler}, style=mystyle]
	sub		esp,	4
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation of sequence \#2}, label=PatternObfuscation2Pattern, language={[x86masm]Assembler}, style=mystyle]
	push	reg32
	mov		reg32,	esp
	xchg	[esp],	reg32
	pop		esp
\end{lstlisting}

Malware authors (and also software developers wishing to protect their intellectual property) can use hundreds of patterns in the same program. Moreover, most protections randomly apply patterns so that obfuscating the same program multiple times yields different results. On top of that, patterns can also be applied iteratively: after transforming the original code \textbf{C} into \textbf{C'} using pattern \textbf{P}, another pattern \textbf{P'} can be applied to \textbf{C'} in order to obtain \textbf{C''}, and so on.

Some patterns preserve \textit{semantic equivalence}, meaning that the CPU state will be the same when executing them or the original code. Some other patterns, however, do not. Therefore, depending on the code logic, some substitutions are safe (meaning that the program behaviour and final results are preserved) while others are not. This makes the job of an obfuscator challenging.

\subsubsection{Control-Based Obfuscation}
Standard static analysis tools generally make assumptions similar to the ones human reverse engineers make when analysing code. Compilers, in fact, predictably translate control flow constructs and data structures. As a result, reverse engineers (and static analysis tools) can easily recognise the original code high level control flow. \textit{Control-based obfuscation} transforms the code control flow structures in non standard ways in order to complicate both static and dynamic code analysis \cite{DangPRE}.

Some examples of stanrard static analysis tools assumptions are:
\begin{itemize}
	\item The \textit{CALL} instruction is always used with the sole purpose of invoking functions.
	
	\item Both sides of a conditional branch may feasibly be taken at runtime.
	
	\item Function calls almost always return.
	
	\item All control transfers target code locations, not data locations.
	
	\item Exceptions are used in standard and predictable ways.
	
	\item etc..
\end{itemize}

By violating these assumptions, \textit{control-based obfuscation} techniques confuse disassemblers and other static analysis tools making the analysis more difficult.

\paragraph{Functions In/Out-Lining}
Reverse engineers frequently rely on control-flow and call graphs to better understand a program's high-level logic. In particular a call graph represents calling relationships between subroutines (functions) in a computer program. Each node of a call graph represents a procedure and each edge (\textbf{f}, \textbf{g}) indicates that procedure \textbf{f} calls procedure \textbf{g}. By making the call graph harder interpret, obfuscators can hinder the reverse engineers capability of understanding the program behaviour \cite{DangPRE}. To do so one could:

\begin{itemize}
	\item \textbf{Inline functions}.
	The code belonging to a subfunction is merged into the code of its caller. If a subfunction is called multiple times, however, the code size can quickly grow.
	
	\item \textbf{Outline functions}.
	A subpart of a function is extracted and transformed into an independent function and replaced by a call to the newly created function.
\end{itemize}

Using these two operations in combination on a program's code results in a degenerated call graph with no clear logic. Moreover, also the functions' prototypes can be modified adding extra fake arguments, reordering arguments and so on, to further hide the high-level logic.

\paragraph{Destruction of Sequential and Temporal Locality}
Usually, in non-obfuscated code, the instructions of a single basic block lie one after the other (\textit{sequential locality}), and basic blocks related to one another (such as successive blocks) are close to each other (\textit{sequential locality of temporally related code}). This is done in order to maximize the instruction cache locality and reduce the number of branches in the final code. Reverse engineers thus can usually rely on the fact that all the code responsible for a specific operation will reside in a single region \cite{DangPRE}.

Violating this assumption introducing unconditional branches that break sequential locality and temporal locality of multiple basic blocks makes manual analysis more difficult. However, by constructing the control-flow graph and removing spurious unconditional branches the original control flow can be restored.

\paragraph{Processor-Based Control Indirection}
Instructions like \textit{JMP} (branch) and \textit{CALL} (save instruction pointer and branch) are, for most processors, the 2 essential control flow transfer primitives. In order to make analysis more difficult, one could obfuscate these primitives for example using dynamically computed branch addresses or by emulating them.

For example the instruction \textit{JMP} instruction \ref{ProcessorBasedControlIndirectionBefore}, can be replaced by the (almost) semantically equivalent listing \ref{ProcessorBasedControlIndirectionAfter}.

\begin{lstlisting}[caption={Processor-based control indirection before}, label=ProcessorBasedControlIndirectionBefore, language={[x86masm]Assembler}, style=mystyle]
	jmp		target_addr
\end{lstlisting}

\begin{lstlisting}[caption={Processor-based control indirection after}, label=ProcessorBasedControlIndirectionAfter, language={[x86masm]Assembler}, style=mystyle]
	push	target_addr
	ret
\end{lstlisting}

\paragraph{Operating System-Based Control Indirection}
As already seed when talking about anti-disassembler techniques, obfuscation can also exploit operating system primitives and structures. For example, the Structured Exception Handler (\textit{SEH}), Vectored Exception Handler (\textit{VEH}) and Unhandled Exception Handler are commonly used to obfuscate the control flow of Microsoft Windows executables (in Unix-like systems the signal handlers \textit{setjmp} and \textit{longjmp} are commonly used instead) \cite{DangPRE}.

\paragraph{Subroutine Reordering}
\textit{Subroutine reordering} in an obfuscation technique that randomly changes the order of a program's subroutines in the original code. This technique can thus generate $n!$ code variations, where $n$ is the number of subroutines \cite{YouMalwareOT}.

\paragraph{Opaque Predicated}
An \textit{opaque predicate} is a non-trivial boolean expressions with a constant result (always true or always false) known only at compilation/obfuscation time. Combining it with a conditional \textit{jmp} instruction introduces an additional branch in the control flow graph (\textit{CFG}). We already briefly talked about this specific combination when talking about the \textit{Jump instruction with a constant condition} anti-disassembly technique. The added branch should look as real as possible in order to elude detection, and it can be used to insert junk code or to form cycles in the control-flow graph to better hide the original program's logic \cite{DangPRE}.

\subsubsection{Simultaneous Control-Flow and Data-Flow Obfuscation}
\textit{Data-flow obfuscation} and \textit{Control-flow obfuscation} techniques are commonly used together to complicate analysis.

\paragraph{Inserting Junk Code}
This technique consists in introducing a dead code block (meaning that it will never be executed at runtime) between two other code blocks. Typically used in conjunction with \textit{opaque predicates}, this technique is used to hinder a disassembler that is disassembling an invalid path. Moreover, the junk code typically contains partially invalid instructions, or branches to invalid addresses with the objective of over-complicating the CFG \cite{DangPRE}.

\begin{lstlisting}[caption={Junk Code example}, label=JunkCodeExample, language={[x86masm]Assembler}, style=mystyle]
	push	eax
	xor		eax,	eax
	jz		9
	;<junk code start>
	jg		4
	inc		esp
	ret
	;<junk code end>
	pop		eax
\end{lstlisting}

The listing \ref{JunkCodeExample} presents an example of this technique. More precisely the instruction at line 2 (\textit{xor eax, eax}) zeroes the \textit{EAX} register setting clearing the zero flag (it is set to 0); therefore the conditional jump (\textit{jz 9}) at line 3 is always taken at runtime. The immediately next instructions are therefore junk code.

\paragraph{Control-Flow Graph Flattening}
\textit{Control-flow graph flattening} consists in replacing all control structures within a sub-part of the control flow graph with a single switch statement commonly called \textit{dispatcher}. This is done to hide the true basic blocks relationships within the dispatcher. When using this technique, first a subpart of the program's control flow graph is selected to be substituted by the dispatcher. Some transformations may then be applied to the basic blocks inside the chosen sub-graph (they split or merged) to further complicate analysis and finally each basic block updates the dispatcher's context to reflect the relative basic block relationships. The final resulting graph offers no clues about the structure of the algorithm, but has the same logic \cite{DangPRE}.

\textit{CFG flattening} is frequently used, together with \textit{opaque predicates}, to insert dead code paths in the CFG.

\paragraph{Code Transposition}
An obfuscator using the technique called \textit{code transposition} effectively reorders the sequence of a program's original code instructions without changing its behaviour \cite{YouMalwareOT}. To achieve this two approaches are commonly followed:
\begin{itemize}
	\item Randomly shuffling the instruction and then recovering the original execution order by inserting unconditional branches. This is easily defeated restoring the original program by removing (and following) the unconditional branches.
	
	\item Choosing and reordering independent instructions that have no impact on the others. This approach is harder to implement given the complexity of finding independent instructions, but it is more effective.
\end{itemize}

\paragraph{Code Virtualization}
\textit{Code virtualization} consists in transforming a program's binary code (compiled for a specific machine) into a different binary code that is understood by a virtual machine. More specifically, the instruction set from the source machine is converted into a new instruction set, understood by the target virtual machine. This can be done using multiple types of virtual machines with different instruction sets. This means that a specific block of, for example, Intel x86 instructions can be converted into a different instruction set for each machine, preventing an analyst/attacker from recognizing any generated virtual opcode after the transformation from x86 instructions \cite{DangPRE}. 

Usually, some specific blocks of the program's code are virtualized (and not the whole program) and inserted back into the program alongside the associated interpreter. At run time, the interpreter assumes execution control and translates the virtualized code back to the original byte code.

When an analyst/attacker tries to decompile a virtualized block of code, however, he will not find the original x86 instructions. Instead, he will find a completely new instruction set which is not recognized by him or any other special decompiler. This will force the attacker to identify how each opcode is executed and how the specific virtual machine works for each protected application. 

Some examples of code virtualization tools include \href{https://vmpsoft.com/}{VMProtect} and \href{https://www.oreans.com/CodeVirtualizer.php}{CodeVirtualizer}.

\paragraph{Code Integration}
\textit{Code integration}, one of the most sophisticated obfuscation techniques, was first introduced by \textit{Win97/Zmist} malware. A malware using this technique first decompiles the target program into a set of manageable objects, it then inserts itself between them and finally it reassembles the code \cite{YouMalwareOT}.

\subsection{Obfuscated Malware}
The huge amount of malware released in the wild since the creation of the first virus in 1960s can be split into two generations. More specifically, the first generation malwares were static, their code and behaviour did not change. The more sophisticated second generation malwares, on the other hand, change their internal structure between one variant and the other maintaining the same malicious behaviour in order to avoid detection.

\subsubsection{Encrypted Malwares}
The first second-generation malwares ever existed exploited encryption in order to evade detection by signature-based antivirus scanners.

In this approach, an encrypted malware typically consists of two parts: the encrypted main body and a decryption code (also called \textit{decryptor}). The \textit{decryptor}'s objective is to recover the original malware code from the encrypted body whenever the infected file is run \cite{YouMOT}.

Moreover, to hide from signature-based scanners, encrypted malware encrypts its code using a different key at each infection, thus creating a unique encrypted body. The decryption routine (\textit{decryptor}), however, remains the same from one generation to another. This means that encrypted malwares can be detected with signature-based scanners by searching for the decryptor's code pattern \cite{Sharma_2014}.

The first known malware to exploit encryption for detection evasion was CASCADE which spread in the 1980s and early 1990s.

Encryption of malware code is often used in conjunction with the use of packers.

\color{Black}
\subsubsection{Packed Malwares}
Malware authors are nowadays increasingly exploiting packers (or even multiple packers at once) to produce numerous variants of the same original malware code \cite{NamanyaTWM}.

As stated by Perdisci, et al \cite{PerdisciCPEACVD}, more than 80\% of the new malware currently discovered are actually packed versions of already existing malware.

Packers are used to compress the original file into a smaller size and, moreover, encryption is sometimes applied to the compressed version of the file in order to make the unpacking process more difficult.

However, it is not uncommon to see malware authors writing and using custom packers. This fact can be used by analysts to detect if a file is malicious, without further analysis, based on the fact that benign software vendors would almost never use custom packers. On the other hand, many malware authors frequently use commercial, and readily available, packers to generate malware variants.

\subsubsection{Oligomorphic Malwares}
Malware authors tried to overcome the short comings of encrypted malware developing malware that can mutate the used decryptor from one variant to another. Initially the decryptor could only be changed slightly. However, a common method used by \textit{oligomorphic malware}, also called '\textit{semipolymorphic}', to provide more diverse decryptors is, in practice, to randomly select one decryption routine at infection time from a set of pre-defined different decryptors \cite{Sharma_2014}.

However, this type of malware is able to generate at most few hundreds different decryptors. For example the virus called \textit{Win95/Memorial} was capable of constructing up to 96 different decryptor patterns. This means that signature-based detection techniques are still able to detect \textit{oligomorphic malwares} by generating the signature of all the decryptors utilised by the malware strain \cite{YouMOT}. Still, signature based techniques are not an effective approach to detect \textit{oligomorphic malware}.

The virus named \textit{Whale} was the first known malware to make use of this technique. It carried a few dozens of different decryptors and picked one randomly at infection time \cite{NamanyaTWM}.

\subsubsection{Polymorphic Malwares}
The \textit{oligomorphic} malware limitations lead malware authors to develop a more advanced type of malware called \textit{polymorphic}.

In \textit{polymorphic} malware countless numbers (millions) of distinct decryptors can be generated by using obfuscation methods including, for example, \textit{dead-code insertion}, \textit{register reassignment}, \textit{subroutine reordering}, \textit{instruction substitution}, \textit{code transposition/integration}, etc. to avoid signature based detection \cite{YouMOT}.

\textit{Polymorphic} malware, like \textit{oligomorphic} malware, consists of two parts: the malware encrypted main body and the decryptor. The decryptor is again run once the malware is executed and it enables the execution of the original malware code decrypting the encrypted body. When replication occurs, the malware encrypts its code with a different key, generates the new associated decryptor and encloses it in the new malware variant code. The malware appearance is thus changed at each infection \cite{Sharma_2014}.

In order to have a wide range of decryptors, \textit{polymorphic} malware typically use a powerful toolkit called 'the \textit{Mutation Engine} (\textit{MtE})'. In particular, during malware replication, the mutation engine is used to create the new decryptor which is appended to the new malware variant code. The mutation engine is, in fact, responsible for rearranging the decryptor code using different obfuscation techniques in order to prevent signature based detection.

Even though \textit{polymorphic} malware can create a large number of different decryptors effectively hindering signature matching techniques, still the constant malware body, which appears after decryption, can be used for detection. In particular, by using emulation techniques, the tool execute the malware in a '\textit{Sandbox}' without resulting in any harm to the system. As soon as the constant malware body is decrypted and loaded into memory, the common detection techniques, such as signature based scanning, can be applied \cite{NamanyaTWM}.

Various armouring techniques are thus used by malware authors to prevent detection by emulation, however most antivirus scanners are now capable of addressing also these techniques effectively defeating \textit{polymorphic} malware.

The first known malware to exhibit \textit{polymorphism} is called \textit{1260} and was written in 1990.

\subsubsection{Metamorphic Malwares}
After the \textit{oligomorphic} and \textit{polymorphic} malware types were effectively defeated, malware authors designed a new and more advanced approach: \textit{metamorphic} malware. This, similarly to \textit{polymorphic} malware, uses obfuscation techniques to create new variants of the original malware in order to evade detection \cite{YouMOT}.

However, in this case, instead of generating new decryptors, it is the malware body itself to be mutated through generations to appear different while having the same behaviour and functionality. \textit{Metamorphic} malware is in fact said to be \textit{body-polymorphic}. In practice the malware code logic is maintained while its appearance is changed using obfuscation techniques such as \textit{dead-code insertion}, \textit{register reassignment}, \textit{code transposition} and more. This way, every generated malware variation appears different making signature based detection ineffective \cite{Sharma_2014}.

However, \textit{metamorphic} malware, in order to efficiently evolve its code it need to be able to recognise, parse and mutate its own body during propagation. This is far from being easy. Moreover, creating a true \textit{metamorphic} malware without arbitrary increasing its code size is also challenging \cite{NamanyaTWM}.

Moreover, \textit{metamorphic} malware is also capable of interleaving its own code inside host programs, thus making detection even harder.

The first malware to exhibit metamorphic behaviour was called \textit{Win95/Regswap} and was developed in 1998.

\chapter{Detection Techniques}
Malware detection is the process of identifying malicious code from benign code. This is done in order to protect systems and being able to recover from the malicious code effects \cite{NamanyaTWM}.

In order to counter malware attacks and threats, in recent years many anti-malware tools have been developed. Many of these are based on static features (such as signatures) with the assumption that most malware is static, it doesn't mutate/change significantly at infection/replication time \cite{Sharma_2014}.

However, attackers are nowadays increasingly using the more sophisticated second generation malwares, which strongly mutate at each infection. Researchers and anti-malware software developers are thus focusing their attention on the creation of more advanced tools capable of detecting this type of evolving malware.

\section{Integrity Checker}
When compromising a computer system or network some changes are inevitably made within the target environment. This implies that systems, like \textit{integrity checkers}, that rely on actively monitoring changes made to existing files within the target operating system, can be used to perform intrusion detection \cite{NamanyaTWM}.

Generally, \textit{integrity checkers}, use hashing functions like the \textit{md5} sum, \textit{Sha1} or \textit{Sha256} to calculate the digest of files and/or executables which are then stored in a database of digests. Programs and files digests are then periodically re-calculated and compared against the ones in the database looking for modifications. If the digest of a file is different and no software updates nor patches were applied, then the file was probably tampered with.

\textit{Integrity checkers} present a number of challenges:
\begin{itemize}
	\item The system state in which the initial file digests are calculated has to be considered clean. However this is difficult to be guaranteed.
	
	\item The application of system (and software) updates and patches, which modify system files and programs, must be followed by an update of the digests database, otherwise there will be a very high false positive rate.
	
	\item The digests database needs to be stored securely and there has to be an offline (and safe) backup, otherwise there would be a single point of failure.
\end{itemize}

\textit{Integrity checking} can be considered as an important tool for detecting any system modifications, but it is more an incident recovery method rather than a malware intrusion/infection prevention method.

\section{Signature-based Detection}
\textit{Signature-based} detection is the simplest and most widely used method in commercial anti-virus software (together with \textit{heuristic-based} techniques) but is becoming less and less effective as the number of malware variants and second generation malwares increases \cite{NguyenSPVD}.

\textit{Signature-based} detection relies on \textit{signatures}, represented by specific unique byte code sequences/strings extracted from malware samples, to detect the presence of malicious files in a system. \textit{Signatures} are typically created using static analysis techniques and are selected to be long enough to uniquely characterize a specific malware families with respect to benign programs.

The \textit{signatures}, which are crated by malware experts from a significant number of already identified malware samples, are saved in a \textit{signature database} and deployed in anti-malware tools. Anti-malware tools in turn scan the files in the target system and consider as malicious any file that matches one of the known signatures \cite{NamanyaTWM}. This implies that the database of signatures must be maintained and frequently updated, especially whenever new malware variants are identified and new signatures are generated in order to detect them.

Some \textit{signature-based} algorithms require an exact match between the signature of the analysed sample and one of the known signatures, others instead make use of \textit{wildcards} characters to detect slight variations. Some second generation (evolving) malwares have been detected in the past by using wildcards, e.g. \textit{W32/Regswap}.

This approach is fast, easy to use and has a high positive rate, however, since the number of known malwares is increasing so fast, it is quickly becoming time-consuming, expensive and impractical. Moreover, this is a completely reactive technique which is unable to counter threats/attacks from new malwares families/variants until they cause damages. Additionally, most second-generation malwares are able to escape this type of detection \cite{Sharma_2014}.

\subsection{Yara Rules}
\textit{YARA} is a widely accepted open-source \textit{signature-based} malware analysis tool which has emerged in recent years thanks to its flexible and customisable nature. It allows malware analysts/researchers to develop malware "descriptions" based on text or binary patterns, commonly referred to as \textit{Yara rules}. \textit{Yara rules}, which combine simple regular expressions matching with logic rules, can be used to identify specific malware families, the presence of \textit{CVE}s, specific functionality signatures or even generic maliciousness indicators. Given the success obtained by this technique, many commercial malware analysis tools nowadays support \textit{Yara rules} natively \cite{SimonWIY}.

\textit{Yara rules} can be generated either manually or automatically. Generating rules manually obviously requires high expertise, whereas generating them automatically using tools is a relatively easy task. However, automatically generated rules are not guaranteed to be effective and may require post-processing operations for their optimization \cite{NaikEAGYRETE}.

Malware analysts typically create \textit{Yara rules} manually by reverse engineering malware samples looking for common \textit{Indicator of Compromise (IoC)} strings. This is followed by the development and iterative refinement of the rules which are considered effective based on their coverage and false positive rate on a dataset of malicious, benign and out-of-family samples. Developing effective \textit{Yara rules} can therefore be challenging and very time consuming, even for expert users with years of experience \cite{RaffAYRGUB}.

\subsubsection{Yara Rules syntax}
Listing \ref{YaraSyntax} presents an example of the syntax of a simple \textit{Yara rule}.

\begin{lstlisting}[caption={YARA Rules Syntax}, label=YaraSyntax, language=YARA, style=mystyle]
	rule RuleName
	{
		meta:
		description = "description of rule"
		author = "name"
		date = "dd/mm/yyyy"
		reference = "url"
		
		strings:
		$text_string1 = "text1 you wish to find in malware"
		$text_string2 = "text2 you wish to find in malware"
		
		$hex_string1 = {hex1 you wish to find in malware}
		$hex_string2 = {hex2 you wish to find in malware}
		
		$reg_exp_string1 = /regular expression1 you wish to find in malware/
		$reg_exp_string2 = /regular expression2 you wish to find in malware/
		
		condition:
		$text_string1 or $text_string2 or
		$hex_string1 or $hex_string2 or
		$reg_exp_string1 or $reg_exp_string2
	}
\end{lstlisting}

As it can be seen in the above example, \textit{Yara rules} must start with the keywork '\textit{rule}', followed by the actual \textit{RuleName}, which is the rule identifier. The \textit{RuleName}s follow the same lexical conventions of the \textit{C} programming language. They are, in fact, case sensitive, they cannot exceed 128 characters and they can contain only alphanumeric characters (with the addition of the underscore character), with the exception of the first character which cannot be a digit. Furthermore there is a list of \textit{YARA} reserved keywords that cannot be used as identifiers \cite{NinjaYSEWDM}.

\textit{Yara rules} main body contains three sections: \textit{meta}, \textit{strings} and \textit{condition}.

\paragraph{Meta section}
The rule author can include additional information about the rule as a list of attribute-value pairs, also called \textit{metadata}, in the \textit{meta} section, at the top of the rule. The values can be strings, integers or boolean values. The metadata, however, cannot be used in the condition section since that is not their purpose \cite{ArntzEYR}.

Some commonly used meta tags are, for example, "author" and "description", which convey information about the author and purpose of the rule. Moreover, malware analysts sometimes also leave tags with the hashes of the malicious files used for the creation of the rule, or references to blog posts with similar information \cite{SimonWIY}.

\paragraph{Strings section} 
This section contains the strings/patterns/signatures that a file must contain to 'trigger' the rule. This section is optional and can be omitted if it is not necessary. \textit{YARA} supports searching for 3 string types: \textit{Hexadecimal Strings}, \textit{Text (ASCI) Strings} and \textit{Regular Expressions}.

\begin{itemize}
	\item \textit{Hexadecimal Strings}: \textit{Hexadecimal Strings} will match hexadecimal characters/sequences of raw bytes in the file being analysed.
	Example:
	\begin{lstlisting}[caption={YARA Hexadecimal}, label=YaraHex, language=YARA, style=mystyle]
	rule ExampleRule
	{
		strings:
		$my_text_string = "text here"
		$my_hex_string = { E2 34 A1 C8 23 FB }
		
		condition:
		$my_text_string or $my_hex_string
	}
	\end{lstlisting}
	
	
	Three special flexible formats, namely \textit{wildcards}, \textit{jumps} and \textit{alternatives}, can be used to complement the search.
	\begin{itemize}
		\item \textit{\textbf{Wildcards}} are represented by the '\textbf{?}' symbol. They indicate that some bytes in the pattern are unknown and should match anything. For example:
		\begin{lstlisting}[caption={YARA Hexadecimal Wildcard}, label=YaraWildcard, language=YARA, style=mystyle]
	rule WildcardExample
	{
		strings:
		$hex_string = { E2 34 ?? C8 A? FB }
		
		condition:
		$hex_string
	}
		\end{lstlisting}
		
		\item \textit{\textbf{Jumps}} are used in circumstances when the values of the pattern are known but their length varies. For example:
		\begin{lstlisting}[caption={YARA Hexadecimal Jump}, label=YaraJump, language=YARA, style=mystyle]
	rule JumpExample
	{
		strings:
		$hex_string = { F4 23 [4-6] 62 B4 }
		
		condition:
		$hex_string
	}
		\end{lstlisting}
		In particular, in listing \ref{YaraJump}, the value '\textit{[2-3]}' indicates that any arbitrary sequence from 2 bytes to 3 bytes long can occupy the sequence at that position.
		
		\item \textit{\textbf{Alternatives}}, whose syntax resembles regular expressions, are used in situations in which the author wants to provide different alternatives for a given fragment of the hex string. For example:
		\begin{lstlisting}[caption={YARA Hexadecimal Alternatives}, label=YaraAlternatives, language=YARA, style=mystyle]
	rule AlternativesExample
	{
		strings:
		$hex_string = { F4 23 ( 62 B4 | 56 ) 45 }
		
		condition:
		$hex_string
	}
		\end{lstlisting}
	In particular, in listing \ref{YaraAlternatives}, the value '\textit{(62 B4 $\vert$ 56)}' indicates that one sequence between '\textit{62 B4}' and '\textit{56}' can occupy the sequence at that position.
	\end{itemize}
	
	\item \textit{Text Strings}:		
	Text strings are generally readable sequences of ASCII characters which are then matched in the condition section \cite{SimonWIY}.
	
	Example of an ASCII-encoded, case-sensitive string:
	\begin{lstlisting}[caption={YARA Text Strings example}, label=YaraTextStrings, language=YARA, style=mystyle]
		rule TextExample
	{
		strings:
		$text_string = "foobar"
		
		condition:
		$text_string
	}
	\end{lstlisting}
	
	Additionally, to specify how \textit{YARA} should search for strings, some modifiers can be added at the end of a string definition. Moreover, even more than one modifier can be used in combination to keep rule as simple and readable as possible. Here are described some of the available modifiers:
	\begin{itemize}			
		\item \textit{nocase}: Text strings in YARA are, by default, case-sensitive. However it is possible to search for strings in case-insensitive mode by appending the modifier '\textit{nocase}' at the end of the string definition, in the same line. Example:
		\begin{lstlisting}[caption={YARA nocase example}, label=YaraNocase, language=YARA, style=mystyle]
	rule CaseInsensitiveTextExample
	{
		strings:
		$text_string = "foobar" nocase
		
		condition:
		$text_string
	}
		\end{lstlisting}
		
		\item \textit{wide}: The '\textit{wide}' modifier can be used to search for strings encoded with two bytes per character (also known as \textit{wide character strings}), something which is typical in many executable binaries.
		
		For example, if the string "Borland" appears in the file encoded as two bytes per character, then the following rule will match:
		\begin{lstlisting}[caption={YARA Wide Character Strings}, label=YaraWideCharacter, language=YARA, style=mystyle]
	rule WideCharTextExample1
	{
		strings:
		$wide_string = "Borland" wide
		
		condition:
		$wide_string
	}
		\end{lstlisting}
	
		\item \textit{xor}: \textit{YARA} can also encode text before searching it in the analysed file. The '\textit{xor}' modifier, for example, can be used to search for strings with a single byte XOR applied to them.
		
		The following rule will search for every string resulting from a single-byte XOR applied to the string "This program cannot":
		\begin{lstlisting}[caption={YARA XOR-ed Strings}, label=YaraXOR, language=YARA, style=mystyle]
	rule XorExample1
	{
		strings:
		$xor_string = "This program cannot" xor
		
		condition:
		$xor_string
	}
		\end{lstlisting}
	
		\item \textit{base64}: The '\textit{base64}' modifier can be used to search for strings that have been base64 encoded.
		
		The following rule will search for all the possible base64 permutations of the string "This program cannot":
		\begin{lstlisting}[caption={YARA Base64 encoded Strings}, label=YaraBase64, language=YARA, style=mystyle]
	rule Base64Example1
	{
		strings:
		$a = "This program cannot" base64
		
		condition:
		$a
	}
		\end{lstlisting}
	\end{itemize}

	\item \textit{Regular Expressions}:
	Starting from version 2.0 YARA has its own regular expression engine, which is one of its most powerful features. \textit{Regular expressions} are defined in the same way as text strings, but enclosed in forward slashes instead of double-quotes \cite{NaikEAGYRETE}.
	
	Example:		
	\begin{lstlisting}[caption={YARA Regular Expression}, label=YaraRegex, language=YARA, style=mystyle]
	rule RegExpExample
	{
		strings:
		$re1 = /md5: [0-9a-fA-F]{32}/
		$re2 = /state: (on|off)/
		
		condition:
		$re1 and $re2
	}
	\end{lstlisting}	
\end{itemize}

\paragraph{Conditions section}
The last section of \textit{YARA rules}, which is the only required one, contains the rule conditions that determine when the rule gets triggered. These conditions are Boolean expressions similar to those used in programming languages \cite{ArntzEYR}. Through the use of all the usual logical and relational operators, conditions can be made arbitrary complex in order to accommodate for the specific author needs \cite{SimonWIY}.	

Inside the \textit{Conditions} section, among other things, it is possible to:
\begin{itemize}
	\item \textbf{Count strings}
	Sometimes it is necessary to know how many times a string appears in the analysed file, not only if it is present or not. The number of occurrences of each string defined in the string section can be retrieved by using a variable whose name is the string identifier but with a \# character in place of the initial \$ character.
	
	For example:
	\begin{lstlisting}[caption={YARA Count Example}, label=YaraCount, language=YARA, style=mystyle]
	rule CountExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		
		condition:
		#a == 6 and #b > 10
	}
	\end{lstlisting}
	
	\item \textbf{Check String at specific offset/in offset range}: Sometimes we need to know if a particular string is available at some specific offset of the file or at some virtual address within the process address space. In such situations it is possible to use the '\textit{at}' operator.
	
	The '\textit{in}' operator, on the other hand, allows to search for a specific string within a range of offsets or addresses, rather than at an exact one.
	
	Examples:
	\begin{itemize}
		\item The rule in listing \ref{YaraAt} will find whether the '\textit{a}' string is located at offset 100 and '\textit{b}' at offset 200 of the running process.
		
		\begin{lstlisting}[caption={YARA At Example}, label=YaraAt, language=YARA, style=mystyle]
	rule AtExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		
		condition:
		$a at 100 and $b at 200
	}
		\end{lstlisting}
		
		\item The rule in listing \ref{YaraIn} will find the '\textit{a}' in the memory location between \textit{0} and \textit{100} and '\textit{b}' between \textit{100} and \textit{filesize} of the running process.
		
		\begin{lstlisting}[caption={YARA In Example}, label=YaraIn, language=YARA, style=mystyle]
	rule InExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		
		condition:
		$a in (0..100) and $b in (100..filesize)
	}
		\end{lstlisting}
	\end{itemize}

	\item \textbf{Check file size}: '\textit{filesize}' is a special variable that can be used in rules conditions, which holds the size of the file being scanned in bytes.
	
	Example:
	\begin{lstlisting}[caption={YARA Filesize Example}, label=YaraFilesize, language=YARA, style=mystyle]
	rule FileSizeExample
	{
		condition:
		filesize > 200KB
	}
	\end{lstlisting}
	
	\item \textbf{Check a set of strings}: When it is necessary to know if a file contains a certain number of strings from a given set the '\textit{of}' operator can be used.
	
	Example:
	\begin{lstlisting}[caption={YARA Of Example}, label=YaraOf, language=YARA, style=mystyle]
	rule OfExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		$c = "dummy3"
		
		condition:
		2 of ($a, $b, $c)
	}
	\end{lstlisting}
\end{itemize}

\paragraph{Additional modules}
\textit{YARA}'s code functionality can be extended through the use of modules. Some modules like the \textit{PE module} and the \textit{Cuckoo module} are officially distributed with YARA, however additional ones can also be created.

Here are mentioned some useful (in this document context) Yara modules:
\begin{itemize}
	\item \textbf{YARA with PE}
	Starting with version 3.0, YARA can parse Portable Executable (PE) files \cite{NinjaYSEWDM}. For example, the rule in listing \ref{YaraPE} will check for the string "abc", will parse the PE file and look for "\textit{CreateProcess}" and "\textit{httpsendrequest}" function names in the import sections '\textit{Kernel32.dll}' and '\textit{wininet.dll}', respectively.
	
	\begin{lstlisting}[caption={YARA with PE}, label=YaraPE, language=YARA, style=mystyle]
	Import "PE"
	
	rule PE_Parse_Check
	{
		strings:
			$string_pe="abc" nocase

		condition:
			pe.imports("Kernel32.dll", "CreateProcess") and
			pe,imports("wininet.dll", "httpsendrequest") and
			$string_pe
	}
	\end{lstlisting}
	
	\item \textbf{YARA with PEiD}
	\textit{YARA} can also be integrated with \textit{PEiD} to check what packer was used to compile the malicious/suspicious executable \cite{NinjaYSEWDM}.
\end{itemize}

\subsubsection{Yara Rules Advantages and Disadvantages}
\begin{enumerate}
	\item \textbf{\textit{Advantages}} of \textit{Yara rules}:
	\textit{Yara rules} offer several advantages over other malware analysis techniques. Here are some of the most notable ones \cite{NaikEAGYRETE}:
	\begin{itemize}
		\item \textit{Yara rules} allow malware analysts to write flexible and custom rules in an easy and efficient way.
		
		\item \textit{Yara rules} are an open standard which work on most of the major operating systems such as Windows, Linux and Mac OS.
		
		\item \textit{Yara rules} can be easily integrated into Python and C/C++ programming languages.
		
		\item \textit{Yara rules} can be used both for static and dynamic malware analysis.
		
		\item Several automatic tools have been developed, and are readily available, to generate \textit{Yara rules} easily and efficiently.
		
		\item There are various public repositories of \textit{Yara rules} which offer readily available rules for malware analysis.
	\end{itemize}
	
	\item \textbf{\textit{Limitations}} of \textit{Yara rules}:
	\textit{Yara rules}, however, have also some limitations. Here are some of the most notable ones \cite{NaikEAGYRETE}:
	\begin{itemize}
		\item \textit{Yara rules} are commonly written based on \textit{IoC} (\textit{Indicator of Compromise}) strings, however, malware authors can easily obfuscate, replace or encrypt these \textit{IoC} strings in their creations in order to evade detection. This could make these rules less effective.
		
		\item \textit{IoC} strings are usually extracted from existing malware samples/families through the use of reverse engineering techniques. The use of these techniques in manually creating effective rules, however, requires a highly specialised skill-set and years of experience.
		
		\item The effectiveness of \textit{Yara rules} is generally influenced by the types and number of \textit{IoC} strings included in the rules. However, achieving the right balance of both is a challenging task.
		
		\item \textit{Yara rules} are effective in detecting malware which matches known malware signature. It may, however, completely miss new and unique malware variants.
	\end{itemize}
\end{enumerate}

\subsubsection{Yara Rules Automatic Generators}
There are various automatic \textit{Yara rules} generator tools available. In the following the most notable ones will be briefly described:

\paragraph{\textit{YarGen} Tool}
\textit{YarGen} \textit{python-based} tool exploits some smart techniques, namely fuzzy regular expressions, Naive Bayes classifier and Gibberish Detector, to generate \textit{Yara rules}. 

The produced rules include features (strings and opcodes) common to malware samples that don't match with the provided goodware databases. A predefined number of features (generally up to 20 strings) are selected, based on their potential utility and a number of heuristics, to be combined and used by the rule in order to maintain a reasonable operation speed.

This tool is able to generate two types of rules: \textit{basic rules} and \textit{super rules}. \textit{Basic rules} can generally target specific malware samples, where \textit{super rules} are able to target a set of malware samples or a whole malware family \cite{NaikEAGYRETE}.

The \textit{yarGen} authors encourage its use as a starting point for rule construction, followed by manual adjustments and to refine \textit{yarGen}'s output \cite{RaffAYRGUB}.

\begin{enumerate}
	\item \textit{YarGen} tool \textit{advantages}:
	\begin{itemize}
		\item It allows generation of \textit{Yara rules} based on both opcodes and strings.
		
		\item It supports the use of PE (portable executable) modules, with are used to interpret Windows operating system executables such as \textit{DLL} and \textit{COM} files.
		
		\item It can be integrated with other anti-malware software in order to improve its effectiveness.
		
		\item It reduces the false positive rate by checking all strings against databases of goodware samples.
		
		\item It is deployed as a simple and easy-to-use python script that can be run through a command-line interface.
	\end{itemize}
	
	\item \textit{YarGen} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item It requires significant resources for generating opcode-based rules and for loading goodware files.
		
		\item The rule generation process is slow.
		
		\item The creation of super rules may cause redundancy and duplication of rules.
		
		\item All dependencies and built-in databases have to be installed in order for the tool to work successfully.
	\end{itemize}
\end{enumerate}

\paragraph{\textit{YaraGenerator} Tool}
This \textit{python-based} tool uses string prioritization logic and code refactoring to generate \textit{Yara rules} with a completely different signature for different file types, such as \textit{EXE}s, \textit{PDF}s, and \textit{Email}s.

The generated \textit{Yara rules} contain only strings (opcodes are not supported) extracted from malware samples that do not match with the provided database of strings from blacklisted files. In particular 30,000 blacklisted strings are contained in such database, arranged based on the different file formats.

The produced \textit{Yara rules} contain a large number of strings which are selected randomly. In fact, no score computation takes place in order to weight the different strings \cite{NaikEAGYRETE}.

\begin{enumerate}
	\item \textit{YaraGenerator} tool \textit{advantages} :
	\begin{itemize}
		\item It can generate specialised rules for specific file formats.
		
		\item It supports the use of PE (portable executable) modules, with are used to interpret Windows operating system executables such as \textit{DLL} and \textit{COM} files.
		
		\item It reduces the false positive rate by checking all strings against databases of blacklisted files.
		
		\item It is deployed as a simple and easy-to-use python script that can be run through a command-line interface.
	\end{itemize}
	
	\item \textit{YaraGenerator} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item It generates rules based on a random selection of features (strings). This implies that the most appropriate strings may not be selected in many cases, thus making the produced rules less effective on average.
		
		\item It does not support the use of opcodes.
		
		\item It was developed as a work-in-progress project and has not been updated for a while now.
	\end{itemize}
\end{enumerate}

\paragraph{\textit{Yabin} Tool}
This is another \textit{python-based} tool, developed by the \textit{Alien Vault Open Threat Exchange} (\textit{OTX}) community, for the automatic generation of \textit{Yara rules}.

In this case \textit{Yara rules} are created by finding rare functions in specific malware samples or families. Functions are recognised by checking specific bytes sequences called \textit{function prologues}, which define the start of the code of a function. For example, the byte sequence '\textit{55 8B EC}' usually specifies the start of a function in programs compiled by Microsoft Visual Studio.

The generated \textit{Yara rules} include those strings common to malware samples that don't match with the provided whitelist of commonly used library functions. Such whitelist was obtained from 100 Gb of non-malicious software in order to exclude common library functions.

The \textit{Yara rules} produced contain a list of hexadecimal strings to be compared against suspicious files looking for similarities in their byte-sequences \cite{NaikEAGYRETE}.

\begin{enumerate}
	\item \textit{Yabin} tool \textit{advantages}:
	\begin{itemize}
		\item It can be used to cluster malware samples based on the reuse of their code.
		
		\item The list of patterns to search for can be extended during the rule post-processing phase.
		
		\item With the purpose of excluding commonly used library functions in the produced rules, a large whitelist obtained from numerous non-malicious executable files is provided with the tool.
		
		\item It is deployed as a simple and easy-to-use python script that can be run through a command-line interface.
	\end{itemize}
	
	\item \textit{Yabin} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item Some specific file types/formats may not be supported.
		
		\item The created rules contain only function prologues. No other string types are used.
		
		\item Since it relies on function prologues, it works only with unpacked executables.
		
		\item It is not designed to work on \textit{.NET} executables, \textit{Java} files and \textit{Microsoft} documents.
		
		\item It was mainly developed for research and testing purpose, not for production use.
	\end{itemize}
\end{enumerate}

\paragraph{\textit{AutoYara} Tool}
Compared to the previously mentioned tools like \textit{YarGen}, which rely on a number of heuristics and string features, \textit{AutoYara} tool makes larger rules using the redundancy and conjunction of components to achieve extremely low false-positive rates \cite{RaffAYRGUB}.

The two primary concerns of the \textit{AutoYara} authors while designing this tool were:
\begin{enumerate}
	\item Yara rules that generate a lot of false positives could slow the investigation
	
	\item Malware analysts often have few samples ($\leq 10$) when creating a Yara rule
\end{enumerate}

\textit{AutoYara} authors thus developed a workflow composed of two steps: the first step leveraged recent works in finding frequent larger n-grams, for $n \leq 1024$, to find several candidate byte strings that could become features. In the second step a bi-clustering method, which consists of simultaneously clustering the rows and columns of an input data matrix, is used on those strings to construct the output rules. Most bi-clustering algorithms require the specific number of bi-clusters to be known in advance, and enforce no overlaps between bi-clusters. The \textit{AutoYara} authors exploited an already existing bi-clustering algorithm extending it to work when the number of bi-clusters is not known \textit{a priori} (the number of bi-clusters gets determined automatically) and to allow overlapping bi-clusters, discarding rows and columns that do not fit in any bi-cluster \cite{RaffAYRGUB}.

\textit{AutoYara} uses \textit{bi-clustering} because it allows to easily produce complex and effective logic rules that enable the creation of signatures with low false positive rates.

To build a good Yara rule, in fact, one needs to know:
\begin{enumerate}
	\item which features should be used at all
	
	\item which features should be combined into '\textit{and}' statements (which reduce the False Positive Rate), and which should be placed into '\textit{or}' statements (which increase the True Positive Rate)
\end{enumerate}
\textit{Bi-clustering} provides a simple approach to do this jointly over the features, rather than considering the features one at a time. In particular, the features within a bi-cluster are combined into an '\textit{and}' statement since they co-occur; moreover the '\textit{and}' statements from multiple bi-clusters are placed into an '\textit{or}' statement resulting in a "disjunction of conjunctions" rule formulation.

\begin{enumerate}
	\item \textit{AutoYara} tool \textit{advantages}:
	\begin{itemize}
		\item It is fast, allowing it to be deployed even on low-resource equipment (like remote networks).
		
		\item It was designed with the intent of producing \textit{Yara rules} with low false positive rates.
		
		\item It was designed to be able to generate \textit{Yara rules} from as few as $\leq10$ available samples.
	\end{itemize}
	
	\item \textit{AutoYara} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item It a very recent tool, mainly developed for research purposes and not for production use.
	\end{itemize}
\end{enumerate}

\color{Green}
Consider if to add something about "Manually generated Yara Rules + Open Source Yara Rules databases".
\color{Black}

\section{Semantic Based Detection}
\textit{Semantic-based} malware detection aims at identifying malware by deducing the analysed code logic and comparing it to a database of already known malicious logic patterns. This technique, differently from signature-based detection which looks at the code syntactic properties, tracks the semantics of the program code instructions. This implies that \textit{semantic-based} detection approaches are capable of overcoming obfuscation attempts and even detecting unknown malware variants \cite{NamanyaTWM}.

\section{Behavioural Based Detection}
\textit{Behavioural-based} malware detection is based on the use of behavioural patterns for the identification of malicious software. This is done by dynamically analysing malware samples and extracting specific system/application behaviours and activities in order to form a '\textit{behavioural signature}' of a malware strain. New samples are then analysed in the same way and identified as malware if their behavioural pattern is similar to the \textit{behavioural signature} of a known malware \cite{NamanyaTWM}.

\textit{Behavioural-based} detection is for the most part immune to obfuscation attempt. However, being based on the time consuming dynamic analysis and on the challenging task of determining the unsafe activities and behaviours to consider within the environment, its applicability is limited.

\section{Heuristics-based Detection}
As opposed to traditional \textit{signature-base} detection methods which identify malware by looking in the code for specific bytes/strings, \textit{heuristic-based} detection uses rules and/or algorithms to search for commands or instructions not commonly found in harmless applications, thus indicating possible malicious intents \cite{MiaoUHSS}.

\textit{Heuristic-based} anti-malware tools may exploit different scanning techniques such as:
\begin{itemize}
	\item \textit{File analysis (static heuristic analysis)}: the suspicious program is disassembled and its source program is examined looking for known malware patterns (stored in a heuristic database). If the percentage of matched code exceeds a predefined threshold then the code is marked as probably infected \cite{KasperskyWHA}.
	
	\item \textit{File emulation (dynamic heuristic analysis)}: in this approach, the suspicious piece of code is examined in a virtual machine (or sandbox) looking for suspicious operations such as attempts at executing other executables, at changing the Master Boot Record, at concealing themselves etc. that are uncommon in benign programs.
	
	\item \textit{Genetic signature detection}: this technique is designed to spot different malware variations within the same family using previous malware definitions \cite{ForcepointWHA}.
\end{itemize}

\textit{Heuristic} analysis is a promising technique for the detection of unknown malware, particularly for encrypted and polymorphic variants \cite{Sharma_2014}.

Nowadays \textit{heuristic} analysis can be found in most mainstream antivirus solutions in the market, combined with signature-based scanners in order to improve detection rate while reducing false alarms \cite{NamanyaTWM}.

\section{Machine Learning}
\color{Red}

In recent years, malware detection with machine learning techniques is gaining popularity. Tom Mitchell \cite{} defines machine learning as the study of computer algorithms that improve through experiments. Robert Moskovitch et. al. \cite{} proposed detection of malwares based on monitoring the computer behaviour (features). His evaluation results suggest that by using classification algorithms applied on only 20 features the mean detection accuracy exceeded 90\%. The advantage of machine learning techniques is that it will not only detect known malwares but also act as knowledge for the detection of new malware. The popular machine learning techniques among the researchers for the detection of second generation malwares are Naive Bayes, Decision Trees, Data Mining, Neural Networks and Hidden Markov Modes. This technique may not replace the standard detection methods, but it can act as an add-on feature. Generally, machine learning techniques are more computationally demanding than the standard anti-malware, hence it may not be suitable for end users. However, it can be implemented at enterprise gateaway level to act as a central anti-malware engine to supplement anti-malwares. Although infrastructure requirement is costly, it can help in protecting valuable enterprises data from the security threats and can prevent immense financial damages \cite{Sharma_2014}.

In recent years, machine learning has gained its popularity in many fields including IT security. Robert Moskovitch et. al. \cite{} proposed a technique that monitors a small set of features that are sufficient for detecting malware without sacrificing accuracy. The result of the study showed that, using only 20 features, the mean detection accuracy was greater than 90\%, and for specific unknown worms, this accuracy got over 99\%, while maintaining a low level of false positives. The advantage of machine learning techniques is that it will not only detect a known malware but also act as a database for detecting new malware. Similar studies can also be found in another model such as Naive Bayes, Decision Trees, Neural Networks. Although this technique is practical, it may not replace the standard detection methods, rather than act as an add-on feature because machine learning techniques are computationally demanding and may not be suitable for end users \cite{NguyenSPVD}.

\color{Black}
\subsection{Simple malware detection network}
\color{Red}

\color{Black}
\subsection{AlOHA: Auxiliary Loss Optimization for Hypothesis Augmentation}
\color{Red}

\color{Black}
\subsection{Automatic Malware Description via Attribute Tagging and Similarity Embedding}
\color{Red}

\color{Black}
\subsection{Learning from Context: Exploiting and Interpreting File Path Information for Better Malware Detection}
\color{Red}

\color{Black}
\section{Malware Normalization}
In order to improve the detection rate of existing anti-malware techniques also against malware produced by advanced packers and toolkits, code \textit{normalization} techniques can be exploited. These techniques consist of a \textit{normalizer} which accepts obfuscated code as input and tries to eliminate obfuscation producing as output the normalized executable.

After \textit{normalization}, the usual signature-based techniques can be applied on the normalized sample \cite{Sharma_2014}.

\chapter{Dataset Used}

\chapter{Experimenting with ML based Malware Detection/Description methods}

\chapter{Proposed Tool}

Description of the proposed tool..

\chapter{Experiments with the proposed tool}

\chapter{Results}

Results analysis..

\chapter{Conclusions}

Qui si inseriscono brevi conclusioni sul lavoro svolto, senza ripetere inutilmente il sommario.

Si possono evidenziare i punti di forza e quelli di debolezza, nonché i possibili sviluppi futuri o attività da svolgere per migliorare i risultati.

\chapter{Appendix}
\section{Notable Examples of Malware in Recent History}\label{NotableMalwareExamples}

Here is an overview of the most famous malware or malware-related events in recent history:
\begin{itemize}
	\item \textbf{\textit{Melissa}} (1999) - Considered to be one of the first cases of social engineering in history, the Melissa mass-mailing macro virus infected thousands of computers worldwide by the end of 1999. The virus was spread via e-mail, using a malicious Word attachment named "list.doc" and as subject: "Important message from", followed by the victim's username. Once opened, the attachment would execute a macro that mass-mailed the virus to the first 50 people in the user's contact list and disabled multiple security features on Microsoft Word and Microsoft Outlook.
	
	\item \textbf{\textit{ILOVEYOU}} (2000) - \textit{ILOVEYOU}, sometimes referred to as \textit{Love Bug} or \textit{Love Letter for you}, was a computer worm that infected over ten million Windows personal computers in 2000. It spread as an email message with the subject line "ILOVEYOU" and the attachment "LOVE-LETTER-FOR-YOU.txt.vbs". Opening the attachment would activate the Visual Basic script which caused damages on the local machine, overwriting random files. Finally, the worm sent a copy of itself to all addresses in the Windows Address Book used by Microsoft Outlook.
	
	\item \textbf{\textit{SQL Slammer}} (2003) - This malware exploited a buffer overflow bug in Microsoft's SQL Server and Desktop Engine database products, causing a denial of service on some Internet hosts and dramatically slowing general Internet traffic. It spread rapidly, infecting most of its 75,000 victims within ten minutes.
	
	\item \textbf{\textit{MyDoom}} (2004) - Also known as \textit{W32.MyDoom@mm}, \textit{Novarg}, \textit{Mimail.R} and \textit{Shimgapi}, it was a computer worm which affected Microsoft Windows systems. It became known mostly because it tried hitting major technology companies, such as Google and Microsoft. It spread by email using attention-grabbing subjects, such as ?Error?, ?Test? and ?Mail Delivery System?. It became the fastest-spreading e-mail worm ever, exceeding previous records set by the Sobig worm and ILOVEYOU, a record which as of 2021 has yet to be surpassed.
	
	\item \textbf{\textit{Conficker}} (2008) - Also known as \textit{Downup}, \textit{Downadup} and \textit{Kido}, this computer worm targeted the Microsoft Windows operating system. It used flaws in Windows OS software and dictionary attacks on administrator passwords to propagate while forming a botnet. The Conficker worm infected over 15 million Windows systems including government, business and home computers in more than 190 countries. This made it the largest known computer worm infection since the 2003 \textit{Welchia}.
	
	\item \textbf{\textit{Zeus}} (2007-2009) - Also known as \textit{ZeuS}, or \textit{Zbot}, \textit{Zeus} was a Trojan horse malware that ran on Microsoft Windows. It was able to carry out many malicious and criminal tasks. However, it was most often used to steal banking information through the use of man-in-the-browser keystroke logging and form grabbing. It was also often used to install the \textit{CryptoLocker} ransomware. Zeus spread mainly through drive-by downloads and phishing mails. First identified in mid 2007, it became more widespread in 2009.
	
	\item \textbf{\textit{Stuxnet Worm}} (2010) - \textit{Stuxnet} was an extremely sophisticated worm that infected computers worldwide. It was allegedly developed by US and Israeli intelligence to hinder the Iranian nuclear program. It was introduced into the target environment (Iran's nuclear power plant) via a flash drive. Stuxnet's escape from the target environment, which was air-gapped, was not expected. Once in the wild, Stuxnet spread aggressively but mostly harmed the target Iranian nuclear facility, where it damaged uranium-enrichment centrifuges, causing little damage outside of its intended target environment \cite{BakerMCTM}.
	
	\item \textbf{\textit{CryptoLocker}} (2013) - It is considered to be one of the first widespread ransomware attacks. It targeted computers running Microsoft Windows and it propagated via infected email attachments. When activated, it encrypted certain types of files stored on local and mounted network drives using RSA public-key cryptography. The private key was stored only on the malware's control servers. A message was then displayed offering to decrypt the data if a payment (through either bitcoin or other means) was made before a certain deadline. After such deadline the private key was deleted. However, paying the ransom did not always lead to the files being decrypted.
	
	Its code now keeps getting repurposed in similar malware projects.
	
	\item \textbf{\textit{Mirai}} (2016) - \textit{Mirai} is an infamous malware which compromised vulnerable IoT (Internet of Things) devices - such as IP cameras and home routers - turning them into remotely controlled bots.
	
	The Mirai botnet, one of the biggest (and worse) botnets in existence, was first found in August 2016 and has been used in some of the largest and most disruptive distributed denial of service (DDoS) attacks, including an attack on computer security journalist Brian Krebs' web site. The source code for Mirai has been published on Hack Forums as open-source, as a result its techniques have been adapted in many other malware projects.
	
	\item \textit{\textbf{Petya} and \textbf{NotPetya}} (2016-2017) - These malware attacks spread globally, however their damages particularly targeted Ukraine, where the national bank was hit. The Petya ransomware family caused an estimated \$10 billion in damages worldwide \cite{ReganWIM}. \textit{Petya} targeted Microsoft Windows-based systems, infecting the Master Boot Record (MBR) to execute a payload that encrypted the hard drive's file system table preventing Windows from booting. It subsequently demanded a ransom in Bitcoin to the user in order to regain access to the system.
	
	Many variants of Petya were created in the subsequent months. In mid 2017, a new variant of Petya was used for a global cyber-attack, again primarily targeting Ukraine. The new variant spread using the EternalBlue exploit, the same one used by the WannaCry ransomware. This new version was called \textit{NotPetya} to distinguish it from the 2016 variants.
	
	\item \textbf{\textit{WannaCry}} (2017) - WannaCry is considered to be one of largest ransomware attacks in history. It targeted computers running Microsoft Windows by encrypting data and demanding ransom payments in Bitcoin. It mainly propagated through EternalBlue, an exploit developed by the U.S. National Security Agency (NSA) for older Windows systems. This exploit was stolen from NSA and leaked approximately one year before the attack. While Microsoft had released security patches against this exploit, some organizations had not applied them, or were using older Windows systems when the attack occurred.
	
	The attack was stopped within a few days of its discovery thanks to emergency patches released by Microsoft and the discovery of a kill switch. Before being stopped, WannaCry was spread infecting systems at a terrifying rate of 10,000 PCs per hour \cite{ReganWIM}. In the end, the attack was estimated to have affected more than 200,000 computers across 150 countries, with total damages ranging from hundreds of millions to billions of dollars.
	
	\item \textbf{\textit{Emotet}} (2018) - This malware, also known as \textit{Heodo}, was first detected in 2014 as a banking trojan aimed at stealing banking credentials from infected hosts. Throughout 2016 and 2017, its creators updated and reconfigured it to work primarily as a "loader" - a type of malware that gains access to a system, and then allows its operators to download and execute additional payloads. These payloads can be any type of executable code, from Emotet's own modules to malware developed by other cybercriminals.
	
	This malware usually makes its way on target systems via a macro virus attached to an email. The infected email appears to be a legitimate reply to an earlier message sent by the victim. When on the system, it is particularly difficult to combat because it evades signature-based detection, is persistent, and includes advanced spreader modules used to propagate effectively. 
	Emotet authors have often used the malware to create a botnet of infected computers to which they sell access in Malware-as-a-Service to other cybercriminals, such as the Ryuk gang.
	
	In 2020, Emotet spread again globally, infecting its victims with TrickBot and Qbot, which are used to steal banking credentials and spread inside networks. In January 2021, Europol and Eurojust coordinated international actions allowed investigators to take control of and disrupt the Emotet infrastructure.
	
	\item \textbf{\textit{COVID-19 related attacks}} (2020) - In 2020, many cybercriminals shamelessly took advantage of the people's fear of coronavirus during the COVID-19 pandemic through COVID-19 related phishing scams. Using fake communications, for example spoofing the World Health Organization, attackers deployed malware and got access to targets' sensitive information among other nefarious actions \cite{ReganWIM}.
	
	Another COVID-19 attack was that of a malicious Android app called \textit{CovidLock}, which claimed to be a real-time coronavirus outbreak tracker but instead was a ransomware that attempted to trick the user into providing administrative access on their device and then locked it requesting a ransom.
\end{itemize}

% bibliografia scritta "a mano"
%\input{biblio.tex}

% se la bibliografia è stata scritta (usando Bibtex) nel file biblio.bib allora commentare la riga precedente e scommentare le due righe seguenti
\bibliographystyle{torsec}
\bibliography{biblio}

\end{document}
