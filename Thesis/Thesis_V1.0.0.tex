% !TEX encoding = IsoLatin

% La riga soprastante serve per configurare gli editor TeXShop, TeXWorks
% e TeXstudio per gestire questo file con la codifica IsoLatin o Latin 1
% o ISO 8859-1.

% per commentare una riga mettere % al suo inizio
% per s-commentare una riga (ossia attivarla) togliere il % al suo inizio
%
\documentclass[pdfa% formato PDF/A, obbligatorio per l'archiviazione delle tesi di Polito
,cucitura%lascia margine per la rilegatura
%,twoside% per stampa fronte-retro (fortemente consigliato per tesi voluminose, opzionale per le altre)
%,12pt% font più grande (12pt) rispetto a quello normalmente usato (11pt)
]{toptesi}
%
\usepackage{hyperref}
\hypersetup{%
    pdfpagemode={UseOutlines},
    bookmarksopen,
    pdfstartview={FitH},
    colorlinks,
    linkcolor={blue},
    citecolor={red},
    urlcolor={blue}
  }
% \documentclass[11pt,twoside,oldstyle,autoretitolo,classica,greek]{toptesi}
% \usepackage[or]{teubner}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Esempio di composizione di tesi di laurea.
%
% Questo esempio e' stato preparato inizialmente 13-marzo-1989
% e poi e' stato modificato via via che TOPtesi andava
% arricchendosi di altre possibilita'.
%
% Nel seguito laurea "quinquennale" sta anche per "specialistica" o "magistrale"

% Cambiare encoding a piacere; oppure non caricare nessun encoding se si usano
% solo caratteri a 7 bit (ASCII) nei file d'entrata.
%
\usepackage[latin1]{inputenc}% IMPORTANTE! usare codifica ISO-8859-1 per le lettere accentate

% temporaneo
\usepackage[dvipsnames]{xcolor}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\input{commands.tex}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{blue},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstdefinelanguage{YARA}{
	morekeywords=[1]{rule, meta, strings, condition},
	morekeywords=[2]{import, ascii, wide, nocase, and, or, all, at, in, of, fullword},
	keywordstyle=[1]\color{Blue},
	keywordstyle=[2]\color{Red},
	sensitive=false,
	morecomment=[l]{//},
	morecomment=[s]{/*}{*/},
	morestring=[b]",
	morestring=[d]',
}

\algdef{SE}% flags used internally to indicate we're defining a new block statement
[CLASS]% new block type
{Class}% "\Class{name}" will indicate the start of the class declaration
{EndClass}% "\EndClass" ends the block indent
[1]% There is one argument, which is the name of the class
{\textbf{class} \textsc{#1}}% typesetting of the start of a class
{\textbf{end class}}% typesetting the end of the class

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{xcolor}

\begin{document}
	
\selectlanguage{english}

\ateneo{Politecnico di Torino}

%%% scegliere la propria facoltà (solo PRIMA dell'AA 2012-2013)
%
%\facolta[III]{Ingegneria dell'Informazione}
%\facolta[IV]{Organizzazione d'Impresa\\e Ingegneria Gestionale}
%\Materia{Remote sensing}% uso sconsigliato

%\monografia{Gestione informatizzata di un magazzino ricambi}% per la laurea triennale
\titolo{Automatic Malware Signature Generation}% per la laurea quinquennale e il dottorato
%\sottotitolo{Metodo dei satelliti medicei}% NON obbligatorio, per la laurea quinquennale e il dottorato

%%% scegliere il proprio corso
%
%\corsodilaurea{Ingegneria dell'Organizzazione d'Impresa}% per la laurea di primo e secondo livello
%\corsodilaurea{Ingegneria Logistica e della Produzione}% per la laurea di primo e secondo livello
%\corsodilaurea{Ingegneria Gestionale}% per la laurea di primo e secondo livello
\corsodilaurea{Ingegneria Informatica}% per la laurea di primo e secondo livello
%\corsodidottorato{Meccanica}% per il dottorato

\candidato{Michele \textsc{Crepaldi}}% per tutti i percorsi
%\secondocandidato{Evangelista \textsc{Torricelli}}% per la laurea magistrale solamente
%\direttore{prof. Albert Einstein}% per il dottorato
%\coordinatore{prof. Albert Einstein}% per il dottorato
\relatore{prof.\ Antonio Lioy}% per la laurea e il dottorato
\secondorelatore{ing.~Andrea Atzeni}% per la laurea magistrale
%\terzorelatore{{\tabular{@{}l}dott.\ Neil Armstrong\\prof. Maria Rossi\endtabular}}% per la laurea magistrale
%\tutore{ing.~Andrea Atzeni}% per il dottorato
%\tutoreaziendale{dott.\ ing.\ Giovanni Giacosa} % solo per la laurea di secondo livello con tesi svolta in azienda
%\NomeTutoreAziendale{Supervisore aziendale\\Centro Ricerche FIAT}
%\sedutadilaurea{Agosto 1615}% per la laurea quinquennale
%\esamedidottorato{Novembre 1610}% per il dottorato
%\sedutadilaurea{\textsc{Novembre} 2017}% per la laurea triennale
\sedutadilaurea{\textsc{Anno~accademico} 2020-2021}% per la laurea magistrale
%\annoaccademico{1615-1616}% solo con l'opzione classica
%\annoaccademico{2006-2007}% idem
%\ciclodidottorato{XV}% per il dottorato
\logosede{logopolito}
%
%\chapterbib %solo per vedere che cosa succede; e' preferibile comporre una sola bibliografia
%\AdvisorName{Supervisors}
%\newtheorem{osservazione}{Osservazione}% Standard LaTeX

%\usepackage[a-1b]{pdfx}
%\hypersetup{%
%    pdfpagemode={UseOutlines},
%    bookmarksopen,
%    pdfstartview={FitH},
%    colorlinks,
%    linkcolor={blue},
%    citecolor={green},
%    urlcolor={blue}
%  }

%
% per numerare e far comparire nell'indice anche le sezioni di quarto livello
% SCONSIGLIATO! da usarsi solo in caso di estrema necessità
%\setcounter{secnumdepth}{4}% section-numbering-depth
%\setcounter{tocdepth}{4}% TOC-numbering-depth (TOC=Table-Of-Content)

%\setbindingcorrection{3mm}

\errorcontextlines=9

\frontespizio
\paginavuota
\newpage
%per sfruttare meglio lo spazio nella pagina
\advance\voffset -5mm
\advance\textheight 30mm

% opzionale, solo se si vuole dedicare la tesi a delle persone care
\begin{dedica}
	
Thanks...

\end{dedica}

\sommario

Summary...

\ringraziamenti

Aknowledgments...

%% inserire sempre nella tesi per la laurea di I livello, perché il nome dei tutori non è indicato sul frontespizio.
%Il lavoro descritto in questa monografia è stato svolto sotto la supervisione
%del Prof. Antonio Lioy (tutore accademico)% inserire sempre il nome del tutore accademico
% e dell'Ing. Mario Rossi (tutore aziendale)% inserire solo se la monografia è relativa ad un tirocinio.
%.

%\tablespagetrue % normalmente questa riga non serve ed e' commentata
%\figurespagetrue % normalmente questa riga non serve ed e' commentata

\indici

\mainmatter

\chapter{Introduction}
\color{Gray}
While working on this document, I will mark with the colour \textcolor{Red}{red} the parts containing drafts and information got from outside sources. I will use the colour \textcolor{Orange}{orange} for parts under active modification, and the colour  \textcolor{Green}{green} for comments (apart from this one).

\color{Red}
The accelerating rate of malware incidents on daily basis indicates the magnitude of the problem in malware analysis. While malware analysts detect many malware attacks and incidents, keeping pace with the number and different types of attacks poses a significant challenge to malware analysts. There is no silver bullet with respect to malware, as there is no single malware analysis technique with the capability to treat all malware incidents, as a result analysts select the most suitable malware analysis technique for the specific security incident under consideration \cite{NaikEAGYRETE}.
\color{Black}

\chapter{Background}

\section{Malware}
\textbf{Malware}, short for \textbf{\textit{malicious software}}, is a general term for all types of programs designed to perform harmful or undesirable actions on a system. In fact in the context of IT security the term \textit{malicious software} commonly means \cite{SharpAIM}:

\begin{quote}
	\textit{Software which is used with the aim of attempting to breach a computer system's security policy with respect to Confidentiality, Integrity and/or Availability.}
\end{quote}

Malware consists of programming artefacts (code, scripts, active content, and other software) designed to disrupt or deny operation, gain unauthorized access to system resources, gather information that leads to loss of privacy or exploitation, and other abusive behaviour.
Malware is not (and should not be confused with) defective software - software that has a legitimate purpose but contains harmful bugs (programming errors).

Different companies, organizations and people describe malware in various ways. For example \textbf{Microsoft} defines it in a generic way as:

\begin{quote}
	\textit{Malware is a catch-all term to refer to any software designed to cause damage to a single computer, server, or computer network} \cite{MoirDM}.
\end{quote}

The \textbf{National Institute of Standards and Technology} (\textbf{NIST}), on the other hand, presents multiple definitions for malware, describing it as "hardware, firmware, or software that is intentionally included or inserted in a system for a harmful purpose" \cite{nistM}.

In another more specific definition \textbf{NIST} affirms that Malware is:

\begin{quote}
	\textit{A program that is inserted into a system, usually covertly, with the intent of compromising the confidentiality, integrity, or availability of the victim's data, applications, or operating system or of otherwise annoying or disrupting the victim} \cite{nistM}.
\end{quote}

Notice that, since the attacker can use a number of different means - such as executable code, interpreted code, scripts, macros etc. - to perpetrate its malicious intents, the term \textbf{\textit{software}} should be understood in a broader sense in the above definitions.\\
Moreover, the computer system whose security policy is attempted to be breached is usually known as the \textbf{\textit{target}} for the malware. Instead, the cybercriminal who originally launched the malware with the purpose of attacking one or more targets is generally referred to as the "\textit{initiator} of the malware". Furthermore, depending on the malware type, the initiator may or may not exactly know what the set of targets is \cite{SharpAIM}.\\
According to the above definitions software is defined as malicious in relation to an attempted breach of the target's \textbf{\textit{security policy}}.
In other words, software is often identified as malware based on its \textit{intended use}, rather than the particular technique or technology used to build it.

\subsection{Why is Malware used}
Generally, cybercriminals use malware to access targets' sensitive data, extort ransoms, or simply cause as much damage as possible to the affected systems.

More generally malware serves a variety of purposes. For example, the most common cybercriminals' uses of malware are: \cite{CraneWIM}

\begin{itemize}
	\item \textbf{To profit financially (either directly or through the sale of their products or services)}.
	For example, attackers may use malware to infect targets' devices with the purpose of stealing their credit account information or cryptocurrency. Alternatively, they may sell their malware to other cybercriminals or as a service offering (\textit{malware-as-a-service}).
	
	\item \textbf{As a means of revenge or to carry out a personal agenda}.
	For example, Brian Krebs of Krebs on Security was struck by a big DDoS attack in 2016 after having talked about a DDoS attacker on his blog.
	
	\item \textbf{To carry out a political or social agenda}.
	Nation-state actors (like state-run hacker groups in China and North Korea) and hacker groups such as Anonymous are a perfect example.
	
	\item \textbf{As a way to entertain themselves}.
	Some cybercriminals enjoy victimizing others.
\end{itemize}

Obviously there are also reasons for non-malicious actors to create and/or deploy some types of malware too - for example it can be used to test a system's security.

\subsection{Common Malware types}
There are numerous different ways of categorizing malware; one way is by \textit{how} the malicious software spreads. Another one is by what it \textit{does} once it has successfully infected its victim's computers (i.e. what is its payload, how it exploits or makes the system vulnerable).

\subsubsection{By how they spread}
Terms like \textit{trojan}, \textit{virus} and \textit{worm} are commonly used interchangeably to indicate generic malware, but they actually describe three subtly different ways malware can infect target computers \cite{SymantecDVWT}:

\begin{itemize}
	\item \textbf{\textit{Trojan horse}}. Generally speaking, a \textit{Trojan Horse}, commonly referred to as a "Trojan", is any program that disguises itself as legitimate and invites the user to download and run it, concealing a malicious payload. When executed, the payload - malicious routines - may immediately take effect and cause many undesirable effects, such as deleting the user files or installing additional malware or PUAs (Potentially Unwanted Apps).
	
	Trojans known as \textit{droppers} are often used to start a worm outbreak, by injecting the worm into users' local networks \cite{MullinsMT}.
	
	Trojans may hide in games, apps, or even software patches, or they may rely on social engineering and be embedded in attachments included in phishing emails.
	
	Trojan horses cannot self-replicate. They rely on the system operators to activate. However, they can grant the attacker remote access permitting him to then perform any malicious activity that is in their interest. Trojan horse programs can affect the host in many different ways, depending on the payload attached to them \cite{NamanyaTWM}.
	
	\item \textbf{\textit{Virus}}. The term "computer virus" is used for describing a passive self-replicating malicious program. Usually spread via infected websites, file sharing, or email attachment downloads, it will lie dormant until the infected host file or program is activated. At that point it spreads to other executables (and/or boot sectors) by embedding copies of itself into those files. A virus, in fact, in order to spread from one computer to another, usually relies on the infected files possibly ending up, by some means or another, in the target system. Viruses are therefore passive. The mean of transport (file, media file, network file, etc.) is often referred to as the virus \textit{vector}. Depending on how complex the virus code is, it may be able to modify its copies upon replication. For the transport of the infected files to the target system(s), the virus may rely on an unsuspecting human user (who for example uses a USB drive containing the infected file) or initiate itself the transfer (for example, it may send the infected files as an e-mail attachment) \cite{SharpAIM}.
	
	Viruses may also perform other harmful actions other than just replicating, such as creating a backdoor for later use, damaging files, stealing information, creating botnets, render advertisements or even damaging equipment.
	
	\item \textbf{\textit{Worm}}. On the other hand, a worm is a self-replicating, active malicious program that exploits various system vulnerabilities to spread over the network. Particularly, it relies on vulnerabilities present in the target's operating system or installed software. Worms usually consume a lot of bandwidth and processing resources due to continuous scanning and may render the host unstable, sometimes causing the system to crash. Computer worms may also contain "payloads" to damage the target systems. Payloads are pieces of code written to perform various nefarious actions on the affected computers among which stealing data, deleting files or creating bots - which can lead the infected systems to become part of a botnet \cite{NamanyaTWM}.
	
\end{itemize}

These definitions lead to the observation that viruses require \textit{user intervention} to spread, whereas a worm spreads itself automatically. A virus, however, cannot execute or reproduce unless the application it infected is running. This dependence on a host program makes viruses different from trojans, which require users to download them, and worms, which do not use applications to execute.

Furthermore, attackers can also install malware "manually" on a computer, either by gaining physical access to the target system or by using privilege escalation methods to obtain remote administrator access \cite{FruhlingerME}.

\subsubsection{By what they do}
There are a wide range of potential attack techniques used by malware, here are some of them:

\begin{itemize}
	\item \textbf{\textit{Adware}}. \textit{Adware}, or "Advertising supported software", is any software package which automatically plays, displays, or downloads advertisements to a computer. Some adware may also re-direct the user's browser to dubious websites. These advertisements can be in the form of a pop-up ads or ad banners in websites, or advertisements displayed by software, that lure the user into making a purchase. The goal of Adware is to generate revenue for its author.
	
	Often times software and application authors offer "free", or discounted, versions of their creations that come bundled with adware. Adware, in fact, is usually seen by the developers as a way to recover development costs. The income derived from ads may motivate the developer to continue developing, maintaining and upgrading his software product. On the other hand users may see advertisements as annoyances, interruptions, or as distractions from the task at hand \cite{MullinsMT}.
	
	Adware, by itself, is annoying but somewhat harmless, since it is solely designed to deliver ads; however, adware often comes bundled with spyware (such as keyloggers), and/or other privacy-invasive software that is capable of tracking user activity and steal information. Adware-spyware bundles are therefore much more dangerous then adware on its own \cite{DuPaulCMT}.
	
	\item \textbf{\textit{Backdoor}}. A \textit{backdoor}, also called Remote Access Trojan (RAT), is a vulnerability deliberately buried into software's code that allows to bypass typical protection mechanisms, like credentials-based login authentication. In other words, it is a method of circumventing normal authentication procedures. Once a system has been compromised (by others types of malware or other methods), one or more backdoors may be installed. This is done with the purpose of allowing the attacker easier access in the future without alerting the user or the system's security programs. Moreover, backdoors may also be installed before other malicious software, to allow attackers entry \cite{MullinsMT}.
	
	Many device or software manufacturers ship their products with intentionally hidden backdoors to allow company personnel or law enforcement to access the system when needed \cite{IngallsTOM}. Alternatively, backdoors are sometimes hidden in programs also by intelligence services. For example, Cisco network routers, which process large volumes of global internet traffic, in the past were equipped with backdoors intended for US Secret Service use \cite{MyraSecurityWIM}.
	
	However, when used by malicious actors, backdoors grant access to attackers without the user knowledge, thus putting the system in real danger.
	
	\item \textbf{\textit{Browser Hijacker}}. A \textit{Browser Hijacker}, also called "hijackware", is a type of malicious program which considerably modifies the behaviour of the victim's web browser. For example it can force the browser to send the user to a new search page, slow down the loading, change the victim's home page, install unwanted toolbars, redirect the user to specific sites, and display unwanted ads without the user consent.\\
	It can be used to make money off ads, to steal information from users, or to infect the systems with other malware by redirecting users to malicious websites \cite{IngallsTOM}.
	
	\item \textbf{\textit{Bots}/\textit{Botnet}}. In general, \textit{bots} (short for 'robots') are software programs designed to automatically perform specific operations. Bots were originally developed to programmatically manage chat IRC channels - Internet Relay Chat: a text-based communication protocol appeared in 1989.\\
	Some bots are still being used for legitimate and harmless purposes such as video programming, video gaming, internet auctions and online contest, among other functions. It is however becoming increasingly common to see bots being used maliciously. Malicious bots can be (and usually are) used to form botnets. A botnet is defined as a network of host computers (zombies/bots) that is controlled by an attacker - the \textit{bot-master} \cite{NamanyaTWM}. Botnets are frequently used for DDoS (Distributed Denial of Service) attacks, but there are other ways that botnets can be useful to cybercriminals: \cite{CraneWIM}
	
	\begin{itemize}
		\item \textbf{Brute force \& credential stuffing} - Bots can be used to carry out different types of brute force attacks on websites. For example they can use a pre-configured list of usernames and passwords combinations on website login pages with the hope of finding a winning combination, after enough tries.
		
		\item \textbf{Data and content scraping} - Botnets can be used as web spiders to scour websites and databases to gather useful information - such as site content, pricing sheets, etc. - which can be used to obtain an unfair advantage against the competition.
		
		\item \textbf{Botnet-as-a-service opportunities} - Botnets are sometimes rented out by their creators to all kinds of malicious users - including less tech-savvy ones. Doing so, even inexperienced attackers can carry out attacks, such as taking down a target's servers and networks with a DDoS, using these mercenary bots. This service model is sometimes called malware-as-a-service.
		
		\item \textbf{Spambot} - A botnet can also be used to act as a spambot and render advertisements on websites.
		
		\item \textbf{Malware distributor} - Finally Botnets can even be used for distributing malware disguised as popular search items on download sites.
	\end{itemize}
	
	\item \textbf{\textit{Crypto-miner}}. Crypto-miners are a relatively new family of malware. Cybercriminals employ this type of malicious tools to mine Bitcoin and/or other bitcoin-alike digital currencies on the target machine. The victim system's computing power is used for this, without the owner realising it. The mined coins end up in the attackers' digital crypto wallets.
	
	Recently, a more modern method of crypto-mining that works within browsers (also called crypto-jacking), has become quite popular.
	
	In some cases, the use of crypto-miners may be deemed legal. For example they could be used to monetize websites, granted that the site operator clearly informed visitors of the use of such tools \cite{MyraSecurityWIM}.
	
	Finally, according to ESET, most crypto-miners focus mostly on \textit{Monero} as target crypto-currency because it offers anonymous transactions and can be mined with regular CPUs and GPUs instead of expensive, specialized hardware \cite{CraneWIM}.
	
	\item \textbf{\textit{File-less malware}}. File-less malware is a type of memory-resident malware that uses legitimate code already existing within the target computer or device to carry out attacks. As the term suggests, it is malware that operates from a victim's computer memory, not from files on the hard drive, taking advantage of legitimate tools and software (known as "LOLBins" \cite{CraneWIM}) that already exist within the system. File-less malware attacks leave no malware files to scan and no malicious processes to detect. Since there are no files to scan, it is harder to detect and remove than traditional malware; this makes them up to ten times more successful than traditional malware attacks \cite{BakerMCTM}. Furthermore, it also renders forensics more difficult because when the victim's computer is rebooted the malware disappears.
	
	\item \textbf{\textit{Keylogger}}. Keystroke logging (often called \textit{keylogging}) is the action of secretly tracking (or logging) keystrokes on a keyboard, without the person using the keyboard knowing that its actions are being monitored. The collected information is stored and then sent to the attacker who can then use the data to figure out passwords, usernames and payment details, for example. There are various methods used to perform keylogging, ranging from hardware and software-based approaches to the more sophisticated electromagnetic and acoustic analysis \cite{MullinsMT}. Key loggers can be inserted into a system through phishing, social engineering or malicious downloads.
	
	There are various methods used to perform keylogging, ranging from hardware and software based approaches to electromagnetic and acoustic analysis.
	
	To this extent keyloggers can be considered as a sub-category of spyware.
	
	Keylogging also has legitimate uses, in fact it is often used by law enforcement, parents, and jealous or suspicious spouses. The most common use, however, is in the workplace, where employers monitor employee use of company computers.
	
	\item \textbf{\textit{RAM Scraper}}. \textit{RAM scraper} malware, also known as \textit{Point-of-Sale (POS)} malware, targets POS systems like cash registers or vendor portals, harvesting data temporarily stored in RAM (Random Access Memory). Doing so the attacker can access unencrypted credit card numbers \cite{IngallsTOM}.
	
	\item \textbf{\textit{Ransomware}}. \textit{Ransomware}, also known as "encryption" or "crypto" Trojan, is a malicious program that, after having infected a host or network, holds the system captive and requests a ransom from the host/network users. In particular it encrypts data on the infected system (or anyway locks down the system so that the users have no access) and only unblocks it when the correct password - decryption key - is entered. The latter is not given to the victims until after they have paid the ransom to the attacker. Messages informing the system user of the attack and demanding a ransom are usually displayed. Without the correct decryption key, it's mathematically impossible for victims to decrypt and regain access to their files.
	
	Digital currencies such as Bitcoin and Ether are the most common means of payment, making it difficult to track the cybercriminals. Moreover, paying the ransom does not guarantee the user to receive the necessary decryption key or that the one provided is correct and functions properly. Additionally, some forms of ransomware threaten victims to publicize sensitive information within the encrypted data.
	
	Ransomware is one of the most profitable, and therefore one of the most popular, and dangerous kinds of malware programs of the past few years.
	
	The "Five Uneasy E's" of ransomware, according to Tim Femister \cite{FemisterEHL} - vice president of digital infrastructure at ConvergeOne - are:
	
	\begin{itemize}
		\item \textbf{Exfiltrate}: Capture and send data to a remote attacker server for later leverage.
		\item \textbf{Eliminate}: Identify and delete enterprise backups to improve odds of payment.
		\item \textbf{Encrypt}: Use leading encryption protocols to fully encrypt data.
		\item \textbf{Expose}: Provide proof of data and threaten public exposure and a data auction if payment is not made.
		\item \textbf{Extort}: Demand an exorbitant payment paid via cryptocurrency.
	\end{itemize}

	\item \textbf{\textit{Rogue Security Software}}. \textit{Rogue Security Software} can be considered as a from of scareware. This type of malware program presents itself as a security tool to remove risks from the user's system. In reality, this fake security software installs more malware onto their system \cite{IngallsTOM}.
	
	\item \textbf{\textit{Rootkit}}. A \textit{rootkit} is generally thought as a type of malicious software, or a collection of software tools, designed to remotely access or control a computer without being detected by users or security programs. An attacker who has installed a rootkit on a system is able to remotely execute files, log user activities, access/steal information, modify system configurations, alter software (including security software), install hidden malware, mount attacks on other systems or control the computer as part of a botnet. Since a rootkit operates stealthily and continually hides its presence, its prevention, detection and removal can be difficult; in fact, typical security product are often not effective in detecting rootkits. Rootkit detection therefore often relies on manual methods such as monitoring the computer's behaviour for irregular activity, scanning system file signatures, and analysing storage dumps \cite{DuPaulCMT}.
	
	More recently, the term "rootkit" has also often been used to refer to concealment routines in a malicious program. These routines are highly advanced and complex and are written to hide malware within legitimate processes on the infected computer. In fact, once a malicious program has been installed on a system, it is essential that it remains hidden, to avoid detection and disinfection. The same is true when a human attacker directly breaks into a computer. Techniques known as rootkits allow for this concealment by modifying the host's operating system so that malware is hidden from the user. They can prevent a malicious process from being visible in the system's process list or prevent its files from being read \cite{MullinsMT}.
	
	Traditionally, rootkits can install themselves in kernel level (ring 0), although some sources state that they can install themselves all the way up to user level (ring 3). This means that they can get as much (or as little) access as necessary.
	
	There are different types of rootkits, which are typically categorized by the reach of the system they affect: \cite{IngallsTOM}
	
	\begin{itemize}
		\item \textbf{\textit{User-level/application level rootkits}} - User-mode rootkits run in Ring 3, along with other applications as user. They can alter security settings, allowing the attacker to replace executables and system libraries.
		
		\item \textbf{\textit{Kernel-level rootkits}} - Kernel-mode rootkits run in ring 0, the highest operating system privileges (Ring 0). They manage to do so by modifying the core functionality of the operating system - the kernel. They usually add code or replace portions of the core operating system, including both the kernel and associated device drivers.
		
		\item \textbf{\textit{Bootkit rootkits}} - A Bootkit rootkit is a type of kernel-mode rootkit which infects startup code like the Master Boot Record (MBR), Volume Boot Record (VBR), or boot sector, subverting the kernel upon computer start up.
		
		\item \textbf{\textit{Virtualization rootkits}} - This type of rootkit, also called \textit{Hypervisor rootkit}, runs in Ring -1 (before the kernel) and hosts the target operating system as a virtual machine. It manages to do so by exploiting hardware virtualization features. This in turn enables the rootkit to intercept hardware calls made by the original OS.
		
		\item \textbf{\textit{Hardware/firmware rootkits}} - A firmware rootkit uses device or platform firmware to create a persistent malware image in hardware. The rootkit hides in firmware, because the latter is not usually inspected for code integrity.
	\end{itemize}

	\item \textbf{\textit{Scareware}}. Scareware is a generic term for malware that uses social engineering to frighten and manipulate a user, inducing him into thinking their system is vulnerable or has been attacked.
	However, in reality no danger has actually been detected: it is a scam.	The attack succeeds when the user purchases unwanted - and potentially dangerous - software in an attempt to eliminate the "threat". Generally, the suggested software is additional malware or allegedly protective software with no value whatsoever \cite{MyraSecurityWIM}.
	
	Both Rogue Security Software and Ransomware can be considered as scareware, together with other scam software.

	Some versions of scareware act as a sort of shadow version of ransomware; they claim to have taken control of the victim's system and demand a ransom. However they are actually just using tricks - such as browser redirect loops - to fool the victim into thinking they have done more damage than they really have \cite{FruhlingerME}.
	
	\item \textbf{\textit{Spyware}}. 
	
	\textit{Spyware}, another name for \textit{privacy-invasive software}, is a type of malicious software that uses functions in the infected host's operating system with the aim of spying on the user activity. Specifically it can collect various types of personal information about users, such as Internet browsing habits, credit card details and passwords, without their knowledge. The information gathered is then sent back to the responsible cybercriminal(s). The presence of spyware is typically hidden from the user, and can be difficult to detect.
		
	However, the functions of spyware often go far beyond simple activity monitoring and information gathering. In fact, they may also interfere with the user's control of the computer in other ways, such as installing additional software and redirecting web browser activity. Spyware is known to change computer settings, often resulting in slow connection speeds, different home pages, and/or loss of Internet connection or functionality of other programs. They spread by attaching themselves to legitimate software, Trojan horses, or even by exploiting known software vulnerabilities \cite{MullinsMT}.
	
	Law enforcement, government agencies and information security organizations often use spyware to monitor communications in a sensitive environment or during an investigation. Spyware is however also available to private consumers, allowing them to spy on their employees, spouse and children \cite{McAfeeWIM}.
\end{itemize}

\subsubsection{Other cyber-threats}
Other cyber threats which are not strictly malware are, for example:

\begin{itemize}
	\item \textbf{\textit{Software Bug}}.
	A software bug is an error, or flaw, in a computer program code or system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. Usually, most of these defects arise from human errors made in the program's source code. Some bugs may be caused by compilers or operating systems component used by the program.
	
	Minor bugs only slightly affect the behaviour of a program. Therefore it can be a long time before they are discovered. On the other hand, more significant bugs can cause crashes or freezes. It is safe to say that almost all software has bugs and most bugs go unnoticed or have a slight impact on the user.
	
	However, other bugs qualify as security bugs. These are the most serious type of bugs since they can allow attackers to bypass access controls such as user authentication, override access privileges, or steal data.
	
	The frequency of bugs can be reduced through developer training, quality control, and code analysis tools \cite{DuPaulCMT}.
	
	\item \textbf{\textit{Malvertising}}. Malvertising is the use of legitimate ads or ad networks to covertly deliver malware to unsuspecting users' computers.
	
	For example, a cybercriminal might pay to place an ad on a legitimate website. When a user clicks on the ad, code in the ad either redirects them to a malicious website or installs malware on their computer.
	
	In some cases, the malware embedded in an ad might execute automatically without any action from the user, a technique referred to as a "drive-by-download".
	
	\item \textbf{\textit{Phishing}}. Phishing is a type of social engineering attack commonly used to perform cyber attacks. Particularly in a phishing attack, the attacker attempts, through email messages, to trick users into divulging passwords (or anyway personal and financial information), downloading a malicious attachment or visiting a website that installs malware on their systems.
		
	Some phishing emails are highly sophisticated and can deceive even experienced users, especially if the attacker has successfully compromised a known contact's email account and uses it to spread phishing attacks or malware such as worms. Others are less sophisticated and simply spam as many emails as possible with messages such as "Check your bank account details" \cite{ComtactWDYM}.
		
	There are different types of Phishing. Here are mentioned some of them: \cite{IngallsTOM}
	
	\begin{itemize}
		\item \textit{Deceptive Phishing} - The most common type. It uses an email headline with a sense of urgency from a know contact. This attack blends legitimate links with malicious code, modifies brand logos, and evades detection with minimal content.
		
		\item \textit{Spear Phishing} - Spear phishing targets specific users or organizations by researching the victim to maximise trick potential. For example the attacker may explore social media, record out-of-office notifications, compromise API tokens etc. in order to better fool the target user.
		
		\item \textit{Whaling} - Whaling is similar to spear phishing, but even more targeted. In fact, it targets chief officers of organizations using various social engineering tricks such as impersonating employees or co-workers and using phone calls - to name a few - to give a sense of legitimacy to malicious emails.
		
		\item \textit{Vishing} - Vishing targets phone users. It uses the Voice over Internet Protocol (VoIP), technical jargon, and ID spoofing to trick a caller into revealing sensitive information.
		
		\item \textit{Smishing} - Smishing also targets phone users. It uses, however malicious text messages (SMS).
		
		\item \textit{Pharming} - Pharming leverages cache poisoning against the DNS with the objective of redirecting users to fake websites.
	\end{itemize}

	\item \textbf{\textit{Spam}}.
	
	In cybersecurity, unsolicited emails are generally referred to as \textit{spam}. Typically, spam includes emails carrying unsolicited advertisements, fraud attempts, links to malicious websites or malicious attachments. Most spam emails contain one or more of the following: \cite{IngallsTOM}
	
	\begin{itemize}
		\item Poor spelling and grammar
		\item Unusual sender address
		\item Unrealistic claims
		\item Suspicious links
	\end{itemize}

	Spam might be one of the most universally understood forms of malicious attacks. As billions of users enable email for their everyday lives, it makes sense that malicious actors try to sneak into their inbox. Some of the most common types of spam emails include fake responses, PayPal, returned mail, and social media. All of which are disguised as legitimate but contain malware.
\end{itemize}

\subsubsection{General considerations on malware types}
Malware samples are usually categorised both by a means of infection and a behavioural category: for instance, WannaCry is a ransomware worm.\\
Moreover, a particular piece of malware may have various forms with different attack vectors: e.g., the banking malware called \textit{Emotet} has been spotted in the wild as both a trojan and a worm \cite{FruhlingerME}.\\
Finally, many instances of malware fit into multiple categories: for example Stuxnet is both a worm, a virus and a rootkit.

Furthermore, in recent years, targeted attacks on mobile devices have also become increasingly popular.
In fact, among the huge amount of available apps, an increasing quantity is not desirable; the problem is even worse when considering third-party app stores. Even when app store providers impose filters and manual checks to prevent the malicious apps from being available, some inevitably slip through.
These mobile malware threats are as various as those targeting desktops and include Trojans, Ransomware, Advertising click fraud and more. They are mostly distributed through phishing and malicious downloads and are a particular problem for jail-broken phones, which tend to lack the default protections that were part of those devices' original operating systems.

\subsection{Malware History}
Malware history began in the 1960s. Then, hackers used to design computer viruses mainly for fun, as an exciting prank/experiment; their creations would generally display harmless messages and then spread to other computers \cite{ReganWIM}.
There are numerous examples of malware created at that time within a laboratory setting: for example the \textbf{\textit{Darwing game}} in 1962, \textbf{\textit{Creeper}} in 1971, \textbf{\textit{Rabbit Virus}} in 1974 and \textbf{\textit{Pervading Animal}} in 1975.

In particular, the malware called \textbf{\textit{Creeper}} was designed to infect mainframes on ARPANET. The program did not alter the machines' functions, nor it stole or deleted data. It only displayed the message "I'm the creeper: Catch me if you can" while illegitimately spreading from one mainframe to another. This malware was later upgraded with the ability to self-replicate and became the first known computer worm \cite{LutkevichM}.

In the early 1980s, the concept of malware caught on in the technology industry, and numerous examples of viruses and worms appeared both on Apple and IBM personal computers. With the introduction of the World Wide Web and the commercial internet in the 1990s it eventually became widely popularized, so much that Yisreal Radai coined the term \textbf{malware} in 1990.

The previously mentioned 1960s and 1970s malware were all kept within a laboratory environment and never managed to escape to the wild. \textbf{\textit{Elk Cloner}} (1981) was the first known virus to have been able to escape its creation environment. Then, following the success of that prank gone wild, the first Microsoft PC virus, called \textbf{\textit{Brain}}, was created in 1986. Again, like \textit{Elk Cloner}, Brain was mostly annoying rather than harmful, but it was also the first known virus capable of concealing its presence on the disk thus evading detection. In 1988 the first worm, called \textbf{\textit{Morris}} worm, an experimental, self-propagating, self-replicating program was released on the internet \cite{NamanyaTWM}. In 1988 made its appearance also the first example of intentionally harmful virus, the \textbf{\textit{Vienna}} virus, which encrypted data and destroyed files. This led to the creation of the first antivirus tool ever \cite{ReganWIM}.

In the following decades malware has evolved both regarding its complexity and malware sample numbers.

In the appendix, section \ref{NotableMalwareExamples}, a list of the most famous examples of malware attacks/incidents of recent history can be found.

\section{Detection evasion}
From the creation of the first malware in 1970 \cite{Szor_P}, there has been a strong competition between attackers and defenders. To defend from malware attacks, anti-malware groups have been developing increasingly complex (and clever) new techniques. On the other hand, malware developers have conceived and adopted new tactics/methods to avoid the malware detectors.

The first type of anti-malware tools were mostly based on the assumption that malware structures do not change appreciably during time. In fact, initially, the malware machine code was completely unprotected. This allowed analysts to exploit opcode sequences to recognise specific malware families. 
Recently, however, a big advancement led to the so-called "second generation" malware \cite{Sharma_2014} which, to evade such opcode signatures, employs several obfuscation techniques and can create variants of itself. This posed a challenge to anti-malware developers.

The first time a malware has been recognised to exhibit detection avoidance behaviour was in 1986 with the \textit{Brain} virus \cite{SkoudisFMC}. In fact, such malware managed to conceal the infected disk section whenever the user attempted to read it, forcing the computer to display clean data instead of the infected part. From that moment on, the ever increasing popularity of detection evasion techniques among malware writers has shown that malware survival has become the number one priority: the longer the malware remains undetected, the more harm it can do and the more profitable it is to its writer \cite{NamanyaTWM}.

\subsection{Reverse-Engineering}
\textit{Reverse engineering}, in broad terms, indicates the process of extracting knowledge, ideas, design philosophy etc. from anything man-made \cite{EilamRSRE}.

Software reverse engineering is, of course, the application of reversing methodologies and techniques to extract knowledge from a software product to better understand its inner workings.

Reversing is used extensively by both malicious actors and investigators but with opposing purposes. Malware developers often use it to discover vulnerabilities in systems or programs, while analysts and antivirus software developers use it to analyse malicious programs to understand how they work, what damages they can cause, how they infect the system and reproduce, how they can be removed, detected and avoided.

\subsection{Malware analysis}
Malware analysis is the process of extracting as much information as possible from malicious samples discovered in the wild, which usually are in the form of machine code executables (compiled executables), in order to determine their purpose and functionality (and threats associated). This process allows security teams to develop effective detection techniques against the analysed malicious code, contain its damage, reverse its effects on the system, develop removal tools that can delete it from infected machines (to cleanly remove a piece of malware from an infected machine it is usually not enough to delete the binary itself) and design methods to guard systems against future infections \cite{BayerDAMC}.

Initially malware analysts/researchers had to manually analyse each malware sample. This process is however complex, requires high expertise, and is time-intensive. Moreover, the number of malware samples that need to be analysed on a daily basis is nowadays of the order of hundreds. This implies that the analysis of malware samples can no longer be done exclusively manually. Several analysis tools have been developed in recent years to facilitate analysts in analysing malware samples.

Traditionally, there are two main types of analysis: \textit{static} and \textit{dynamic}. Moreover, these two types can be, and frequently are, combined together (\textit{hybrid} analysis) in various stages of malware analysis to optimize results \cite{NamanyaTWM}.

\subsubsection{Static analysis}
\textit{Static analysis} consists of examining an executable file's code without actually executing it. Static analysis techniques usually extract peculiar features from malicious samples in order to be able to recognise them and distinguish them from benign ones. The features usually extracted are, for example, string signatures, byte-sequence n-grams, library or API calls, opcode frequency distributions, peculiar attributes found in the executable header etc. However, this approach, being based on signatures/features extracted from already analysed samples, is not much effective on zero-day and evolutionary malware.

A malware analyst performing manual static analysis usually disassembles the binary first, meaning that he 'translates' the program's machine code instructions back into assembly language ones generating a more human-interpretable code listing. On the latter, control flow, data flow analysis, and many others static techniques can be employed to try understating the program functionality and inner workings, among other useful information \cite{BayerDAMC}.

Static analysis advantages are, among others, that it takes into account the entire program code and it is also usually faster (and safer) than the dynamic one. However, a general disadvantage of static analysis is that many times the information collected during this type of analysis is very simple and not always sufficient for a conclusive decision on the malicious intent of a file. It is, however, good practice to start the analysis of a suspicious executable file extracting as much information as possible through various static techniques before passing to the dynamic counterpart. The information statically extracted may in fact provide useful knowledge to better apply dynamic techniques and enhance the final results.

Additionally, another common problem to deal with when using static analysis is that, since malicious code is written directly by the adversary, it can be purposefully designed to be hard to analyse statically. For example, analysis evasion techniques like packing, encryption and obfuscation can be exploited by malware authors to hinder both disassembly and code analysis steps typical of static analysis approaches, ultimately leading to incorrect or useless information \cite{NamanyaTWM}.

\subsubsection{Dynamic analysis}
Contrary to static analysis, \textit{dynamic techniques} analyse the program's code while or after execution in a controlled environment. These techniques, while being non-exhaustive, they have the significant advantage that they analyse only those instructions that are actually executed by the running process. This implies that dynamic analysis is less susceptible to anti-analysis attempts like code obfuscation or anti-disassembly \cite{BayerDAMC}. Moreover, dynamic analysis is also more effective in terms of malicious behaviour detection, since it doesn't look at the disassembled code but, through the use of monitoring tools, it tracks the operations that the code performs on the file system, registry, network etc. It is however, computationally more expensive and time consuming.

Basic dynamic analysis consists of observing the sample under analysis interacting with the system. For example, this can be done taking a snapshot of the original system state, introducing the malware into the system, executing it and finally comparing the new system state with the original one. The changes detected can then be used for infection removal on infected systems and/or for modelling effective signatures/features.

Advanced dynamic analysis, on the other hand, consists of directly examining the executed malware internal state while it is being run. This is done typically by monitoring the APIs and OS function calls invoked, the files created and/or deleted, the registry changes and the data processed by the program under analysis during its interaction with the system. The information extracted in this way can be used to understand the malware behaviour and functionality \cite{NamanyaTWM}.

When using dynamic techniques, however, malware analysts don't simply run malware executables on their own computer, which most probably is even connected to Internet, as they could easily escape the analysis environment and infect other hosts/networks. It is, in fact, advised to deploy dynamic techniques on "safe" and controlled (isolated) environments such as dedicated stand-alone (and isolated) hosts, virtual machines or emulators.

The use of clean dedicated hosts, reinstalled after each dynamic analysis run, is however not the most efficient solution due to the environment re-installation process overheads. On the other hand, using virtual machines (for example VMware) to perform dynamic analysis is more efficient. In fact, in this case, since the malware only affects the virtual machine environment, it is enough, after a dynamic analysis run, to simply discard the infected hard disk image and replace it with a clean one. Unfortunately, a significant drawback is that the malware being analysed may determine it is running in a virtualized environment and, as a result, modify its behaviour. To counter this last problem one could make use of emulators, which are theoretically undetectable by analysed malware. These tools, however, run the code under analysis significantly slower and are therefore sometimes detectable using specially crafted time-related code.

\subsubsection{Hybrid analysis}
Hybrid Analysis is the combination of static and dynamic analysis. It is a technique that integrates run-time information extracted through dynamic analysis with information extracted  through static analysis in order to have a complete view of the malware's behaviour while avoiding the problems posed by anti-analysis techniques as much as possible.

\subsection{Anti-reversing}
\textit{Anti-reversing} techniques are techniques originally meant to make the reverse engineering process difficult for a hacker or any malicious user. The main objective of various anti-reverse engineering techniques is simply to complicate the process of reversing as much as possible. For example an attacker could use the disassembly of a binary in order to get an insight of the logic of the code as well as getting hidden information.

Recently anti-reversing techniques are, however, extensively used also by malware authors in order to make their creations difficult to analyse in an attempt to postpone detection as much as possible.

There exist several anti-reversing approaches, each with its own advantages and disadvantages. However it is common practice to use a combination of more than one of them. In the next sections some of the more common anti-reversing techniques are discussed.

\subsection{Anti-disassembly}
\textit{Anti-disassembly} techniques use specially crafted code and/or data in a program to cause disassembly analysis tools to generate an incorrect program listing \cite{SikorskiPMA}. The attackers' usage of these techniques thus implies a time-consuming analysis for malware analysts, ultimately preventing the retrieval of the source code in a reasonable time.

Any executable code can be reverse engineered, but by armouring their code with anti-disassembly and anti-debugging techniques, attackers increase the skill level required by analysts.
Furthermore, anti-disassembly techniques may also inhibit various automated analysis tools and heuristic-based engines which take advantage of disassembly analysis to identify or classify malware.

These techniques exploit the inherent weaknesses present in disassembler algorithms. Moreover, disassemblers, in order to work properly, make certain assumptions on the code being analysed. However, when these assumptions are not met, there is an opportunity for malware authors to deceive the analyst.

For example, while disassembling a program, sequences of executable code can have multiple disassembly representations, some of which may be invalid and obscure the real purpose of the program.
Thus, the malware authors, in order to add anti-disassembly functionality to their creations, can produce sequences of code that deceive the disassembler into outputting a list of instructions that differs from those that would be executed \cite{SikorskiPMA}.

There are two types of disassembler algorithms: linear and flow-oriented (recursive).
The linear one is easier to implement, but it is also more simplistic and error-prone.

\subsubsection{Linear Disassemblers}
The \textit{linear} disassembly strategy is based upon the basic assumption that the program's instructions are organized one after the other, linearly. In fact, this type of disassemblers iterates over a block of code, disassembling one instruction at a time, sequentially, without deviating. More specifically, the tool uses the size of the currently disassembled instruction to figure out what bytes to disassemble next, without accounting for control-flow instructions \cite{SikorskiPMA}.

Linear disassemblers are easy to implement and work reasonably well when working with small sections of code. They introduce, however, occasional errors even with non-malicious binaries. The main drawback of this technique is that it blindly disassembles code until the end of the section, assuming the data is nothing but instructions packed together, without being able to distinguish between code, data and pointers.

In a PE-formatted executable file, for example, the executable code is typically contained inside a single ".text" section. However, for almost all binaries, this code section contains also data, such as pointer values. These pointers will be blindly disassembled and interpreted by the linear disassembler as instructions.

Malware authors can exploit this weakness of linear-disassembly algorithms implanting data bytes that form the opcodes of multi-byte instructions in the code section.

\subsubsection{Flow-Oriented Disassemblers}
The \textit{flow-oriented} (or \textit{recursive}) disassembly strategy is more advanced than the previous one and is, in fact, the one used by most commercial disassemblers like \textit{IDA Pro} \cite{SikorskiPMA}.

Differently form the linear strategy, the flow oriented one examines each instruction, builds a list of locations to disassemble (the ones reached by code) and keeps track of the code flow.

This implies that, if disassembling a code section we find a JMP instruction, this type of disassembler will not blindly parse the bytes immediately following the JMP instruction?s ones, but it will disassemble the bytes at the jump destination address.

This behaviour is more resilient and generally provides better results, but also implies a greater complexity.

In fact, while a linear disassembler has no choices to make about which instructions to disassemble at any given time, flow-oriented disassemblers have to make choices and assumptions, in particular when dealing with conditional branches and call instructions.\\
Particularly, in the case of conditional branches, the disassembler needs to follow both the false branch (most flow-oriented disassemblers will process the false branch of any conditional jump first) and the true one. In typical compiler-generated code there would be no difference in output if the disassembler processes first one branch or the other. However, in handwritten assembly code and anti-disassembly code, taking first one branch or the other can often produce different disassembly for the same block of code, leading to problems in analysis.

\subsubsection{Anti-Disassembly Techniques}

\paragraph{Jump Instructions with the Same Target}
One of the most used anti-disassembly techniques consists of two consecutive conditional \textit{jump} instructions both pointing to the same target \cite{SikorskiPMA}.

Here is an example:
\begin{lstlisting}[caption={Jump Instructions with the Same Target}, label=JumpSameTarget, language={[x86masm]Assembler}, style=mystyle]
	74 03		jz 	loc
	75 01		jnz	loc
	
	loc:
\end{lstlisting}

In this case, the conditional jump '\textbf{jz loc}' is immediately followed by a jump to the same target but with opposite condition: '\textbf{jnz loc}'. This implies that the location \textbf{loc} will always be jumped to.
Consequently, the combination of \textbf{jz} with \textbf{jnz} acts, in this case, like an unconditional \textbf{jmp} instruction. A disassembler, however, since it disassembles just one instruction at a time, won't recognize this combination as being an unconditional branch. During the disassembly process, in fact, if a \textbf{jnz} instruction is encountered, the disassembler will take the false branch of the instruction and will continue disassembling, even though this branch will never be executed in practice.

\paragraph{Jump Instructions with a Constant Condition}
Another common anti-disassembly technique is composed of a single conditional \textit{jump} instruction with an always true (or false) condition \cite{SikorskiPMA}.

Example:
\begin{lstlisting}[caption={Jump Instructions with a Constant Condition example}, label=JumpConstant, language={[x86masm]Assembler}, style=mystyle]
	33 C0		xor	eax, eax
	74 01		jz 	loc
	
	loc:
\end{lstlisting}

The first instruction in the example code, \textbf{xor eax, eax}, sets the \textbf{EAX} register to zero and, consequently, it sets the zero flag. The next instruction, \textbf{jz} (jump if zero flag is set), appears to be a conditional jump but in reality is not conditional at all. In fact the the zero flag will always be set at this point in the program execution. The disassembler, however, will process the false branch first, even if in reality it would never trigger.

\paragraph{Impossible Disassembly}
The simple anti-disassembly techniques mentioned above are frequently coupled with the use of a, so called, \textit{rogue byte}. A \textit{rogue byte} is a data byte strategically placed after a conditional \textit{jump} instruction in order to trick the disassembler. The byte inserted usually is the opcode for a multi-byte instruction, therefore disassembling it prevents the real following instruction from being properly disassembled. This byte is called \textit{rogue byte} because it is not part of the program logic flow and it is inserted in the code with the only purpose of fooling the disassembler \cite{SikorskiPMA}.

In all these cases, however, a reverse engineer is able to properly disassemble the code with the use of interactive disassemblers like IDA Pro, ignoring the \textit{rogue bytes}.

However, there are some conditions in which no traditional assembly listing can accurately represent the instructions that are executed. Exploiting these conditions we obtain what are called \textit{impossible disassembly} techniques. The code produced using these techniques can however be disassembled, but only using a vastly different representation of the code than what is provided by currently available disassemblers.

The core idea behind these techniques is to make the \textit{rogue byte} part of a legitimate instruction that is executed at runtime. This way the \textit{rogue byte} becomes not ignorable during disassembly. In this scenario any given byte may be a part of multiple instructions that are executed. This is done using \textit{jump} instructions. The processor, while running the code, will interpret and execute the bytes following the logical flow of the program, so there is no limitation on the number of instructions the same byte can be part of; a disassembler, however, has such limitations since it will usually represent a single byte as being part of a single instruction.

Example:
\begin{lstlisting}[caption={Impossible Disassembly example}, label=ImpossibleDisassembly, language={[x86masm]Assembler}, style=mystyle]
	EB 
				JMP -1
	FF
				INC EAX
	C0
	48		DEC EAX
\end{lstlisting}

In this simple example the first instruction is a 2-byte \textit{jmp -1} instruction (\textbf{EB FF}). Its target is the its own second byte. At run time this causes no errors because the \textbf{FF} byte is the first byte of the next instruction \textit{inc eax} (\textbf{FF C0}).

However, when disassembling, if the disassembler interprets the \textbf{FF} byte as part of the \textit{jmp} instruction, it won't be able to interpret it also as the beginning of the \textit{inc eax} instruction. While the \textbf{FF} byte is in reality part of both instructions that actually execute, the disassembler is not able to recognise this.

The 4-byte example code increments the \textbf{EAX} register, and then decrements it, therefore it is essentially a complex \textbf{NOP} sequence. Being a simple, and small, sequence it could be inserted at any location in a program code in order to fool disassemblers. However this sequence it is also easily recognisable by reverse engineers and substituted with \textbf{NOP} instructions using IDA Pro or other instruments and/or scripts. Another alternative is to interpret this sequence as data bytes forcing the disassembler to skip it.

However this was only a simple example sequence. More complex and ingenious sequences can be made to fool disassemblers while being harder to detect.

\subsubsection{Obscuring Flow Control}
Control-flow analysis (CFA) is a static-code-analysis technique for determining the control flow of a program. Modern disassemblers like IDA Pro are able to correlate function calls and extract high-level information about the program knowing how functions are related to each other \cite{SikorskiPMA}.

Control-flow analysis can however be easily defeated by malware authors.

\paragraph{The Function Pointer Problem}
Function pointers are a common programming idiom present in programming languages such as \textbf{C}, while being extensively used in the background in object oriented languages like \textbf{C++} and \textbf{Java} \cite{SikorskiPMA}.

As opposed to referencing a data value, a function pointer points to executable code within memory. Dereferencing the function pointer yields the referenced function, which can be invoked and passed arguments to as in a normal function call. Since, doing so, the function is being invoked indirectly through a variable instead of directly through a fixed identifier or address, such invocation is also known as an "indirect" call. In assembly code this corresponds to a \textit{call} instruction with a function pointer as argument.

Function pointers, however, greatly reduce the information that can be automatically extracted by the disassembler about the program control flow. Moreover, if function pointers are used in specially crafted, or non-standard code, the resulting code can be difficult to reverse-engineer without the use of dynamic analysis techniques.

As a result, function pointers, in combination with other anti-disassembly techniques, can greatly increase the complexity and difficulty of reverse-engineering.

\paragraph{Return Pointer Abuse}
Among the instructions capable of transferring control within a program we already mentioned the \textit{call} and \textit{jmp} instructions, however there are more \cite{SikorskiPMA}.

The counterpart to the \textit{call} instruction is \textit{retn}. When a call instruction is reached during program execution, a return pointer is pushed on the stack, before jumping to the call instruction target. This return pointer in the stack will point to the address of the instruction immediately following the end of the \textit{call} instruction itself.
Therefore a \textit{call} instruction can be seen as the combination of a \textit{jmp} and \textit{push}; a \textit{retn} instruction, on the other hand, is the combination of \textit{pop} and \textit{jmp}.

The \textit{retn} instruction pops the last value pushed to the stack and jumps to it; it is therefore typically used to return from a function call, but it could also be used for other purposes. When used for such other reasons the disassembler is generally fooled, because it still will interpret it as a return from a function call. Therefore it won't show any code cross-reference to the target being jumped to. As added benefit the disassembler will also prematurely terminate the function being analysed.

\paragraph{Misusing Structured Exception Handlers}\label{MisusingStructuredExceptionHandlers}
Another powerful anti-disassembly technique exploits the Structured Exception Handling (\textbf{SEH}) mechanism. Performing program flow control using this mechanism is able to fool both disassemblers and debuggers \cite{SikorskiPMA}.

\textbf{SEH} provides programs a way to handle error conditions intelligently. \textit{C++} and other programming languages heavily rely on exception handling (and therefore on \textbf{SEH}) when compiled for x86 systems.

Exceptions can be triggered for numerous reasons: for example when dividing by zero or accessing an invalid memory region. Moreover, software exception can also be raised by the code itself by calling the \textit{RaiseException} function.

When an exception is raised it makes its way through the \textbf{SEH} chain, which is a list of functions specifically designed to handle exception, until it is caught by one exception handler in the chain. Each function in the list can either handle the exception (a.k.a. \textit{catch} it) or pass it to the next handler in the list. \textit{Unhandled exceptions} are the ones that make their way to the last handler. The last exception handler is the code responsible for triggering the 'unhandled exception' message to the user. 

Exception handling is used in almost all programs and exceptions happen regularly in most processes (and are handled silently). A malicious actor could, however, exploit this mechanism to achieve covert flow control by adding his own specially crafted handler on top of the \textbf{SEH} chain.

This can be done at runtime simply pushing some specific values on the stack, effectively adding a new entry in the Exception handling chain. This procedure, however, is subject to the constraints imposed by the Software Data Execution Prevention (\textbf{Software DEP}), which is a security feature that prevents the addition of third-party exception handlers at runtime. However various workarounds to this protection can be used in the case of handwritten assembly code.

\subsection{Anti-debugging}
Another popular anti-analysis technique, besides anti-disassembly, is \textit{anti-debugging}. Malware authors use anti-debugging techniques to recognise when their malicious program is under the control of a debugger or to interfere with the debugger behaviour. This is done in an attempt to slow down the malware analysts who use debuggers to understand how the malware operates. A malware using these techniques usually alter its normal control flow paths or causes crashes if it detects it is running in a debugger, thus interfering with analysis \cite{SikorskiPMA}.

\subsubsection{Windows Debugger Detection}
In Windows OS various techniques can be used to detect if a process is being run in a debugger: from exploiting the Windows API itself, to manually checking memory structures for debugging artefacts \cite{SikorskiPMA}.


\paragraph{Using the Windows API}
One of the most obvious, and simple, ways to know if a debugger is attached to a process is by using Windows API functions. Inside the Windows API there are, in fact, functions that were specifically designed to detect debuggers; moreover some functions that were originally created with other purposes can also be used for debugger detection \cite{SikorskiPMA}.

Malware analysts can counter this technique by manually modifying the malware code during execution modifying the resulting flag after the call to make sure the desired path is taken, or by straight up removing/skipping the function call.

Here are some examples of common Windows API functions used for \textit{anti-debugging}:
\begin{itemize}
	\item \textbf{IsDebuggerPresent}
	This is the simplest API function that can be used for debugger detection. It determines whether the \textbf{current} process is being debugged by a user-mode debugger. It does so by getting the value of the field \textit{IsDebugged} from the Process Environment Block (\textbf{PEB}) structure. In particular this functions returns zero if the process is not running within a debugger context and a non-zero value otherwise.
	
	\item \textbf{CheckRemoteDebuggerPresent}
	This API function is similar to the previously described one (\textit{IsDebuggerPresent}). This function checks for a 'remote' debugger on the specified process. The term 'remote' in the name CheckRemoteDebuggerPresent does not imply that the debugger necessarily resides on a different machine; instead, it indicates that the debugger resides in a separate and parallel process. This function takes a process handle as argument, and will check if that process has a debugger attached. It can however be used also to check the current process by passing its handle.
	
	\item \textbf{NtQueryInformationProcess}
	This function can retrieve different kinds of information from a process. The first argument for this function is the process handle, the second one is the ProcessInformationClass parameter which specifies the information you want to get. When using the value \textit{ProcessDebugPort} for this parameter, for example, the function will return a zero if the process is not currently being debugged; a non-zero value representing the debugger port number will instead be returned otherwise.
	
	\item \textbf{OutputDebugString}
	This function, originally designed to just send a string to a debugger for display, can be used to detect the presence of a debugger. In fact, in there is no debugger attached, the function will internally set the last-error code. In a few lines of code it is thus possible to know if a debugger is present or not:
	
	\begin{lstlisting}[caption={OutputDebugString debugger detection}, label=OutputDebugString, language=C, style=mystyle]
	DWORD errorValue = 12345;
	// set custom last error code
	SetLastError(errorValue);
	
	// try outputting string on debugger;
	// if no debugger is present, it will set
	// the last-error code to a new value
	OutputDebugString("Test for Debugger");
	
	if(GetLastError() == errorValue){
		// a debugger is present
		ExitProcess();
	}
	else{
		// no debugger was detected
		RunMaliciousPayload();
	}
	\end{lstlisting}
	
\end{itemize}

\paragraph{Manually Checking Structures}
Malware authors usually don't exploit the Windows API functions for detecting the presence of a debugger, but they prefer checking the PEB structure (and others) by themselves. One of the reasons why they usually don't like using Windows API functions is that API calls can be easily hooked by a rootkit to return false information, thus thwarting this technique \cite{SikorskiPMA}.

\begin{itemize}
	\item \textbf{Checking the BeingDebugged Flag}
	The Windows PEB structure contains all user-mode parameters associated with a process, including the process's environment data such as environment variables, addresses in memory and debugger status, among other things.
	
	Malware can 'manually' check the \textit{BeingDebugged} flag within the PEB structure to understand if a debugger is attached its process. More precisely if this flag is zero it means that no debugger is attached.
	
	Example of code listing performing 'manual' \textit{BeingDebugged} check:
	\begin{lstlisting}[caption={BeingDebugged manual check}, label=BeingDebuggedManual, language={[x86masm]Assembler}, style=mystyle]
	mov		eax,	dword ptr fs:[30h]	; get PEB address
	mov		ebx,	byte ptr [eax+2]		; get BeingDebugged flag value
	test	ebx,	ebx									; test if the value is 0
	jz		NoDebuggerDetected				; if 0, no debugger was detected
	\end{lstlisting}
	
	Malware analysts can counter this technique detecting this code sequence in the code and then wither manually changing the \textit{BeingDebugged} flag to zero, or forcing the jump to be taken (or not) by manually modifying the zero flag before the jump instruction.
	
	\item \textbf{Checking the ProcessHeap Flag} 
	The \textit{ProcessHeap}, which is an undocumented location within a reserved array inside the PEB structure, contains the location of the first heap of a process allocated by the loader. This heap can be used for debugger detection since it contains some information telling if it was created within a debugger or not. In particular malware usually check the values of the fields called \textit{ForceFlags} and \textit{Flags}.
	
	To overcome this technique, malware analysts can change the \textit{ProcessHeap} flags manually or use a hide-debug plug-in for their debugger.
	
	\item \textbf{Checking NTGlobalFlag}
	Processes started within a debugger run slightly differently than others, therefore they create memory heaps differently. The information needed to determine how to create heap structures is stored at an undocumented location in the PEB. Practically, a value of \textit{0x70} at this location indicates that the process is running within a debugger.
	
	Again, in order to counter this technique, malware analysts can change the flags manually or use a hide-debug plug-in for their debugger.
	
\end{itemize}

\paragraph{Checking for System Residue}
Debugging tools typically leave traces of their presence on the system. Malicious programs can therefore be designed to search for these traces in the system in order to determine when it is being analysed. For example malware can search for references to debuggers in the registry keys \cite{SikorskiPMA}.

Moreover, malware can also be designed to search the system for files and directories commonly related to debuggers, such as debugger program executables.

Furthermore, malware can also detect debugger residues in live memory, by viewing the current process listing or, more commonly, by performing a \textit{FindWindow} in search for a debugger.

\subsubsection{Identifying Debugger Behaviour}
Debuggers are very useful to malware analysts because they can be used to set breakpoints in the code or even to single-step through a process running code to ease the reverse-engineering process. These operations, however, modify the process code and are therefore easily detectable \cite{SikorskiPMA}.

\paragraph{INT Scanning}
A common anti-debugging technique used by malware authors consists in making the process scan its own code in search for an \textbf{INT 3} (opcode \textit{0xCC}). \textbf{INT 3} is, in fact, a software interrupt used by debuggers: when setting a breakpoint the debugger replaces the target instruction in the running program with the opcode \textit{0xCC} (INT 3) which causes the process to call the debug exception handler \cite{SikorskiPMA}.

Malware analysts can counter this technique exploiting hardware breakpoints instead of software ones.

\paragraph{Performing Code Checksums}
Another anti-debugger technique consists in calculating the checksum of a section of the process' own code. This has the same net effects as scanning the code for software interrupts. However, instead of explicitly searching for a specific opcode (\textit{0xCC}) in the process code, this check performs a cyclic redundancy check (CRC) or a MD5 checksum of the malware code \cite{SikorskiPMA}.

Again this technique can be countered by using hardware breakpoints instead of software ones, or by modifying the program's control flow at runtime with a debugger.

\paragraph{Timing Checks}
One of the most widespread techniques for debugger detection is to perform \textit{timing checks}. Processes, in fact, tend to run substantially slower when executed within a debugger context. Moreover analysts usually run programs in single steps in order to better understand the code behaviour, this in turn greatly increases execution time \cite{SikorskiPMA}.

Using timing checks it is possible to detect a debugger in different ways:
\begin{enumerate}
	\item Recording 2 timestamps before and after the execution of some operations and then comparing them. If the lag is greater than a specified threshold then a debugger is probably being used.
	\item Recording 2 timestamps before and after raising an exception. If the current process is being debugged then the exception will be handled by the debugger itself more slowly than normal. Moreover, by default, debuggers ask for human intervention when an exception occurs, thus causing huge delays.
\end{enumerate}

\begin{itemize}
	\item \textbf{Using the \textit{rdtsc} Instruction}
	The most common timing check method uses the \textit{rdtsc} instruction. This instruction returns the number of ticks since the last system reboot. Malware authors thus use it as described above: rdtsc is called twice, once before and once after some other operations, and then the difference between the results is calculated. If too much time has elapsed between the two calls it means that a debugger is probably being used.
	
	\item \textbf{Using \textit{QueryPerformanceCounter} and \textit{GetTickCount}}
	These are two Windows API functions that can be used similarly to \textit{rdtsc} for debugger detection.
	
	More precisely \textit{QueryPerformanceCounter} can be called to query a high-resolution counter available to processors which stores counts of activities performed by the processor.
	
	The function \textit{GetTickCounter}, on the other hand, returns the number of milliseconds that have elapsed since the last reboot, very similarly to what the \textit{rdtsc} instruction does.
	
	Both of those functions, when used as described above, allow the malware to detect the presence of a debugger.
\end{itemize}

Anti-debugging though the use of timing checks can be discovered by malware analysts during debugging or static analysis by identifying specific sequences of instructions. Moreover, these checks usually detect debuggers only when the analyst is single-stepping though the code or setting a breakpoint between the two time related instruction calls.
This implies that, to counter this technique, malware analysts could avoid setting breakpoints and single-stepping in those regions of code, or modify the result of the timestamps comparison as needed.

\subsection{Anti-virtual machine}
Malware analysts often use virtual machines (VMs) or other isolated environments like sandboxes, to analyse malware samples. With the purpose of evading analysis and bypassing security systems malware authors often design their code to detect isolated environments. The techniques used with such purpose are called \textit{Anti-virtual machine} techniques (Anti-VM). Once a virtual machine is detected the evasion mechanism may alter the malware?s behaviour, or it may even prevent the malicious code from running altogether \cite{SikorskiPMA}.

\subsubsection{VMware Artefacts}
Virtual machines are designed to emulate real hardware functionality. To achieve that, however, some artefacts inevitably remain on the system, which can reveal that a virtual machine is indeed being used. These kind of artefacts can be specific files, processes, registry keys, services, network device adapters etc. \cite{SikorskiPMA}.

Here are some examples of anti-virtual machine techniques applied to detect VMware virtualization software:
\begin{itemize}
	\item \textbf{Checking for Processes Indicating a VM}.
	When a VMware virtual machine is running and VMware tools is installed, three VMware-related processes can be found in the system process listing: \textit{VMwareService.exe}, \textit{VMwareTray.exe} and \textit{VMwareUser.exe}. A malicious software can therefore easily detect if VMware is being run searching through the process listing for the \textit{VMware} string.
	
	\item \textbf{Checking for Existence of Files Indicating a VM}.
	The VMware default installation path usually also contains artefacts. Searching for the string \textit{VMware} in such location may reveal the use of a virtualized environment.
	
	\item \textbf{Checking for Registry Keys}.
	VMware Tools may leave some artefacts also in the registry. More specifically the presence of specific registry entries may reveal the use of VMware.
	
	\item \textbf{Checking for Known Mac Addresses}.
	In order to connect a virtual machine to a network it needs to have its own virtual network interface card (NIC). This implies that VMware needs to create a MAC address for the virtual machine, to associate to its NIC. However, depending on VMware configuration, this may lead to the network adapter being able to identify VMware usage. VMware utilises, in fact, addresses with a specific starting sequence which depends on its current version. Therefore a malicious software just needs to check the system MAC address against common VMware values.
\end{itemize}

In order to counter anti-virtual machine techniques, malware analysts need to apply a two step process: identify the check for VMware artefacts and then 'manually' patch it. For example, depending on the anti-VM technique used, they may patch the malware code while debugging to artificially make all checks pass, or modify the name of VMware processes in order to make them undetectable by the malicious software.

\subsubsection{Vulnerable Instructions}
The virtual machine monitor program, which monitors the virtual machine execution, has some security weaknesses that may allow malware to detect its usage. In particular, in order to avoid performance issues deriving from fully emulating all instructions, VMware allows certain instructions to execute without being properly virtualized. This in turn means that certain instruction sequences may return different results when running within a VMware virtualized environment than they do on native hardware. This discrepancy can be used by malware authors to detect VMware usage \cite{SikorskiPMA}.

However, those instructions previously mentioned are not typically used within a malicious program unless it is specifically performing VMware detection, because they are useless if executed in user mode. Therefore avoiding this type of anti-VM technique can be as easy as patching the malicious code to prevent it calling these instructions.

\subsection{Packers and unpacking}
Packing programs, commonly known as \textit{packers}, are software programs that take an \textit{executable file} or \textit{dynamic link library (DLL)}, compresses and/or encrypts its contents and then packs it into a new executable file \cite{SikorskiPMA}.

When packers are used on malicious programs, the malicious code appearance is changed as a consequence of the compression and/or encryption. The packed file will thus hinder basic static analysis and malware detection. Moreover, a packer specifically designed to make the file difficult to analyse may even employ anti-reverse-engineering techniques, such as anti-disassembly, anti-debugging or anti-VM on the resulting compressed version; on top of that some packers, using randomization, are also able to generate different variants of a single file every time it is packed \cite{LiPRTCMP}.

Malware authors have thus increasingly been using these tools to hide their creations from anti-malware solutions and malware analysts. In order to analyse packed malware, in fact, it must be unpacked first. Properly unpacking a packed program generally is, however, not easy.

A packed file usually contains two basic components:
\begin{itemize}
	\item A number of data blocks containing the compressed and/or encrypted original executable file.
	
	\item An unpacking stub able to dynamically recover the original executable file at runtime.
\end{itemize}

When the packed file is executed, the unpacking stub is loaded by the OS and begins unpacking the original executable code in memory. When the unpacking has been fully completed the control flow is transferred, with a \textit{jmp}, \textit{call} or the more stealthy \textit{retn} instruction (also referred to as the \textit{tail jump}), to the original file entry point (OEP). This implies that someone attempting to perform static analysis on the packed program, would actually analyse the unpacking stub and not the original code.

\subsubsection{Packer types}
Commercial and custom made packers can be divided in several levels of complexity depending on the packing techniques used and the additional features they have.
The authors of \cite{PedreroDPI} identified 6 packer main types with increasing complexity.
Packer types from 1 to 5 allow, sooner or later at runtime, to have a complete view over the original (unpacked) malicious code, meaning that the unpacker stub unpacks all the code at once. However, what makes them differ is the amount and complexity of the encryption (and obfuscation) methodologies used during packing. On the other hand, type 6 packers unpack only a slice of code at a time in memory, never revealing the whole original code altogether. This implies that malware analysts need to take several memory dumps, instead of only one, if they want to get the complete unpacked code.

Another possible classification of packers can be made based on their purposes and behaviours. Following this idea packers can be broadly classified into four categories \cite{WeiRPM}:

\begin{itemize}
	\item \textbf{Compressors} utilise compression to shrink files while exploiting few or no anti-unpacking tricks. Popular compressors include the Ultimate PE Packer (UPack), Ultimate Packer for Executables (\href{https://upx.github.io/}{UPX}), and \href{http://www.aspack.com/}{ASPack}.
	
	\item \textbf{Crypters} encrypt and obfuscate the original file contents. No compression is usually done. Malware developers widely use crypters such as \href{https://sourceforge.net/projects/yodap/}{Yoda's Crypter} and PolyCrypt PE.
	
	\item \textbf{Protectors} combine features from both compressors and crypters. Some popular commercial protectors are Armadillo and \href{https://www.oreans.com/Themida.php}{Themida}.
	
	\item \textbf{Bundlers} are used to pack a software package of multiple executable files into a single bundled executable file. These files within the package can then be unpacked and accessed without extracting them to disk. Some common PE bundlers are \href{https://www.bitsum.com/pebundle.asp}{PEBundle} and \href{https://www.molebox.com}{MoleBox}.
\end{itemize}

\subsubsection{Packers detection}
Packed executables can be detected through a heuristic approach known as \textit{Shannon Entropy Calculation}. Entropy is, generally speaking, a measure of uncertainty, disorder, in a system or program. The idea behind this approach is that compressed or encrypted executables tend to resemble random data, thus they have higher entropy than unencrypted/uncompressed programs. This approach, however, does not tell any information about the packer used to obtain the packed sample \cite{SikorskiPMA}.

One common way to tackle this problem is through packer signatures checking. Tools like \href{https://www.aldeid.com/wiki/PEiD}{PEiD} and Sigbuster use such method. These tools are, however, not always successful due to the huge number of packer variations and evolutions present in the wild, and the fact that malware authors frequently modify commercially available packers code or create their own packers so that their packed malicious programs do not match any known signature.

\subsubsection{Unpacking}
Unpacking is the process of restoring the original contents from packed executables in order to allow AV programs and security researchers to analyse the original executable code. There are three different techniques to unpack a packed executable: \textit{automated static unpacking}, \textit{automated dynamic unpacking} and \textit{manual unpacking} (\cite{SikorskiPMA}, \cite{WeiRPM}).

Automated static unpacking programs are dedicated routines designed to decompress and/or decrypt executables packed by specific packers, without actually executing the suspicious programs. This method, when it works, is the fastest and most secure method to unpack an executable. Automatic static unpackers are, however, specific to a single packer. Moreover, they are not able to unpack packed samples that were created with the intention to hinder analysis.

Automated dynamic unpackers, instead, use programs to run or emulate the packed executable allowing the unpacking stub to unpack the original executable code in memory. Once the original executable is unpacked, the in-memory program's code is written on disk, and the automated unpacker reconstructs the original import table.

Most often security researchers prefer to perform manual unpacking. The two most common approaches used  to manually unpack a program are:
\begin{itemize}
	\item Discover what packing algorithm has been used to pack a sample and then write a program/script to revert it. This process is however time consuming.
	
	\item Manually run the packed program to allow the unpacking stub to unpack the original code in memory, then dump the process on disk and finally manually modify the PE header so that the program is complete. This process is more efficient than the previous one. 
\end{itemize}

\subsection{Code Obfuscation}
Obfuscation is a technique that generally makes programs harder to understand \cite{Balakrishnan2005CodeOL}, both for humans and automatic tools. To do so, it transforms a program into a new (structurally different) and more difficult to analyse version while retaining the same functionality as the original (the new version of the program is said to be \textit{computationally equivalent} to the original one) \cite{YouMOT}.

Originally, this technology was conceived for legitimate purposes to protect the intellectual property of software developers; however it has been widely exploited by malware authors to evade detection \cite{KonstantinouMV}. Particularly, in order to elude anti-malware scanners, malware can, using obfuscation techniques, evolve their body into new generations \cite{YouMalwareOT}, which eventually can be even harder to disassemble and analyse.

Obfuscation techniques can be broadly divided into 2 main sub-categories:
\begin{itemize}
	\item \textit{Data-based} obfuscation
	\item \textit{Control-based} obfuscation
\end{itemize}

However, malware authors usually combine those 2 types of obfuscation techniques in complex and difficult ways to strengthen the resulting obfuscation \cite{DangPRE}.

\subsubsection{Data-Based Obfuscation}
Data-based obfuscation techniques focus on modifying data values and non-control computations. In the following paragraphs some common data-based obfuscation techniques will be discussed.

\paragraph{Constant Unfolding}
\textit{Constant folding} is a technique commonly used by compilers to optimize a program's code. It does so by replacing expressions with results known at compile time with the results themselves \cite{DangPRE}.

For example, a compiler usually transforms the following expression \ref{ConstantFoldingBefore}, into \ref{ConstantFoldingAfter}.
\begin{lstlisting}[caption={Before constant folding}, label=ConstantFoldingBefore, language=C, style=mystyle]
	x = 4 * 5;
\end{lstlisting}

\begin{lstlisting}[caption={After constant folding}, label=ConstantFoldingAfter, language=C, style=mystyle]
	x = 20;
\end{lstlisting}

\textit{Constant unfolding} is, instead, an obfuscation technique that performs the exact inverse operation: it replaces the constants in the program's code with some expressions having the constant as a result.

For example, the listing \ref{ConstantUnfoldingBefore}, after \textit{Constant unfolding} may become \ref{ConstantUnfoldingAfter}. The two listings are equivalent. Moreover, there is an infinite amount of listings equivalent to \ref{ConstantUnfoldingBefore} that can be generated following this principle.
\begin{lstlisting}[caption={Before constant unfolding}, label=ConstantUnfoldingBefore, language={[x86masm]Assembler}, style=mystyle]
	push	0h
\end{lstlisting}

\begin{lstlisting}[caption={After constant unfolding}, label=ConstantUnfoldingAfter, language={[x86masm]Assembler}, style=mystyle]
	push	0F9CBE47Ah
	add		dword ptr [esp],	6341B86h
\end{lstlisting}

\paragraph{Data-Encoding Schemes}
The previously described technique is, however, easily defeated by simply applying the standard compiler's constant folding optimization. This is possible because both the data encoding and decoding functions ($f(x)=x-6341B86h$ and $f_{-1}(x)=x+6341B86h$ respectively) were present in the code one after the other. The use of \textit{fully Homomorphic} mappings (operation-preserving mappings) allow us to perform some operations on the encoded data before decoding it back, thus overcoming the previous technique's flaw. \textit{Fully Homomorphic} mappings are however still not widely used because still too inefficient \cite{DangPRE}.

\paragraph{Dead Code Insertion}
\textit{Dead code elimination} is another common compiler optimization technique. Its objective is to remove program statements/expressions that nave no real effects on the program operation and final results \cite{DangPRE}.

For example, the listing \ref{DeadCodeEliminationBefore}, using \textit{dead code elimination} would become \ref{DeadCodeEliminationAfter}.
\begin{lstlisting}[caption={Before dead code elimination}, label=DeadCodeEliminationBefore, language=C, style=mystyle]
	int f(){
		int x, y;
		x = 1;		// this assignement is useless, here x is dead
		y = 2;		// y is never used, it is thus dead.
		x = 3;
		return x;	// x is live
	}
\end{lstlisting}

\begin{lstlisting}[caption={After dead code elimination}, label=DeadCodeEliminationAfter, language=C, style=mystyle]
	int f(){
		return 3;
	}
\end{lstlisting}

Obfuscators, on the other hand, use the so-called \textit{dead code insertion} technique in an attempt to make the code harder to follow. This technique performs the inverse operation with respect to \textit{dead code elimination}, adding dead code in the original program's code.

However, when used alone, this techniques produces an obfuscated program that can be efficiently de-obfuscated by using the compiler's dead code elimination optimization.

\paragraph{Arithmetic Substitution via Identities}
This technique aims at replacing certain operators with combinations of other operators with equal net result. Exploiting the equivalence between different combinations of different operators the code can be changed arbitrarily without changing the effective program operation and final result \cite{DangPRE}. Here are some examples of operators equivalences:

\begin{lstlisting}[caption={Operators equivalences}, label=OperatorEquivalences, language=C, style=mystyle]
	-x == ~x + 1
	
	x-1 == ~-x
	
	x+1 == -~x
	
	rotate_left(x,y) == (x << y) | (x >> (bits(x) - y))
	
	rotate_right(x,y) == (x >> y) | (x << (bits(x) - y))
\end{lstlisting}

\paragraph{Register Reassignment}
Another simple obfuscation technique is called \textit{register reassignment}. An obfuscator using this technique switches the registers used throughout the code at every application, while keeping the same program code and behaviour \cite{YouMalwareOT}.

An analyst/attacker using wildcard searching, however, easily defeats this technique.

\paragraph{Instruction Substitution}
\textit{Instruction substitution} creates variants of a program's original code by replacing some instructions with other equivalent ones \cite{YouMalwareOT}.

\paragraph{Pattern-Based Obfuscation}
\textit{Pattern-based} obfuscation is another commonly used technique similar in principle to \textit{instruction substitution}, but more complex. It consists in constructing \textit{patterns} (transformations) that map single or multiple adjacent instructions into a more complex, computationally equivalent, sequence of instructions \cite{DangPRE}.

For example, the sequence \ref{PatternObfuscationOriginalSequence} might be converted into \ref{PatternObfuscationPattern1}, as well as into \ref{PatternObfuscationPattern2} or even \ref{PatternObfuscationPattern3}.

\begin{lstlisting}[caption={Original sequence}, label=PatternObfuscationOriginalSequence, language={[x86masm]Assembler}, style=mystyle]
	push	reg32
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation using pattern 1}, label=PatternObfuscationPattern1, language={[x86masm]Assembler}, style=mystyle]
	push	imm32
	mov		dword ptr [esp],	reg32
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation using pattern 2}, label=PatternObfuscationPattern2, language={[x86masm]Assembler}, style=mystyle]
	lea		esp,	[esp-4]
	mov		dword ptr [esp],	reg32
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation using pattern 3}, label=PatternObfuscationPattern3, language={[x86masm]Assembler}, style=mystyle]
	sub		esp,	4
	mov		dword ptr [esp],	reg32
\end{lstlisting}

Moreover, patterns can be arbitrarily complicated. For example a listing such as \ref{PatternObfuscationOriginalSequence2}, could be substituted by the more complex \ref{PatternObfuscation2Pattern}.

\begin{lstlisting}[caption={Original sequence \#2}, label=PatternObfuscationOriginalSequence2, language={[x86masm]Assembler}, style=mystyle]
	sub		esp,	4
\end{lstlisting}

\begin{lstlisting}[caption={Obfuscation of sequence \#2}, label=PatternObfuscation2Pattern, language={[x86masm]Assembler}, style=mystyle]
	push	reg32
	mov		reg32,	esp
	xchg	[esp],	reg32
	pop		esp
\end{lstlisting}

Malware authors (and also software developers wishing to protect their intellectual property) can use hundreds of patterns in the same program. Moreover, most protections randomly apply patterns so that obfuscating the same program multiple times yields different results. On top of that, patterns can also be applied iteratively: after transforming the original code \textbf{C} into \textbf{C'} using pattern \textbf{P}, another pattern \textbf{P'} can be applied to \textbf{C'} in order to obtain \textbf{C''}, and so on.

Some patterns preserve \textit{semantic equivalence}, meaning that the CPU state will be the same when executing them or the original code. Some other patterns, however, do not. Therefore, depending on the code logic, some substitutions are safe (meaning that the program behaviour and final results are preserved) while others are not. This makes the job of an obfuscator challenging.

\subsubsection{Control-Based Obfuscation}
Standard static analysis tools generally make assumptions similar to the ones human reverse engineers make when analysing code. Compilers, in fact, predictably translate control flow constructs and data structures. As a result, reverse engineers (and static analysis tools) can easily recognise the original code high level control flow. \textit{Control-based obfuscation} transforms the code control flow structures in non standard ways in order to complicate both static and dynamic code analysis \cite{DangPRE}.

Some examples of stanrard static analysis tools assumptions are:
\begin{itemize}
	\item The \textit{CALL} instruction is always used with the sole purpose of invoking functions.
	
	\item Both sides of a conditional branch may feasibly be taken at runtime.
	
	\item Function calls almost always return.
	
	\item All control transfers target code locations, not data locations.
	
	\item Exceptions are used in standard and predictable ways.
	
	\item etc..
\end{itemize}

By violating these assumptions, \textit{control-based obfuscation} techniques confuse disassemblers and other static analysis tools making the analysis more difficult.

\paragraph{Functions In/Out-Lining}
Reverse engineers frequently rely on control-flow and call graphs to better understand a program's high-level logic. In particular a call graph represents calling relationships between subroutines (functions) in a computer program. Each node of a call graph represents a procedure and each edge (\textbf{f}, \textbf{g}) indicates that procedure \textbf{f} calls procedure \textbf{g}. By making the call graph harder interpret, obfuscators can hinder the reverse engineers capability of understanding the program behaviour \cite{DangPRE}. To do so one could:

\begin{itemize}
	\item \textbf{Inline functions}.
	The code belonging to a subfunction is merged into the code of its caller. If a subfunction is called multiple times, however, the code size can quickly grow.
	
	\item \textbf{Outline functions}.
	A subpart of a function is extracted and transformed into an independent function and replaced by a call to the newly created function.
\end{itemize}

Using these two operations in combination on a program's code results in a degenerated call graph with no clear logic. Moreover, also the functions' prototypes can be modified adding extra fake arguments, reordering arguments and so on, to further hide the high-level logic.

\paragraph{Destruction of Sequential and Temporal Locality}
Usually, in non-obfuscated code, the instructions of a single basic block lie one after the other (\textit{sequential locality}), and basic blocks related to one another (such as successive blocks) are close to each other (\textit{sequential locality of temporally related code}). This is done in order to maximize the instruction cache locality and reduce the number of branches in the final code. Reverse engineers thus can usually rely on the fact that all the code responsible for a specific operation will reside in a single region \cite{DangPRE}.

Violating this assumption introducing unconditional branches that break sequential locality and temporal locality of multiple basic blocks makes manual analysis more difficult. However, by constructing the control-flow graph and removing spurious unconditional branches the original control flow can be restored.

\paragraph{Processor-Based Control Indirection}
Instructions like \textit{JMP} (branch) and \textit{CALL} (save instruction pointer and branch) are, for most processors, the 2 essential control flow transfer primitives. In order to make analysis more difficult, one could obfuscate these primitives for example using dynamically computed branch addresses or by emulating them.

For example the instruction \textit{JMP} instruction \ref{ProcessorBasedControlIndirectionBefore}, can be replaced by the (almost) semantically equivalent listing \ref{ProcessorBasedControlIndirectionAfter}.

\begin{lstlisting}[caption={Processor-based control indirection before}, label=ProcessorBasedControlIndirectionBefore, language={[x86masm]Assembler}, style=mystyle]
	jmp		target_addr
\end{lstlisting}

\begin{lstlisting}[caption={Processor-based control indirection after}, label=ProcessorBasedControlIndirectionAfter, language={[x86masm]Assembler}, style=mystyle]
	push	target_addr
	ret
\end{lstlisting}

\paragraph{Operating System-Based Control Indirection}
As already seed when talking about anti-disassembler techniques, obfuscation can also exploit operating system primitives and structures. For example, the Structured Exception Handler (\textit{SEH}), Vectored Exception Handler (\textit{VEH}) and Unhandled Exception Handler are commonly used to obfuscate the control flow of Microsoft Windows executables (in Unix-like systems the signal handlers \textit{setjmp} and \textit{longjmp} are commonly used instead) \cite{DangPRE}.

\paragraph{Subroutine Reordering}
\textit{Subroutine reordering} in an obfuscation technique that randomly changes the order of a program's subroutines in the original code. This technique can thus generate $n!$ code variations, where $n$ is the number of subroutines \cite{YouMalwareOT}.

\paragraph{Opaque Predicated}
An \textit{opaque predicate} is a non-trivial boolean expressions with a constant result (always true or always false) known only at compilation/obfuscation time. Combining it with a conditional \textit{jmp} instruction introduces an additional branch in the control flow graph (\textit{CFG}). We already briefly talked about this specific combination when talking about the \textit{Jump instruction with a constant condition} anti-disassembly technique. The added branch should look as real as possible in order to elude detection, and it can be used to insert junk code or to form cycles in the control-flow graph to better hide the original program's logic \cite{DangPRE}.

\subsubsection{Simultaneous Control-Flow and Data-Flow Obfuscation}
\textit{Data-flow obfuscation} and \textit{Control-flow obfuscation} techniques are commonly used together to complicate analysis.

\paragraph{Inserting Junk Code}
This technique consists in introducing a dead code block (meaning that it will never be executed at runtime) between two other code blocks. Typically used in conjunction with \textit{opaque predicates}, this technique is used to hinder a disassembler that is disassembling an invalid path. Moreover, the junk code typically contains partially invalid instructions, or branches to invalid addresses with the objective of over-complicating the CFG \cite{DangPRE}.

\begin{lstlisting}[caption={Junk Code example}, label=JunkCodeExample, language={[x86masm]Assembler}, style=mystyle]
	push	eax
	xor		eax,	eax
	jz		9
	;<junk code start>
	jg		4
	inc		esp
	ret
	;<junk code end>
	pop		eax
\end{lstlisting}

The listing \ref{JunkCodeExample} presents an example of this technique. More precisely the instruction at line 2 (\textit{xor eax, eax}) zeroes the \textit{EAX} register setting clearing the zero flag (it is set to 0); therefore the conditional jump (\textit{jz 9}) at line 3 is always taken at runtime. The immediately next instructions are therefore junk code.

\paragraph{Control-Flow Graph Flattening}
\textit{Control-flow graph flattening} consists in replacing all control structures within a sub-part of the control flow graph with a single switch statement commonly called \textit{dispatcher}. This is done to hide the true basic blocks relationships within the dispatcher. When using this technique, first a subpart of the program's control flow graph is selected to be substituted by the dispatcher. Some transformations may then be applied to the basic blocks inside the chosen sub-graph (they split or merged) to further complicate analysis and finally each basic block updates the dispatcher's context to reflect the relative basic block relationships. The final resulting graph offers no clues about the structure of the algorithm, but has the same logic \cite{DangPRE}.

\textit{CFG flattening} is frequently used, together with \textit{opaque predicates}, to insert dead code paths in the CFG.

\paragraph{Code Transposition}
An obfuscator using the technique called \textit{code transposition} effectively reorders the sequence of a program's original code instructions without changing its behaviour \cite{YouMalwareOT}. To achieve this two approaches are commonly followed:
\begin{itemize}
	\item Randomly shuffling the instruction and then recovering the original execution order by inserting unconditional branches. This is easily defeated restoring the original program by removing (and following) the unconditional branches.
	
	\item Choosing and reordering independent instructions that have no impact on the others. This approach is harder to implement given the complexity of finding independent instructions, but it is more effective.
\end{itemize}

\paragraph{Code Virtualization}
\textit{Code virtualization} consists in transforming a program's binary code (compiled for a specific machine) into a different binary code that is understood by a virtual machine. More specifically, the instruction set from the source machine is converted into a new instruction set, understood by the target virtual machine. This can be done using multiple types of virtual machines with different instruction sets. This means that a specific block of, for example, Intel x86 instructions can be converted into a different instruction set for each machine, preventing an analyst/attacker from recognizing any generated virtual opcode after the transformation from x86 instructions \cite{DangPRE}. 

Usually, some specific blocks of the program's code are virtualized (and not the whole program) and inserted back into the program alongside the associated interpreter. At run time, the interpreter assumes execution control and translates the virtualized code back to the original byte code.

When an analyst/attacker tries to decompile a virtualized block of code, however, he will not find the original x86 instructions. Instead, he will find a completely new instruction set which is not recognized by him or any other special decompiler. This will force the attacker to identify how each opcode is executed and how the specific virtual machine works for each protected application. 

Some examples of code virtualization tools include \href{https://vmpsoft.com/}{VMProtect} and \href{https://www.oreans.com/CodeVirtualizer.php}{CodeVirtualizer}.

\paragraph{Code Integration}
\textit{Code integration}, one of the most sophisticated obfuscation techniques, was first introduced by \textit{Win97/Zmist} malware. A malware using this technique first decompiles the target program into a set of manageable objects, it then inserts itself between them and finally it reassembles the code \cite{YouMalwareOT}.

\subsection{Obfuscated Malware}
The huge amount of malware released in the wild since the creation of the first virus in 1960s can be split into two generations. More specifically, the first generation malwares were static, their code and behaviour did not change. The more sophisticated second generation malwares, on the other hand, change their internal structure between one variant and the other maintaining the same malicious behaviour in order to avoid detection.

\subsubsection{Encrypted Malwares}
The first second-generation malwares ever existed exploited encryption in order to evade detection by signature-based antivirus scanners.

In this approach, an encrypted malware typically consists of two parts: the encrypted main body and a decryption code (also called \textit{decryptor}). The \textit{decryptor}'s objective is to recover the original malware code from the encrypted body whenever the infected file is run \cite{YouMOT}.

Moreover, to hide from signature-based scanners, encrypted malware encrypts its code using a different key at each infection, thus creating a unique encrypted body. The decryption routine (\textit{decryptor}), however, remains the same from one generation to another. This means that encrypted malwares can be detected with signature-based scanners by searching for the decryptor's code pattern \cite{Sharma_2014}.

The first known malware to exploit encryption for detection evasion was CASCADE which spread in the 1980s and early 1990s.

Encryption of malware code is often used in conjunction with the use of packers.

\color{Black}
\subsubsection{Packed Malwares}
Malware authors are nowadays increasingly exploiting packers (or even multiple packers at once) to produce numerous variants of the same original malware code \cite{NamanyaTWM}.

As stated by Perdisci, et al \cite{PerdisciCPEACVD}, more than 80\% of the new malware currently discovered are actually packed versions of already existing malware.

Packers are used to compress the original file into a smaller size and, moreover, encryption is sometimes applied to the compressed version of the file in order to make the unpacking process more difficult.

However, it is not uncommon to see malware authors writing and using custom packers. This fact can be used by analysts to detect if a file is malicious, without further analysis, based on the fact that benign software vendors would almost never use custom packers. On the other hand, many malware authors frequently use commercial, and readily available, packers to generate malware variants.

\subsubsection{Oligomorphic Malwares}
Malware authors tried to overcome the short comings of encrypted malware developing malware that can mutate the used decryptor from one variant to another. Initially the decryptor could only be changed slightly. However, a common method used by \textit{oligomorphic malware}, also called '\textit{semipolymorphic}', to provide more diverse decryptors is, in practice, to randomly select one decryption routine at infection time from a set of pre-defined different decryptors \cite{Sharma_2014}.

However, this type of malware is able to generate at most few hundreds different decryptors. For example the virus called \textit{Win95/Memorial} was capable of constructing up to 96 different decryptor patterns. This means that signature-based detection techniques are still able to detect \textit{oligomorphic malwares} by generating the signature of all the decryptors utilised by the malware strain \cite{YouMOT}. Still, signature based techniques are not an effective approach to detect \textit{oligomorphic malware}.

The virus named \textit{Whale} was the first known malware to make use of this technique. It carried a few dozens of different decryptors and picked one randomly at infection time \cite{NamanyaTWM}.

\subsubsection{Polymorphic Malwares}
The \textit{oligomorphic} malware limitations lead malware authors to develop a more advanced type of malware called \textit{polymorphic}.

In \textit{polymorphic} malware countless numbers (millions) of distinct decryptors can be generated by using obfuscation methods including, for example, \textit{dead-code insertion}, \textit{register reassignment}, \textit{subroutine reordering}, \textit{instruction substitution}, \textit{code transposition/integration}, etc. to avoid signature based detection \cite{YouMOT}.

\textit{Polymorphic} malware, like \textit{oligomorphic} malware, consists of two parts: the malware encrypted main body and the decryptor. The decryptor is again run once the malware is executed and it enables the execution of the original malware code decrypting the encrypted body. When replication occurs, the malware encrypts its code with a different key, generates the new associated decryptor and encloses it in the new malware variant code. The malware appearance is thus changed at each infection \cite{Sharma_2014}.

In order to have a wide range of decryptors, \textit{polymorphic} malware typically use a powerful toolkit called 'the \textit{Mutation Engine} (\textit{MtE})'. In particular, during malware replication, the mutation engine is used to create the new decryptor which is appended to the new malware variant code. The mutation engine is, in fact, responsible for rearranging the decryptor code using different obfuscation techniques in order to prevent signature based detection.

Even though \textit{polymorphic} malware can create a large number of different decryptors effectively hindering signature matching techniques, still the constant malware body, which appears after decryption, can be used for detection. In particular, by using emulation techniques, the tool execute the malware in a '\textit{Sandbox}' without resulting in any harm to the system. As soon as the constant malware body is decrypted and loaded into memory, the common detection techniques, such as signature based scanning, can be applied \cite{NamanyaTWM}.

Various armouring techniques are thus used by malware authors to prevent detection by emulation, however most antivirus scanners are now capable of addressing also these techniques effectively defeating \textit{polymorphic} malware.

The first known malware to exhibit \textit{polymorphism} is called \textit{1260} and was written in 1990.

\subsubsection{Metamorphic Malwares}
After the \textit{oligomorphic} and \textit{polymorphic} malware types were effectively defeated, malware authors designed a new and more advanced approach: \textit{metamorphic} malware. This, similarly to \textit{polymorphic} malware, uses obfuscation techniques to create new variants of the original malware in order to evade detection \cite{YouMOT}.

However, in this case, instead of generating new decryptors, it is the malware body itself to be mutated through generations to appear different while having the same behaviour and functionality. \textit{Metamorphic} malware is in fact said to be \textit{body-polymorphic}. In practice the malware code logic is maintained while its appearance is changed using obfuscation techniques such as \textit{dead-code insertion}, \textit{register reassignment}, \textit{code transposition} and more. This way, every generated malware variation appears different making signature based detection ineffective \cite{Sharma_2014}.

However, \textit{metamorphic} malware, in order to efficiently evolve its code it need to be able to recognise, parse and mutate its own body during propagation. This is far from being easy. Moreover, creating a true \textit{metamorphic} malware without arbitrary increasing its code size is also challenging \cite{NamanyaTWM}.

Moreover, \textit{metamorphic} malware is also capable of interleaving its own code inside host programs, thus making detection even harder.

The first malware to exhibit metamorphic behaviour was called \textit{Win95/Regswap} and was developed in 1998.

\chapter{Detection Techniques}
Malware detection is the process of identifying malicious code from benign code. This is done in order to protect systems and being able to recover from the malicious code effects \cite{NamanyaTWM}.

In order to counter malware attacks and threats, in recent years many anti-malware tools have been developed. Many of these are based on static features (such as signatures) with the assumption that most malware is static, it doesn't mutate/change significantly at infection/replication time \cite{Sharma_2014}.

However, attackers are nowadays increasingly using the more sophisticated second generation malwares, which strongly mutate at each infection. Researchers and anti-malware software developers are thus focusing their attention on the creation of more advanced tools capable of detecting this type of evolving malware.

\color{Red}
Commercial Portable Executable (PE) malware detectors consist of a hybrid of static and dynamic analysis engines. Static detection - which is fast and effective at detecting a large fraction of malware - is usually first employed to flag suspicious samples. Static detection involves analysing the raw PE image on disk and can be performed very quickly, but it is vulnerable to code obfuscation techniques.

Dynamic detection, by contrast, requires running the PE in an emulator and analysing behaviour at run time. When dynamic analysis works, it is less susceptible to code obfuscation, but takes substantially greater computational capacity and time to execute than static methods. Moreover, some files are difficult to execute in an emulated environment, but can still be statically analysed. Consequently, static detection methods are typically the most critical part of an endpoint's malware prevention pipeline.
\color{Black}

\section{Integrity Checker}
When compromising a computer system or network some changes are inevitably made within the target environment. This implies that systems, like \textit{integrity checkers}, that rely on actively monitoring changes made to existing files within the target operating system, can be used to perform intrusion detection \cite{NamanyaTWM}.

Generally, \textit{integrity checkers}, use hashing functions like the \textit{md5} sum, \textit{Sha1} or \textit{Sha256} to calculate the digest of files and/or executables which are then stored in a database of digests. Programs and files digests are then periodically re-calculated and compared against the ones in the database looking for modifications. If the digest of a file is different and no software updates nor patches were applied, then the file was probably tampered with.

\textit{Integrity checkers} present a number of challenges:
\begin{itemize}
	\item The system state in which the initial file digests are calculated has to be considered clean. However this is difficult to be guaranteed.
	
	\item The application of system (and software) updates and patches, which modify system files and programs, must be followed by an update of the digests database, otherwise there will be a very high false positive rate.
	
	\item The digests database needs to be stored securely and there has to be an offline (and safe) backup, otherwise there would be a single point of failure.
\end{itemize}

\textit{Integrity checking} can be considered as an important tool for detecting any system modifications, but it is more an incident recovery method rather than a malware intrusion/infection prevention method.

\section{Signature-based Detection}
\textit{Signature-based} detection is the simplest and most widely used method in commercial anti-virus software (together with \textit{heuristic-based} techniques) but is becoming less and less effective as the number of malware variants and second generation malwares increases \cite{NguyenSPVD}.

\textit{Signature-based} detection relies on \textit{signatures}, represented by specific unique byte code sequences/strings extracted from malware samples, to detect the presence of malicious files in a system. \textit{Signatures} are typically created using static analysis techniques and are selected to be long enough to uniquely characterize a specific malware families with respect to benign programs.

The \textit{signatures}, which are crated by malware experts from a significant number of already identified malware samples, are saved in a \textit{signature database} and deployed in anti-malware tools. Anti-malware tools in turn scan the files in the target system and consider as malicious any file that matches one of the known signatures \cite{NamanyaTWM}. This implies that the database of signatures must be maintained and frequently updated, especially whenever new malware variants are identified and new signatures are generated in order to detect them.

Some \textit{signature-based} algorithms require an exact match between the signature of the analysed sample and one of the known signatures, others instead make use of \textit{wildcards} characters to detect slight variations. Some second generation (evolving) malwares have been detected in the past by using wildcards, e.g. \textit{W32/Regswap}.

This approach is fast, easy to use and has a high positive rate, however, since the number of known malwares is increasing so fast, it is quickly becoming time-consuming, expensive and impractical. Moreover, this is a completely reactive technique which is unable to counter threats/attacks from new malwares families/variants until they cause damages. Additionally, most second-generation malwares are able to escape this type of detection \cite{Sharma_2014}.

\subsection{Yara Rules}
\textit{YARA} is a widely accepted open-source \textit{signature-based} malware analysis tool which has emerged in recent years thanks to its flexible and customisable nature. It allows malware analysts/researchers to develop malware "descriptions" based on text or binary patterns, commonly referred to as \textit{Yara rules}. \textit{Yara rules}, which combine simple regular expressions matching with logic rules, can be used to identify specific malware families, the presence of \textit{CVE}s, specific functionality signatures or even generic maliciousness indicators. Given the success obtained by this technique, many commercial malware analysis tools nowadays support \textit{Yara rules} natively \cite{SimonWIY}.

\textit{Yara rules} can be generated either manually or automatically. Generating rules manually obviously requires high expertise, whereas generating them automatically using tools is a relatively easy task. However, automatically generated rules are not guaranteed to be effective and may require post-processing operations for their optimization \cite{NaikEAGYRETE}.

Malware analysts typically create \textit{Yara rules} manually by reverse engineering malware samples looking for common \textit{Indicator of Compromise (IoC)} strings. This is followed by the development and iterative refinement of the rules which are considered effective based on their coverage and false positive rate on a dataset of malicious, benign and out-of-family samples. Developing effective \textit{Yara rules} can therefore be challenging and very time consuming, even for expert users with years of experience \cite{RaffAYRGUB}.

\subsubsection{Yara Rules syntax}
Listing \ref{YaraSyntax} presents an example of the syntax of a simple \textit{Yara rule}.

\begin{lstlisting}[caption={YARA Rules Syntax}, label=YaraSyntax, language=YARA, style=mystyle]
	rule RuleName
	{
		meta:
		description = "description of rule"
		author = "name"
		date = "dd/mm/yyyy"
		reference = "url"
		
		strings:
		$text_string1 = "text1 you wish to find in malware"
		$text_string2 = "text2 you wish to find in malware"
		
		$hex_string1 = {hex1 you wish to find in malware}
		$hex_string2 = {hex2 you wish to find in malware}
		
		$reg_exp_string1 = /regular expression1 you wish to find in malware/
		$reg_exp_string2 = /regular expression2 you wish to find in malware/
		
		condition:
		$text_string1 or $text_string2 or
		$hex_string1 or $hex_string2 or
		$reg_exp_string1 or $reg_exp_string2
	}
\end{lstlisting}

As it can be seen in the above example, \textit{Yara rules} must start with the keywork '\textit{rule}', followed by the actual \textit{RuleName}, which is the rule identifier. The \textit{RuleName}s follow the same lexical conventions of the \textit{C} programming language. They are, in fact, case sensitive, they cannot exceed 128 characters and they can contain only alphanumeric characters (with the addition of the underscore character), with the exception of the first character which cannot be a digit. Furthermore there is a list of \textit{YARA} reserved keywords that cannot be used as identifiers \cite{NinjaYSEWDM}.

\textit{Yara rules} main body contains three sections: \textit{meta}, \textit{strings} and \textit{condition}.

\paragraph{Meta section}
The rule author can include additional information about the rule as a list of attribute-value pairs, also called \textit{metadata}, in the \textit{meta} section, at the top of the rule. The values can be strings, integers or boolean values. The metadata, however, cannot be used in the condition section since that is not their purpose \cite{ArntzEYR}.

Some commonly used meta tags are, for example, "author" and "description", which convey information about the author and purpose of the rule. Moreover, malware analysts sometimes also leave tags with the hashes of the malicious files used for the creation of the rule, or references to blog posts with similar information \cite{SimonWIY}.

\paragraph{Strings section} 
This section contains the strings/patterns/signatures that a file must contain to 'trigger' the rule. This section is optional and can be omitted if it is not necessary. \textit{YARA} supports searching for 3 string types: \textit{Hexadecimal Strings}, \textit{Text (ASCI) Strings} and \textit{Regular Expressions}.

\begin{itemize}
	\item \textit{Hexadecimal Strings}: \textit{Hexadecimal Strings} will match hexadecimal characters/sequences of raw bytes in the file being analysed.
	Example:
	\begin{lstlisting}[caption={YARA Hexadecimal}, label=YaraHex, language=YARA, style=mystyle]
	rule ExampleRule
	{
		strings:
		$my_text_string = "text here"
		$my_hex_string = { E2 34 A1 C8 23 FB }
		
		condition:
		$my_text_string or $my_hex_string
	}
	\end{lstlisting}
	
	
	Three special flexible formats, namely \textit{wildcards}, \textit{jumps} and \textit{alternatives}, can be used to complement the search.
	\begin{itemize}
		\item \textit{\textbf{Wildcards}} are represented by the '\textbf{?}' symbol. They indicate that some bytes in the pattern are unknown and should match anything. For example:
		\begin{lstlisting}[caption={YARA Hexadecimal Wildcard}, label=YaraWildcard, language=YARA, style=mystyle]
	rule WildcardExample
	{
		strings:
		$hex_string = { E2 34 ?? C8 A? FB }
		
		condition:
		$hex_string
	}
		\end{lstlisting}
		
		\item \textit{\textbf{Jumps}} are used in circumstances when the values of the pattern are known but their length varies. For example:
		\begin{lstlisting}[caption={YARA Hexadecimal Jump}, label=YaraJump, language=YARA, style=mystyle]
	rule JumpExample
	{
		strings:
		$hex_string = { F4 23 [4-6] 62 B4 }
		
		condition:
		$hex_string
	}
		\end{lstlisting}
		In particular, in listing \ref{YaraJump}, the value '\textit{[2-3]}' indicates that any arbitrary sequence from 2 bytes to 3 bytes long can occupy the sequence at that position.
		
		\item \textit{\textbf{Alternatives}}, whose syntax resembles regular expressions, are used in situations in which the author wants to provide different alternatives for a given fragment of the hex string. For example:
		\begin{lstlisting}[caption={YARA Hexadecimal Alternatives}, label=YaraAlternatives, language=YARA, style=mystyle]
	rule AlternativesExample
	{
		strings:
		$hex_string = { F4 23 ( 62 B4 | 56 ) 45 }
		
		condition:
		$hex_string
	}
		\end{lstlisting}
	In particular, in listing \ref{YaraAlternatives}, the value '\textit{(62 B4 $\vert$ 56)}' indicates that one sequence between '\textit{62 B4}' and '\textit{56}' can occupy the sequence at that position.
	\end{itemize}
	
	\item \textit{Text Strings}:		
	Text strings are generally readable sequences of ASCII characters which are then matched in the condition section \cite{SimonWIY}.
	
	Example of an ASCII-encoded, case-sensitive string:
	\begin{lstlisting}[caption={YARA Text Strings example}, label=YaraTextStrings, language=YARA, style=mystyle]
		rule TextExample
	{
		strings:
		$text_string = "foobar"
		
		condition:
		$text_string
	}
	\end{lstlisting}
	
	Additionally, to specify how \textit{YARA} should search for strings, some modifiers can be added at the end of a string definition. Moreover, even more than one modifier can be used in combination to keep rule as simple and readable as possible. Here are described some of the available modifiers:
	\begin{itemize}			
		\item \textit{nocase}: Text strings in YARA are, by default, case-sensitive. However it is possible to search for strings in case-insensitive mode by appending the modifier '\textit{nocase}' at the end of the string definition, in the same line. Example:
		\begin{lstlisting}[caption={YARA nocase example}, label=YaraNocase, language=YARA, style=mystyle]
	rule CaseInsensitiveTextExample
	{
		strings:
		$text_string = "foobar" nocase
		
		condition:
		$text_string
	}
		\end{lstlisting}
		
		\item \textit{wide}: The '\textit{wide}' modifier can be used to search for strings encoded with two bytes per character (also known as \textit{wide character strings}), something which is typical in many executable binaries.
		
		For example, if the string "Borland" appears in the file encoded as two bytes per character, then the following rule will match:
		\begin{lstlisting}[caption={YARA Wide Character Strings}, label=YaraWideCharacter, language=YARA, style=mystyle]
	rule WideCharTextExample1
	{
		strings:
		$wide_string = "Borland" wide
		
		condition:
		$wide_string
	}
		\end{lstlisting}
	
		\item \textit{xor}: \textit{YARA} can also encode text before searching it in the analysed file. The '\textit{xor}' modifier, for example, can be used to search for strings with a single byte XOR applied to them.
		
		The following rule will search for every string resulting from a single-byte XOR applied to the string "This program cannot":
		\begin{lstlisting}[caption={YARA XOR-ed Strings}, label=YaraXOR, language=YARA, style=mystyle]
	rule XorExample1
	{
		strings:
		$xor_string = "This program cannot" xor
		
		condition:
		$xor_string
	}
		\end{lstlisting}
	
		\item \textit{base64}: The '\textit{base64}' modifier can be used to search for strings that have been base64 encoded.
		
		The following rule will search for all the possible base64 permutations of the string "This program cannot":
		\begin{lstlisting}[caption={YARA Base64 encoded Strings}, label=YaraBase64, language=YARA, style=mystyle]
	rule Base64Example1
	{
		strings:
		$a = "This program cannot" base64
		
		condition:
		$a
	}
		\end{lstlisting}
	\end{itemize}

	\item \textit{Regular Expressions}:
	Starting from version 2.0 YARA has its own regular expression engine, which is one of its most powerful features. \textit{Regular expressions} are defined in the same way as text strings, but enclosed in forward slashes instead of double-quotes \cite{NaikEAGYRETE}.
	
	Example:		
	\begin{lstlisting}[caption={YARA Regular Expression}, label=YaraRegex, language=YARA, style=mystyle]
	rule RegExpExample
	{
		strings:
		$re1 = /md5: [0-9a-fA-F]{32}/
		$re2 = /state: (on|off)/
		
		condition:
		$re1 and $re2
	}
	\end{lstlisting}	
\end{itemize}

\paragraph{Conditions section}
The last section of \textit{YARA rules}, which is the only required one, contains the rule conditions that determine when the rule gets triggered. These conditions are Boolean expressions similar to those used in programming languages \cite{ArntzEYR}. Through the use of all the usual logical and relational operators, conditions can be made arbitrary complex in order to accommodate for the specific author needs \cite{SimonWIY}.	

Inside the \textit{Conditions} section, among other things, it is possible to:
\begin{itemize}
	\item \textbf{Count strings}
	Sometimes it is necessary to know how many times a string appears in the analysed file, not only if it is present or not. The number of occurrences of each string defined in the string section can be retrieved by using a variable whose name is the string identifier but with a \# character in place of the initial \$ character.
	
	For example:
	\begin{lstlisting}[caption={YARA Count Example}, label=YaraCount, language=YARA, style=mystyle]
	rule CountExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		
		condition:
		#a == 6 and #b > 10
	}
	\end{lstlisting}
	
	\item \textbf{Check String at specific offset/in offset range}: Sometimes we need to know if a particular string is available at some specific offset of the file or at some virtual address within the process address space. In such situations it is possible to use the '\textit{at}' operator.
	
	The '\textit{in}' operator, on the other hand, allows to search for a specific string within a range of offsets or addresses, rather than at an exact one.
	
	Examples:
	\begin{itemize}
		\item The rule in listing \ref{YaraAt} will find whether the '\textit{a}' string is located at offset 100 and '\textit{b}' at offset 200 of the running process.
		
		\begin{lstlisting}[caption={YARA At Example}, label=YaraAt, language=YARA, style=mystyle]
	rule AtExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		
		condition:
		$a at 100 and $b at 200
	}
		\end{lstlisting}
		
		\item The rule in listing \ref{YaraIn} will find the '\textit{a}' in the memory location between \textit{0} and \textit{100} and '\textit{b}' between \textit{100} and \textit{filesize} of the running process.
		
		\begin{lstlisting}[caption={YARA In Example}, label=YaraIn, language=YARA, style=mystyle]
	rule InExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		
		condition:
		$a in (0..100) and $b in (100..filesize)
	}
		\end{lstlisting}
	\end{itemize}

	\item \textbf{Check file size}: '\textit{filesize}' is a special variable that can be used in rules conditions, which holds the size of the file being scanned in bytes.
	
	Example:
	\begin{lstlisting}[caption={YARA Filesize Example}, label=YaraFilesize, language=YARA, style=mystyle]
	rule FileSizeExample
	{
		condition:
		filesize > 200KB
	}
	\end{lstlisting}
	
	\item \textbf{Check a set of strings}: When it is necessary to know if a file contains a certain number of strings from a given set the '\textit{of}' operator can be used.
	
	Example:
	\begin{lstlisting}[caption={YARA Of Example}, label=YaraOf, language=YARA, style=mystyle]
	rule OfExample
	{
		strings:
		$a = "dummy1"
		$b = "dummy2"
		$c = "dummy3"
		
		condition:
		2 of ($a, $b, $c)
	}
	\end{lstlisting}
\end{itemize}

\paragraph{Additional modules}
\textit{YARA}'s code functionality can be extended through the use of modules. Some modules like the \textit{PE module} and the \textit{Cuckoo module} are officially distributed with YARA, however additional ones can also be created.

Here are mentioned some useful (in this document context) Yara modules:
\begin{itemize}
	\item \textbf{YARA with PE}
	Starting with version 3.0, YARA can parse Portable Executable (PE) files \cite{NinjaYSEWDM}. For example, the rule in listing \ref{YaraPE} will check for the string "abc", will parse the PE file and look for "\textit{CreateProcess}" and "\textit{httpsendrequest}" function names in the import sections '\textit{Kernel32.dll}' and '\textit{wininet.dll}', respectively.
	
	\begin{lstlisting}[caption={YARA with PE}, label=YaraPE, language=YARA, style=mystyle]
	Import "PE"
	
	rule PE_Parse_Check
	{
		strings:
			$string_pe="abc" nocase

		condition:
			pe.imports("Kernel32.dll", "CreateProcess") and
			pe,imports("wininet.dll", "httpsendrequest") and
			$string_pe
	}
	\end{lstlisting}
	
	\item \textbf{YARA with PEiD}
	\textit{YARA} can also be integrated with \textit{PEiD} to check what packer was used to compile the malicious/suspicious executable \cite{NinjaYSEWDM}.
\end{itemize}

\subsubsection{Yara Rules Advantages and Disadvantages}
\begin{enumerate}
	\item \textbf{\textit{Advantages}} of \textit{Yara rules}:
	\textit{Yara rules} offer several advantages over other malware analysis techniques. Here are some of the most notable ones \cite{NaikEAGYRETE}:
	\begin{itemize}
		\item \textit{Yara rules} allow malware analysts to write flexible and custom rules in an easy and efficient way.
		
		\item \textit{Yara rules} are an open standard which work on most of the major operating systems such as Windows, Linux and Mac OS.
		
		\item \textit{Yara rules} can be easily integrated into Python and C/C++ programming languages.
		
		\item \textit{Yara rules} can be used both for static and dynamic malware analysis.
		
		\item Several automatic tools have been developed, and are readily available, to generate \textit{Yara rules} easily and efficiently.
		
		\item There are various public repositories of \textit{Yara rules} which offer readily available rules for malware analysis.
	\end{itemize}
	
	\item \textbf{\textit{Limitations}} of \textit{Yara rules}:
	\textit{Yara rules}, however, have also some limitations. Here are some of the most notable ones \cite{NaikEAGYRETE}:
	\begin{itemize}
		\item \textit{Yara rules} are commonly written based on \textit{IoC} (\textit{Indicator of Compromise}) strings, however, malware authors can easily obfuscate, replace or encrypt these \textit{IoC} strings in their creations in order to evade detection. This could make these rules less effective.
		
		\item \textit{IoC} strings are usually extracted from existing malware samples/families through the use of reverse engineering techniques. The use of these techniques in manually creating effective rules, however, requires a highly specialised skill-set and years of experience.
		
		\item The effectiveness of \textit{Yara rules} is generally influenced by the types and number of \textit{IoC} strings included in the rules. However, achieving the right balance of both is a challenging task.
		
		\item \textit{Yara rules} are effective in detecting malware which matches known malware signature. It may, however, completely miss new and unique malware variants.
	\end{itemize}
\end{enumerate}

\subsubsection{Yara Rules Automatic Generators}
There are various automatic \textit{Yara rules} generator tools available. In the following the most notable ones will be briefly described:

\paragraph{\textit{YarGen} Tool}
\textit{YarGen} \textit{python-based} tool exploits some smart techniques, namely fuzzy regular expressions, Naive Bayes classifier and Gibberish Detector, to generate \textit{Yara rules}. 

The produced rules include features (strings and opcodes) common to malware samples that don't match with the provided goodware databases. A predefined number of features (generally up to 20 strings) are selected, based on their potential utility and a number of heuristics, to be combined and used by the rule in order to maintain a reasonable operation speed.

This tool is able to generate two types of rules: \textit{basic rules} and \textit{super rules}. \textit{Basic rules} can generally target specific malware samples, where \textit{super rules} are able to target a set of malware samples or a whole malware family \cite{NaikEAGYRETE}.

The \textit{yarGen} authors encourage its use as a starting point for rule construction, followed by manual adjustments and to refine \textit{yarGen}'s output \cite{RaffAYRGUB}.

\begin{enumerate}
	\item \textit{YarGen} tool \textit{advantages}:
	\begin{itemize}
		\item It allows generation of \textit{Yara rules} based on both opcodes and strings.
		
		\item It supports the use of PE (portable executable) modules, with are used to interpret Windows operating system executables such as \textit{DLL} and \textit{COM} files.
		
		\item It can be integrated with other anti-malware software in order to improve its effectiveness.
		
		\item It reduces the false positive rate by checking all strings against databases of goodware samples.
		
		\item It is deployed as a simple and easy-to-use python script that can be run through a command-line interface.
	\end{itemize}
	
	\item \textit{YarGen} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item It requires significant resources for generating opcode-based rules and for loading goodware files.
		
		\item The rule generation process is slow.
		
		\item The creation of super rules may cause redundancy and duplication of rules.
		
		\item All dependencies and built-in databases have to be installed in order for the tool to work successfully.
	\end{itemize}
\end{enumerate}

\paragraph{\textit{YaraGenerator} Tool}
This \textit{python-based} tool uses string prioritization logic and code refactoring to generate \textit{Yara rules} with a completely different signature for different file types, such as \textit{EXE}s, \textit{PDF}s, and \textit{Email}s.

The generated \textit{Yara rules} contain only strings (opcodes are not supported) extracted from malware samples that do not match with the provided database of strings from blacklisted files. In particular 30,000 blacklisted strings are contained in such database, arranged based on the different file formats.

The produced \textit{Yara rules} contain a large number of strings which are selected randomly. In fact, no score computation takes place in order to weight the different strings \cite{NaikEAGYRETE}.

\begin{enumerate}
	\item \textit{YaraGenerator} tool \textit{advantages} :
	\begin{itemize}
		\item It can generate specialised rules for specific file formats.
		
		\item It supports the use of PE (portable executable) modules, with are used to interpret Windows operating system executables such as \textit{DLL} and \textit{COM} files.
		
		\item It reduces the false positive rate by checking all strings against databases of blacklisted files.
		
		\item It is deployed as a simple and easy-to-use python script that can be run through a command-line interface.
	\end{itemize}
	
	\item \textit{YaraGenerator} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item It generates rules based on a random selection of features (strings). This implies that the most appropriate strings may not be selected in many cases, thus making the produced rules less effective on average.
		
		\item It does not support the use of opcodes.
		
		\item It was developed as a work-in-progress project and has not been updated for a while now.
	\end{itemize}
\end{enumerate}

\paragraph{\textit{Yabin} Tool}
This is another \textit{python-based} tool, developed by the \textit{Alien Vault Open Threat Exchange} (\textit{OTX}) community, for the automatic generation of \textit{Yara rules}.

In this case \textit{Yara rules} are created by finding rare functions in specific malware samples or families. Functions are recognised by checking specific bytes sequences called \textit{function prologues}, which define the start of the code of a function. For example, the byte sequence '\textit{55 8B EC}' usually specifies the start of a function in programs compiled by Microsoft Visual Studio.

The generated \textit{Yara rules} include those strings common to malware samples that don't match with the provided whitelist of commonly used library functions. Such whitelist was obtained from 100 Gb of non-malicious software in order to exclude common library functions.

The \textit{Yara rules} produced contain a list of hexadecimal strings to be compared against suspicious files looking for similarities in their byte-sequences \cite{NaikEAGYRETE}.

\begin{enumerate}
	\item \textit{Yabin} tool \textit{advantages}:
	\begin{itemize}
		\item It can be used to cluster malware samples based on the reuse of their code.
		
		\item The list of patterns to search for can be extended during the rule post-processing phase.
		
		\item With the purpose of excluding commonly used library functions in the produced rules, a large whitelist obtained from numerous non-malicious executable files is provided with the tool.
		
		\item It is deployed as a simple and easy-to-use python script that can be run through a command-line interface.
	\end{itemize}
	
	\item \textit{Yabin} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item Some specific file types/formats may not be supported.
		
		\item The created rules contain only function prologues. No other string types are used.
		
		\item Since it relies on function prologues, it works only with unpacked executables.
		
		\item It is not designed to work on \textit{.NET} executables, \textit{Java} files and \textit{Microsoft} documents.
		
		\item It was mainly developed for research and testing purpose, not for production use.
	\end{itemize}
\end{enumerate}

\paragraph{\textit{AutoYara} Tool}
Compared to the previously mentioned tools like \textit{YarGen}, which rely on a number of heuristics and string features, \textit{AutoYara} tool makes larger rules using the redundancy and conjunction of components to achieve extremely low false-positive rates \cite{RaffAYRGUB}.

The two primary concerns of the \textit{AutoYara} authors while designing this tool were:
\begin{enumerate}
	\item Yara rules that generate a lot of false positives could slow the investigation
	
	\item Malware analysts often have few samples ($\leq 10$) when creating a Yara rule
\end{enumerate}

\textit{AutoYara} authors thus developed a workflow composed of two steps: the first step leveraged recent works in finding frequent larger n-grams, for $n \leq 1024$, to find several candidate byte strings that could become features. In the second step a bi-clustering method, which consists of simultaneously clustering the rows and columns of an input data matrix, is used on those strings to construct the output rules. Most bi-clustering algorithms require the specific number of bi-clusters to be known in advance, and enforce no overlaps between bi-clusters. The \textit{AutoYara} authors exploited an already existing bi-clustering algorithm extending it to work when the number of bi-clusters is not known \textit{a priori} (the number of bi-clusters gets determined automatically) and to allow overlapping bi-clusters, discarding rows and columns that do not fit in any bi-cluster \cite{RaffAYRGUB}.

\textit{AutoYara} uses \textit{bi-clustering} because it allows to easily produce complex and effective logic rules that enable the creation of signatures with low false positive rates.

To build a good Yara rule, in fact, one needs to know:
\begin{enumerate}
	\item which features should be used at all
	
	\item which features should be combined into '\textit{and}' statements (which reduce the False Positive Rate), and which should be placed into '\textit{or}' statements (which increase the True Positive Rate)
\end{enumerate}
\textit{Bi-clustering} provides a simple approach to do this jointly over the features, rather than considering the features one at a time. In particular, the features within a bi-cluster are combined into an '\textit{and}' statement since they co-occur; moreover the '\textit{and}' statements from multiple bi-clusters are placed into an '\textit{or}' statement resulting in a "disjunction of conjunctions" rule formulation.

\begin{enumerate}
	\item \textit{AutoYara} tool \textit{advantages}:
	\begin{itemize}
		\item It is fast, allowing it to be deployed even on low-resource equipment (like remote networks).
		
		\item It was designed with the intent of producing \textit{Yara rules} with low false positive rates.
		
		\item It was designed to be able to generate \textit{Yara rules} from as few as $\leq10$ available samples.
	\end{itemize}
	
	\item \textit{AutoYara} tool \textit{disadvantages}:
	\begin{itemize}
		\item It requires post-processing of the generated rules for increasing their effectiveness.
		
		\item It a very recent tool, mainly developed for research purposes and not for production use.
	\end{itemize}
\end{enumerate}

\color{Green}
Consider if to add something about "Manually generated Yara Rules + Open Source Yara Rules databases".
\color{Black}

\section{Semantic Based Detection}
\textit{Semantic-based} malware detection aims at identifying malware by deducing the analysed code logic and comparing it to a database of already known malicious logic patterns. This technique, differently from signature-based detection which looks at the code syntactic properties, tracks the semantics of the program code instructions. This implies that \textit{semantic-based} detection approaches are capable of overcoming obfuscation attempts and even detecting unknown malware variants \cite{NamanyaTWM}.

\section{Behavioural Based Detection}
\textit{Behavioural-based} malware detection is based on the use of behavioural patterns for the identification of malicious software. This is done by dynamically analysing malware samples and extracting specific system/application behaviours and activities in order to form a '\textit{behavioural signature}' of a malware strain. New samples are then analysed in the same way and identified as malware if their behavioural pattern is similar to the \textit{behavioural signature} of a known malware \cite{NamanyaTWM}.

\textit{Behavioural-based} detection is for the most part immune to obfuscation attempt. However, being based on the time consuming dynamic analysis and on the challenging task of determining the unsafe activities and behaviours to consider within the environment, its applicability is limited.

\section{Heuristics-based Detection}
As opposed to traditional \textit{signature-base} detection methods which identify malware by looking in the code for specific bytes/strings, \textit{heuristic-based} detection uses rules and/or algorithms to search for commands or instructions not commonly found in harmless applications, thus indicating possible malicious intents \cite{MiaoUHSS}.

\textit{Heuristic-based} anti-malware tools may exploit different scanning techniques such as:
\begin{itemize}
	\item \textit{File analysis (static heuristic analysis)}: the suspicious program is disassembled and its source program is examined looking for known malware patterns (stored in a heuristic database). If the percentage of matched code exceeds a predefined threshold then the code is marked as probably infected \cite{KasperskyWHA}.
	
	\item \textit{File emulation (dynamic heuristic analysis)}: in this approach, the suspicious piece of code is examined in a virtual machine (or sandbox) looking for suspicious operations such as attempts at executing other executables, at changing the Master Boot Record, at concealing themselves etc. that are uncommon in benign programs.
	
	\item \textit{Genetic signature detection}: this technique is designed to spot different malware variations within the same family using previous malware definitions \cite{ForcepointWHA}.
\end{itemize}

\textit{Heuristic} analysis is a promising technique for the detection of unknown malware, particularly for encrypted and polymorphic variants \cite{Sharma_2014}.

Nowadays \textit{heuristic} analysis can be found in most mainstream antivirus solutions in the market, combined with signature-based scanners in order to improve detection rate while reducing false alarms \cite{NamanyaTWM}.

\section{Machine Learning}
In recent years, the rapid proliferation and increased sophistication of malicious software, coupled with the rising popularity of machine learning techniques in many fields, led to the adoption of more general ML-based approaches to malware detection on top of the use of manually generated signatures \cite{DucauAMDATSE}.

In particular, the application of machine learning for Information Security (ML-Sec) methods to perform malware detection generally consists in training a highly parametrized ML classifier to reliably (as much as possible) predict a binary label (malicious or benign) using features extracted from sample files. In order to do this the classifier parameters are numerically optimized to learn general concepts of \textit{malware} and \textit{benignware}, by minimizing misclassification as measured by some loss criterion, which measures the deviation of predictions from their actual ground truth. This is based on the assumption that, if the samples are well labelled and malware/benignware samples in the training set are similar enough to those seen at test/deployment, the learned detection function should work well on unseen samples \cite{ruddALOHA}.

Most static ML-Sec classifiers work on learned embeddings over portions of files (e.g. headers), learned embeddings over full files, or most commonly, on pre-engineered numerical \textit{feature vectors} designed to summarize the content from each file. Learned embeddings generally are the result of convolutional architectures which do not presume a fixed file structure. However, the process of embedding features directly from inputs is expensive, and does not scale gracefully. Moreover, generic bytes do not present structural localities/hierarchies typical of images and text inputs that can be exploited by convolutional filters. Pre-engineered feature vector representations, on the other hand, quickly distil content useful for classification from each file \cite{KyadigeLFCEIFPIBMD}. There are various possible ways to statically craft feature vectors, for example:
\begin{itemize}
	\item  tracking per-byte statistics over sliding windows
	
	\item byte histograms
	
	\item n-gram histograms
	
	\item treating bytes as pixel values in an image
	
	\item opcode and function call graph statistics
	
	\item symbol statistics
	
	\item hashed/numerical metadata values
	
	\item hashes of delimited tokens
	
	\item etc.
\end{itemize}
The process of transforming a sample file to its numerical feature representation is called \textit{feature extraction} and consists of some numerical transformation that preserves aggregate and fine-grained information throughout each sample \cite{ruddALOHA}.

ML methods generally require many high quality samples in order to train effective models. When creating datasets for these models labels are often collected from vendor aggregation feeds, which combine detection results from various vendors for each malware sample. This can be done, for example, by using a $1-$/$5+$ criterion or by using statistical estimation methods. The $1-$/$5+$ criterion works as follows: if a file has one or fewer vendors reporting it as malicious, the file is labelled as 'benign'; on the other hand, if a sample has five or more vendors reporting it as malicious, the file is labelled as 'malicious'. Moreover, it is common practice to introduce a time lag to let vendors update their models to account for new malware samples. When deployed, classifiers are periodically re-trained on new data/labels to reflect the current malware trends \cite{KyadigeLFCEIFPIBMD}.

The advantage of machine learning techniques with respect to signature engines, where the aim is to reactively blacklist/whitelist samples that hard-match manually-defined patterns (signatures), is that, by being more general, they are able to detect not only known malwares but also novel malware strains/variants, providing some degree of proactive detection \cite{NguyenSPVD}.

Commercial anti-malware solutions/engines have nowadays integrated ML on top of standard detection methods (without replacing them) with the aim of enhancing the detection results, especially for second generation malwares and novel malware strains. Popular ML techniques employed by such tools are, for example, deep neural networks (DNN), boosted decision tree ensembles, Na\"ive Bayes models, Data Mining approaches and Hidden Markov Models. Moreover, multiple vendors in the IT security industry nowadays have dedicated ML-Sec teams \cite{Sharma_2014}.

In the following I will focus on the following recent static ML-based malware detection methods:
\begin{itemize}
	\item AlOHA: Auxiliary Loss Optimization for Hypothesis Augmentation
	
	\item Automatic Malware Description via Attribute Tagging and Similarity Embedding
	
	\item Learning from Context: Exploiting and Interpreting File Path Information for Better Malware Detection
\end{itemize}

\subsection{AlOHA: Auxiliary Loss Optimization for Hypothesis Augmentation}
In a recent work called \textbf{ALOHA: Auxiliary Loss Optimization for Hypothesis Augmentation}, \cite{ruddALOHA}, Rudd et al. observed that, although ML-based malware detection is frequently framed as a binary classification task (using a simple binary cross-entropy loss function), there are often a number of other sources of contextual metadata for each input sample available at training time, beyond just aggregate malicious/benign labels. Such metadata might include malicious/benign labels from multiple sources (e.g. from various security vendors), malware family information, temporal information, counts of affected endpoints, and associated tags.

However, this metadata is, in many cases, not available at deployment time thus making it difficult to include it as input features. Therefore, the authors proposed exploiting the metadata from threat intelligence feeds as auxiliary targets in the multi-target learning approach. Simultaneously optimizing classifier parameters for multiple targets (labels) while training a model may, in fact, have a regularizing effect leading to better generalization, particularly if the auxiliary targets are related to the main target of interest.

In practice, in their work \cite{ruddALOHA} the authors fit a deep neural network with multiple additional targets derived from metadata in a threat intelligence feed for Portable Executable (PE) malware and benignware. The additional losses include a multi-source malicious/benign loss, a count loss on multi-source detections, and a semantic malware attribute tag loss. The authors ultimately stated that this approach yielded a considerable improvement in performance on the main detection task.

\paragraph{Implementation Details}
The model presented in \cite{ruddALOHA} is composed of a base feed-forward neural network consisting of 5 blocks, each composed of Dropout, a dense layer, batch normalization, and an exponential linear unit (ELU) activation, with 1024, 768, 512, 512, and 512 hidden units respectively. This base topology applies the function $f(\cdot)$ to the input vector to produce an intermediate 512 dimensional representation of the input file $\textbf{h} = f(\textbf{x})$. An additional block for each output of the model, consisting of one or more dense layers and activation functions, is then appended on top of the base net. This composition of the base topology and the target-specific 'heads' is denoted as $f_{target}(\textbf{x})$.

The output for the main malware/benign prediction task - $f_{mal}(\textbf{x})$ - is always present (it constitutes the baseline model) and consists of a single dense layer followed by a sigmoid activation function on top of the base shared network. On top of that one or more auxiliary outputs are added with similar structure as described above: one fully connected layer (two for the \textit{tag} prediction task) with a task-specific activation function. Finally, multi-task losses are produced by computing the sum, across all tasks, of the per-task loss multiplied by a task-specific weight (1.0 for the malware/benign task and 0.1 for all other tasks) \cite{ruddALOHA}.

\paragraph{Malware Loss}
The task of predicting if a given binary file, represented by its features $\textbf{x}^{(i)}$, is malicious or benign is optimized by minimizing the binary cross-entropy loss between the malware/benign output of the network $\hat{y}^{(i)} = f_{mal}(\textbf{x}^{(i)})$ and the malicious label $y^{(i)}$. This results in the following loss for a dataset with \textit{M} samples:
\begin{equation} \label{alohaMalwareLoss}
	\begin{split}
		L_{mal}(X,Y) & = \frac{1}{M} \sum_{i=1}^{M} l_{mal} (f_{mal}(\textbf{x}^{(i)}), y^{(i)}) \\ & = -\frac{1}{M} \sum_{i=1}^{M} y^{(i)} \log(\hat{y}^{(i)}) + (1-y^{(i)}) \log(1-\hat{y}^{(i)}).
	\end{split}
\end{equation}
A "1-/5+" criterion was used for labelling a given file as malicious or benign \cite{ruddALOHA}.

\paragraph{Vendor Count Loss}
The first additional target the authors of \cite{ruddALOHA} tried using is the count of 'malicious' reports for a given sample from the vendor aggregation service. This is based on the assumption that the more a sample gets reported by vendors, the more likely it is to be malicious. To model count data, the authors used the Poisson noise model parametrized by the parameter $\mu$, where $\mu$ is the mean and variance of the Poisson distribution. The probability of an observation of $y$ counts is therefore:
\begin{equation} \label{alohaPoisson}
	P(y|\mu) = \mu^y e^{-\mu}/y!.
\end{equation}

The model is then trained to \textit{estimate} $\mu$ for each sample $\textbf{x}^{(i)}$ such that the likelihood of $y^{(i)}|\mu^{(i)}$ is maximized (or, equivalently, the negative log-likelihood is minimized). The output of the model vendor count head, for sample \textit{i}, is denoted as $f_{cnt}(\textbf{x}^{(i)})$. Thereafter, an activation function $a(\cdot)$, which maps $f_{cnt}(\textbf{x}^{(i)})$ to the non-negative real numbers, is used so the final approximation for parameter $\mu$ is: $\mu^{(i)} = a(f_{cnt}(\textbf{x}^{(i)}))$. In particular, the activation function used in \cite{ruddALOHA} is an exponential linear unit activation (ELU).

Letting $y^{(i)}$ denote the actual number of vendors that deemed sample $\textbf{x}^{(i)}$ malicious, the corresponding negative log-likelihood loss over the dataset is:
\begin{equation} \label{alohaVendorCountLoss}
	\begin{split}
		L_p(X,Y) & = \frac{1}{M} \sum_{i=1}^{M} l_p (a(f_{cnt}(\textbf{x}^{(i)})), y^{(i)}) \\ & = \frac{1}{M} \sum_{i=1}^{M} \mu^{(i)} - y^{(i)} \log(\mu^{(i)}) + \log(y^{(i)}!),
	\end{split}
\end{equation}
which is referred to in \cite{ruddALOHA} as the \textit{Poisson} or \textit{vendor count} loss. In practice, the term $\log(y^{(i)}!)$ can be ignored when minimizing this function loss since it does not depend on the network parameters.

\paragraph{Per-Vendor Malware Loss}
The authors of \cite{ruddALOHA} identified a subset $\mathcal{V} = \{v_1, ..., v_V\}$ of $9$ vendors that each produced a result for (nearly) every sample in their data. Each vendor result was added as additional target by adding an extra fully connected layer per vendor followed by a sigmoid activation function to the end of the shared baseline architecture. A binary cross-entropy loss per vendor was then employed during training. The aggregate \textit{vendors} loss $L_{vdr}$ for the $V = 9$ selected vendors is simply the sum of the individual vendor losses:
\begin{equation} \label{alohaPerVendorMalwareLoss}
	\begin{split}
		L_{vdr}(X,Y) & = \frac{1}{M} \sum_{i = 1}^{M} \sum_{j = 1}^{V} l_{vdr}(f_{vdr_j}(\textbf{x}^{(i)}), y_{v_j}^{(i)}) \\ & = - \frac{1}{M} \sum_{i = 1}^{M} \sum_{j = 1}^{V} y_{v_j}^{(i)} \log(\hat{y}_{v_j}^{(i)}) + (1 - y_{v_j}^{(i)}) \log{(1 - \hat{y}_{v_j}^{(i)})},
	\end{split}
\end{equation}
where $l_{vdr}$ is the per-sample binary cross-entropy function and $f_{vdr_j}(\textbf{x}^{(i)}) = \hat{y}_{v_j}^{(i)}$ is the output of the network that is trained to predict the label $y_{v_j}^{(i)}$ assigned by vendor $j$ to input sample $\textbf{x}^{(i)}$ \cite{ruddALOHA}.

\paragraph{Malicious Tags Loss}
Further additional targets were provided in the form of malicious tags. This was done in an attempt to exploit information contained in family detection names provided by different vendors. In particular, the tags used as auxiliary targets in \cite{ruddALOHA} are: \textit{flooder}, \textit{downloader}, \textit{dropper}, \textit{ransomware}, \textit{crypto-miner}, \textit{worm}, \textit{adware}, \textit{spyware}, \textit{packed}, \textit{file-infector} and \textit{installer}.

These tags were created by parsing individual vendor detection names, using a set of 10 vendors which provided high quality detection names. After having extracted the most common tokens, the tokens not related to well-known malware family names were filtered out. Finally, a mapping between tokens and tags was created based on the authors experience.

The tag prediction task was then defined as a multi-label binary classification, since zero or more tags from the set of possible tags $\mathcal{T} = \{t_1, ..., t_T\}$ can be present at the same time for a given sample. This was implemented as a \textit{multi-headed} architecture: two additional layers per tag were added to the end of the shared baseline architecture, a fully connected layer of size 512-to-256, followed by a sigmoid activation function. Each of the possible $T=11$ tags has its own loss term computed with binary cross-entropy. Finally, the aggregate tag loss is the sum of the individual tag losses \cite{ruddALOHA}. For the dataset with $M$ samples the loss is:
\begin{equation} \label{alohaMalwareTagLoss}
	\begin{split}
		L_{tag}(X,Y) & = \frac{1}{M} \sum_{i = 1}^{M} \sum_{j = 1}^{T} l_{tag}(f_{tag_j}(\textbf{x}^{(i)}), y_{t_j}^{(i)}) \\ & = - \frac{1}{M} \sum_{i = 1}^{M} \sum_{j = 1}^{T} y_{t_j}^{(i)} \log(\hat{y}_{t_j}^{(i)}) + (1 - y_{t_j}^{(i)}) \log(1 - \hat{y}_{t_j}^{(i)}),
	\end{split}
\end{equation}
where $y_{t_j}^{(i)}$ indicates if sample $i$ is annotated with tag $j$, and $\hat{y}_{t_j}^{(i)} = f_{tag_j}(\textbf{x}^{(i)})$ is the prediction of the network for that value.

\paragraph{Final Loss + Experiment Evaluation}
Finally, in \cite{ruddALOHA} each model used a loss weight of 0.1 on the aggregate malicious/benign loss and 0.1 on each auxiliary loss. Therefore, when adding $K$ targets to the main loss, the final loss that gets back-propagated through the model becomes:
\begin{equation} \label{alohaFinalLoss}
	L(X,Y) = L_{mal}(X,Y) + 0.1 \sum_{k=1}^{K} L_k(X,Y).
\end{equation}

\subsection{Automatic Malware Description via Attribute Tagging and Similarity Embedding}
As explained by Ducau et Al. in \cite{DucauAMDATSE}, in order to counter and remediate a malware infection on a system/network it is of vital importance to understand the nature (malware family and variant) of the attack in progress. In fact, knowing the malicious capabilities associated with each suspicious file found on a system/network gives important clues to the system end user, administrator or security operator that help define a remediation procedure, identify possible root causes, and evaluate the severity and potential consequences of the attack. 

Machine learning detection methods, which have the potential to identify even new malware samples/variants as malicious, however, generally produce a simple binary malicious/benign label with no further information about the type of threat posed by malicious samples, which in turn does not allow the identification of relationships between malware samples. On the other hand, most commercial anti-malware solutions provide,  when they alert about potentially harmful files detected in a machine, \textit{detection names} coming from specific hand-written signatures created by reverse engineers to identify particular threats, that are theoretically useful for categorizing known malware variants. However, even these detection names are problematic. In fact, the increasing number of feature-rich malware and the fact that different vendors use differing malware naming conventions led to inconsistent and highly vendor-specific detection names. Moreover, it is now common to see detection names which only act as unique identifiers without providing actionable information about the type of potential harm the malicious sample is capable of doing.

The authors of \cite{DucauAMDATSE} therefore proposed the use of SMART (Semantic Malware Attribute Relevance Tagging) tags, which are human interpretable, high level descriptions of the capabilities of a given malware sample, to approach malicious software description. These SMART tags, which were derived by leveraging the underlying knowledge encoded in detection names from different anti-malware vendors in the industry, are non-exclusive, meaning that one malware family can be associated with multiple tags and a given tag can be associated with multiple malware families. In \cite{DucauAMDATSE}, the authors defined a set of malicious tags $\mathcal{T}$, with $|\mathcal{T}| = 11$ different tags (or descriptive dimensions) of interest that they then used to describe malicious PE files: \textit{adware}, \textit{crypto-miner}, \textit{downloader}, \textit{dropper}, \textit{file-infector}, \textit{flooder}, \textit{installer}, \textit{packed}, \textit{ransomware}, \textit{spyware} and \textit{worm}.

These tags were then used to train a Joint Embedding neural network to learn a low dimensional Euclidean representation (embedding) space in which malware samples with similar characteristics are close to each other, having access only to the files' static binary representations; this in turn is used at test/deploy time for automatically predicting tags for new (unseen) files in real time.

Furthermore, the learned low dimensional embedding space (and the associated embedding function) for malicious files enables the comparison between malware samples in terms of \textit{type} of malicious content. This in turns allows the introduction of a similarity index between malware files, allowing for efficient indexing, searching and querying of malware corpora along interpretable dimensions \cite{DucauAMDATSE}.

\paragraph{Malware Family Categorization}
Given the extremely high number of malware samples which are nowadays received by security vendors' labs, in the order of millions per month, it has become unfeasible to manually and consistently group each malicious file into a well defined hierarchy of families. 

The detection names typically used by modern security vendors can be divided into four categories, which contain varying amounts of information about the specific malware families \cite{DucauAMDATSE}.

\begin{itemize}
	\item \textit{Traditional family based}: Detection names are associated to unique and distinctive attributes of malware and its variants. More effort in analysing malware inner-workings is required. Detection names of this type are often of high-quality and have more consistency across vendors.
	
	\item \textit{Technique based}: Detection names group together malware that may come from different origins and/or have multiple authors but share a common method or technique. The difference in detection methods employed by different vendors often results in less consistency in detection names across vendors.
	
	\item \textit{Method based}: Detection names denote the specific detection technology used to detect the malware sample. Some detection names can be that of a patented technology, project, or internal code name specific to the AV vendor, indicating the use of heuristics, ML, or real-time detection technologies. In this case the detection name does not refer to a particular malware family, but to the specific method that was used to detect the sample.
	
	\item \textit{Kit based}: Detection names are associated to kits/tools used to generate the specific malware sample. These kits can be used both offensively by penetration testing teams and by malware authors and are therefore often referred to as grey hat tools. Detection names in this category tend to identify methods used by the kit or tool to obfuscate or hide the payload of a specific malware sample, rather than to describe its origin or functionality.
\end{itemize}

\paragraph{Multi-Label Classification}
The authors of \cite{DucauAMDATSE} applied multi-label classification in order to perform semantic attribute tagging. The most trivial way of implementing a multi-label classification model is by learning one classifier per-label. This approach, however, is far from being efficient since the single per-tag classifiers are independently optimized. In this scenario, it is more common to use a single classifier with multiple outputs (multi-label learning) and multiple target losses which are combined and jointly optimized during training (multi-objective loss). This approach yields a more compact representation while also improving classification performance with respect to using independent classifiers. In \cite{DucauAMDATSE}, the authors used a multi-label deep neural network architecture as baseline architecture.

An alternative approach to multi-label classification is to learn a compact shared vector (embedding) space representation to which map both input samples and labels - a joint embedding - where similar content across modalities are projected into similar vectors in the same low dimensional space \cite{DucauAMDATSE}. Then, at test/deploy time, in order to determine likely labels a similarity comparison between vectors belonging to this learned latent space is performed, e.g. via inner product. In \cite{DucauAMDATSE}, the authors used a joint embedding model that maps malware tags and executable files into the same low dimensional Euclidean joint-embedding space for the malware description problem.

\color{Black}
\paragraph{Tag Distillation from Detection Names}
Ducau et Al. \cite{DucauAMDATSE} relied on semi-automatic strategies, even if they are noisier than manual labelling, because they allowed them to label millions of files that can be then used to train a classifier. In particular, they designed a labelling function which annotates PE files using the previously mentioned set of tags $\mathcal{T}$ by combining information extracted from the detection names got from ten reputable anti-malware vendors.

The labelling process consisted of the following three main stages:
\begin{enumerate}
	\item \textit{token extraction}
	
	\item \textit{token-to-tag mapping}
	
	\item \textit{token relationship mining}
\end{enumerate}

The token extraction phase consisted of normalizing and parsing the multiple detection names and converting them in sets of sub-strings. In a similar way to what the malware labelling tool AVClass, which was proposed by Marcos et al. in \cite{MarcosAVclass}, does, the token-to-tag mapping stage uses rules created from expert knowledge by a group of malware analysts, that associate relevant tokens with the set of tags of interest. Finally, this mapping is extended by mining statistical relationships between tokens to improve tagging stability and coverage.

\paragraph{Tags Prediction - Implementation Details}
In \cite{DucauAMDATSE}, in order to predict, in a multi-label classification manner, zero or more tags per sample from the set of $T$ possible tags $\mathcal{T} = \{t_1, t_2, ..., t_T\}$, the authors proposed two different neural network architectures, represented in \ref{}, which they referred to as \textit{Multi-Head} (top) and \textit{Joint Embedding} (bottom).

In particular, the \textit{Multi-Head} consisted of a base topology common to the prediction of all tags, and one output (or "head") per tag. The shared base topology can be thought of a feature extraction (or embedding) network that transforms the input features $\textbf{x}$ into low dimensional hidden vector $\textbf{h}$ and consisted of an input feed-forward layer of output size 2048, followed by a batch normalization layer, an ELU non-linearity and three blocks, each composed by dropout, a linear layer, batch normalization and ELU of output sizes 512, 128, and 32 respectively. Each head, on the other hand, is a binary classifier that predicts the presence or absence of each tag and it consists of a a linear layer (the same for each head) composed of the same type of basic blocks as are in the main base architecture, but with output size 11 (the number of tags being predicted) and a sigmoid non-linearity instead of the ELU to compute the predicted probability for each label. Binary cross-entropy loss is computed as the output of each head and then added together to form the final loss.

The \textit{Joint Embedding} model, instead, mapped both the labels (malware tags) and the binary file features $\textbf{x}$ to vectors in a joint Euclidean latent-space in such a way that, for a given similarity function, the transformations of semantically similar labels are close to each other, and the embedding of a binary file should be close to that of its associated labels in the same space. In practice, the \textit{Joint Embedding} model consisted on a PE \textit{embedding} network, a \textit{tag embedding} matrix $\textbf{E}$, and a \textit{prediction layer}.

The PE embedding network learns a non-linear function $\phi_\theta(\cdot)$, with parameters $\theta$ that maps the input binary representation of the PE executable file $\textbf{x} \in \mathbb{R}^d$ into a vector $\textbf{h} \in \mathbb{R}^D$ in low dimensional Euclidean space,
\begin{equation} \label{jointEmbeddingPEEmbedding}
	\phi_\theta(\textbf{x}) : \mathbb{R}^d \rightarrow \mathbb{R}^D.
\end{equation}

The tag embedding matrix $\textbf{E} \in \mathbb{R}^{T \times D}$ learns a mapping from a tag $t_n \in \mathcal{T} = \{t_1, ..., t_T\}$, to a distributed representation $\textbf{e} \in \mathbb{R}^D$ in the joint embedding space.
\begin{equation} \label{jointEmbeddingTagEmbedding}
	\phi_E(t) : \{t_1, ..., t_T\} \rightarrow \mathbb{R}^D.
\end{equation}

In practice, the embedding vector for the tag $t_n$ is simply the $n$-th row of the tag embedding matrix, i.e. $\phi_E(t_n) = \textbf{E}_n$.

Finally, the prediction layer compares both the tag and the sample embeddings ($\textbf{e}$ and $\textbf{h}$ respectively) and produces a similarity score. This is later run through a sigmoid non-linearity to estimate the probability that sample $\textbf{x}$ is associated with tag $t$ for each $t \in \mathcal{T}$. In the final model implementation, the similarity score is the dot product between the embedding vectors. The output of the network $f_n(\textbf{x} | \theta, \textbf{E})$ then becomes,
\begin{equation}
	\begin{split} \label{jointEmbeddingProbability}
		\hat{y}_n = f_n(\textbf{x} | \theta, \textbf{E}) & = \sigma(\langle\phi_E(n), \phi_\theta(\textbf{x})\rangle) \\ & = \sigma(\langle\textbf{E}_n, \textbf{h}\rangle),
	\end{split}
\end{equation}
where $\sigma$ is the sigmoid activation function, and $\hat{y}_n$ is the probability estimated by the model of tag $t_n$ being a descriptor for $\textbf{x}$.

Furthermore, the authors of \cite{DucauAMDATSE} constrained the embedding vectors for the tags such that:
\begin{equation}
	||\textbf{E}_n||_2 \leq C, n = 1, ..., T,
\end{equation}
which has a regularizing effect and they fixed the value of $C$ to 1.

During training, the parameters of both embedding functions $\phi_\theta(\cdot)$ and $\phi_E(\cdot)$ are jointly optimized to minimize the binary cross-entropy loss for the prediction of each tag via back-propagation and stochastic gradient descent. The loss function to minimize for a mini-batch of $M$ samples is:
\begin{equation} \label{jointEmbeddingLoss}
	\begin{split}
		\mathcal{L} & = -\frac{1}{M} \sum_{i = 1}^{M} \sum_{n = 1}^{T} f_n(\textbf{x}^{(i)} | \theta, \textbf{E}) \log(t_n^{(i)}) + (1 - f_n(\textbf{x}^{(i)} | \theta, \textbf{E})) \log(1 - t_n^{(i)}) \\ & = -\frac{1}{M} \sum_{i = 1}^{M} \sum_{n = 1}^{T} \hat{y}_n^{(i)} \log(t_n^{(i)}) + (1 - \hat{y}_n^{(i)}) \log(1 - t_n^{(i)})
	\end{split}
\end{equation}
where $t_n^{(i)} = 1$ if sample $i$ is labelled with tag $t_n$ or zero otherwise, and $\hat{y}_n^{(i)}$ is the probability predicted by the network of that tag being associated with the $i$-th sample.

\color{Red}

In practice, to get a vector of tag similarities for a given sample $\textbf{x}$ with PE embedding vector $\textbf{h}$ we multiply the matrix of tag embeddings $\textbf{E} \in \mathbb{R}^{T \times D}$ by $\textbf{h} \in \mathbb{R}^D$ and scale the output to obtain a prediction vector $\hat{\textbf{y}} = \sigma(\textbf{E} \cdot \textbf{h}) \in \mathbb{R}^T$, where $\sigma$ is the element-wise sigmoid function for transforming the similarity values into a valid probability. Each element in $\hat{\textbf{y}}$ is then the predicted probability for each tag.

The authors noted that, because this model maps every tag into the same low dimensional space, it can explicitly account for similarities on the labels. That is, if two tags are likely to occur together, they will be mapped close to each other in embedding space.

Finally, if one compares both models in \ref{}, they are mathematically similar, with the main differences being the explicit modelling of the tag embedding step (and its regularization), the subsequent explicit modelling of the joint embedding space that allows to naturally perform label-to-label and sample-to-sample similarity searches, and the ability to use various distance functions in the prediction layer.

---

The Joint Embedding architecture used the same base topology as the Multi-Head model for the embedding of the PE files into a 32 dimensional joint latent space. An embedding matrix ($\textbf{E}$) of learnable parameters with size $T \times 32$ is used for the embedding of the tags. The authors used dot product to compute the similarity between the PE file embedding and the tag embedding followed by a sigmoid non-linearity to produce an output probability score. As before, the sum of the per-tag binary cross-entropy losses is used as the mini-batch loss during model training.

\color{Black}
\subparagraph{Evaluation of Tagging Algorithms}
\color{Red}
There are different ways to evaluate the performance of tagging algorithms. Particularly, the evaluation can be done in a \textit{per-tag} or a \textit{per-sample} dimension. The former seeks to quantify how well the tagging algorithm performs on identifying each tag, while the latter focuses on the quality of the predictions for each sample instead.

In the \textit{per-tag} case, one suitable way to evaluate the performance of the model is to measure the area under the receiver operating characteristic curve (AUC-ROC, or simply AUC) for each of the tags being predicted. A ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR). Also, since the target value for the $n$-th tag of a given sample is a binary True/False value ($t_n \in \{0, 1\}$), binary classification evaluation metrics such as 'Accuracy', 'Precision', 'Recall', and 'F-score' also apply. To compute these metrics, the output probability prediction needs to be binarized. For the binarization of the predictions, the authors choose a threshold independently for each tag such that the FPR in the validation set is $0.01$ and use the resulting 0/1 predictions.

The \textit{per-sample} evaluation dimension seeks to evaluate the performance of a tagging algorithm for a given sample, across all tags. Let $T^{(i)}$ be the set of tags associated with sample $i$ and $\hat{T}^{(i)}$ the set of tags predicted for the same sample after binarizing the predictions. We can use the Jaccard similarity (or index) $J(T^{(i)}, \hat{T^{(i)}})$ as a figure of how similar both sets are. Furthermore, let $\textbf{y} \in \{0, 1\}^T$ be the binary target vector for a PE file, where $\textbf{y}_n$ indicates whether the $n$-th tag applies to the file and $\hat{\textbf{y}}$ be the binarized prediction vector from a given tagging model. The per-sample accuracy is then defined as the percentage of samples for which the target vector is equal to the prediction vector, i.e. all tags correctly predicted, or, in other words, the Hamming distance between the two vectors is zero. For an evaluation dataset with $M$ samples one can use,
\begin{equation}
	\textrm{Mean Jaccard similarity} = \frac{1}{M} \sum_{i=1}^{M} J(T^{(i)}, \hat{T}^{(i)}) = \frac{1}{M} \sum_{i=1}^{M} \frac{T^{(i)} \cap \hat{T}^{(i)}} {T^{(i)} \cup \hat{T}^{(i)}}
\end{equation}
\begin{equation}
	\textrm{Mean per-sample accuracy} = \frac{1}{M} \sum_{i=1}^{M} \mathbb{I}(\textbf{y}^{(i)} = \hat{\textbf{y}}^{(i)})
\end{equation}
as per-sample performance metrics for the tagging problem, where $\mathbb{I}$ is the indicator function which is 1 if the condition in the argument is true, and 0 otherwise.

\color{Black}
\paragraph{Latent Space (Joint Embedding) Analysis}
\color{Red}
The Joint Embedding network supposedly learns a more informative internal representation of the binary files, guided by the ability to model, and therefore exploit tag relationships (labels structure) in the latent space.

It is also possible to perform file similarity searches: using one malware sample to retrieve other samples with similar malicious characteristics by simply retrieving files for which the embedding representation is close to the representation of the query sample. Furthermore, it can also be used for obtaining examples of malicious programs that fit a given tag description, where with given a combination of descriptive tags we can define a subspace within the embedding space containing those samples that closely match that particular tag combination of interest.

\color{Black}
\subparagraph{File-File Similarity Index}
\color{Red}
The proposed representation of PE files in embedding space, along with the distance function defined in this space, allows to measure not only similarities between files' and tags' embeddings, but between files' representations as well.

Because of how the models were trained, two pieces of malware that are close to each other in latent space should exhibit similar malicious capabilities. This means that it is possible to use the latent representation of the files to measure how similar two pieces of malware are in terms of their capabilities. Moreover, the size of the file embedding representation (32 dimensions) is 32 times smaller than the original file feature representation (1024 dimensions). This makes the task of storing, indexing and querying large databases of malware more efficient.

Because the models are being indirectly trained with malware families' information generated by a group of (quasi-)independent "experts" (anti-malware vendors), via tagging decomposition, then the authors expected to be able to differentiate malware campaigns from each other, even if they are described by the same set of tags.

The authors identified the top $f = 13$ most prominent malware campaigns in the test set that can be convicted with high confidence.

Next, the authors created the joint embedding representation for those files using the already trained Joint Embedding network.

Finally, they set up the task of $f$-way family classification via nearest neighbour search. It consisted in randomly sampling $k$ files per family as anchor samples, and $q$ files per family as query samples. Each of the $(f \cdot q)$ query samples was then predicted to belong to the same class as its closest anchor sample in feature space. A more descriptive representational space should separate malware families, i.e. pull those samples that belong to the same family close to each other while pushing away samples from other families, thus performing better on the nearest neighbour classification task.

The authors considered the neural network embeddings and the original 1024 features as feature spaces for this task. They randomly chose 23 query samples per family and varied the number of anchor samples $k$ from 1 to 10. They repeated the sampling process (for both anchors and query samples), classification and evaluation 15 times per value of $k$ to obtain uncertainty estimates for the accuracy results.

\color{Black}
\subsection{Learning from Context: Exploiting and Interpreting File Path Information for Better Malware Detection}
Recent static portable executable (PE) malware detection techniques, including \cite{ruddALOHA}, typically employ ML-Sec classifiers with a single numerical feature vector derived from each file as input, having as output one or more target labels/tasks during training. However, as noted by Kyadige et. al. in \cite{KyadigeLFCEIFPIBMD}, there is still much unused orthogonal information that could be exploited regarding the samples files, namely the file paths. The authors in \cite{KyadigeLFCEIFPIBMD} thus proposed utilizing the paths of the PE files as static source of contextual information as auxiliary data to the classifier in order to augment static ML detectors. File paths, which are already commonly used by malware analysts to correct and investigate detection errors, are available statically with very little overhead, and can seamlessly be integrated into a multi-view static ML detector.

File paths are not inherently malicious or benign; however, given that many malware strains use specifically crafted file paths to perpetrate their malicious intents (a file path may in fact be chosen to increase the odds of the malware being executed, to avoid disk scans, or to hide from the user's view), they provide much instrumental information that can be used to enhance the overall detection.

In \cite{KyadigeLFCEIFPIBMD}, the authors thus proposed the use of a \textit{multi-view} neural network which combines, in input, information about the PE file content, via feature vectors, with information about how likely it is to see such file in a specific location, through file paths, and outputs a detection score.

To compare their results, they actually focused their experiments on three models:
\begin{itemize}
	\item A baseline file-content-only PE model, which takes only the PE features as input and outputs a malware confidence score.
	
	\item Another baseline file-path-only FP model, which takes only the file's paths as input and outputs a malware confidence score.
	
	\item Their proposed multi-view PE file-content + contextual file-path (PE + FP) model, which takes both the PE file content features and file paths as inputs, and also outputs a malware confidence score.
\end{itemize}

The experiments were conducted on a dataset of files and file paths collected from actual scans on customer endpoints from a large anti-malware vendor.

The authors of \cite{KyadigeLFCEIFPIBMD} finally stated that their proposed multi multi-view classifier trained on both file content and the contextual file paths yielded statistically better results across the ROC curve and particularly in low false positive rate (FPR) regions.

\paragraph{Background and Related work (Static ML Malware Detection)}

\paragraph{Feature Engineering}
In order to be able to use file paths in a feed-forward neural network along with PE file content feature vectors, the file paths, which are strings of variable length, needed to be converted into numerical vectors of fixed size. To do this the authors of \cite{KyadigeLFCEIFPIBMD} created a lookup table keyed on each character with a numeric value (between 0 and the character set size) representing each character. Moreover, the conversion required the file paths to be trimmed to a fixed size, therefore the authors considered just the first 100 characters of each file path.

As features for the content of the PE files, they used floating point 1024-dimensional feature vectors consisting of four distinct feature types, similar to \cite{saxeDNNBMDUTDBPF}:
\begin{enumerate}
	\item A 256-dimensional (16x16) 2D histogram of windowed entropy values per byte with a window size of 1024.
	
	\item A 256-dimensional (16x16) 2D logarithmically scaled string length/hash histogram.
	
	\item A 256-dimensional bin of hashes of metadata from the PE header, including PE metadata, including imports, exports, etc.
	
	\item A 256-dimensional (16x16) byte standard deviation/entropy histogram.
\end{enumerate}
In total, they represented each sample as two feature vectors: A PE-content feature vector of 1024 dimensions and a contextual file-path feature vector of 100 dimensions \cite{KyadigeLFCEIFPIBMD}.

\paragraph{Implementation details}
The model proposed in \cite{KyadigeLFCEIFPIBMD} has two inputs, the 1024 element PE-content feature vector, $\textbf{x}_{PE}$, and the 100 element file-path integer vector, $\textbf{x}_{FP}$. The two distinct inputs are fed to two different base sub-networks, each composed by a series of layers with input-specific parameters: $\theta_{PE}$ for the PE content part and $\theta_{FP}$ parameters for file-path part. The two sets of parameters ($\theta_{PE}$ and $\theta_{FP}$) are jointly optimized during training. The outputs of these base sub-networks are then concatenated and passed through a series of final hidden layers - a joint output sub-network with parameters $\theta_{O}$ terminating with a final dense layer followed by a sigmoid activation function. The final sigmoid activation is used to have as output a detection score between 0 (benign) and 1 (malicious). However, the threshold for determining if a samples is malicious or benign can be set anywhere along the $(0.0, 1.0)$ range according to false positive rate (FPR) and detection rate (TPR) trade-offs for the application at hand - a reasonable threshold is typically at or below $10^{-3}$ FPR.

The PE base sub-network (with parameters $\theta_{PE}$) passes its input $\textbf{x}_{PE}$ through a series of 5 blocks with sizes 1024, 768, 512, 512, and 512, each consisting of four layers: a Fully Connected layer, a Normalization layer, a Dropout layer with dropout probability of 0.05, and a Rectified Linear Unit (ReLU) activation function.

The FP base sub-network (with parameters $\theta_{FP}$), on the other hand, passes $\textbf{x}_{FP}$ first into an Embedding layer that converts the integer input vector into a $(100, 32)$ embedding. This embedding is then fed into 4 parallel convolution blocks with filters of size 2, 3, 4 and 5 respectively, each composed by a 1-D convolution layer with 128 filters, a Layer Normalization layer and a 1-D sum layer to flatten the output to a vector. The flattened outputs of these convolution blocks are then concatenated and serve as input to two dense blocks similar to those found in the PE input arm.

Finally, the outputs from the two base sub-networks are then concatenated and passed into the joint output path with parameters $\theta_{O}$. This output sub-network is composed by dense blocks (same form as in the PE input arm) of layer sizes 512, 256 and 128. Finally, a single fully-connected layer is employed to project the 128-D output from the previous blocks into a 1-D output, followed by a sigmoid activation function that provides the final output score of the model.

The PE-only model can be easily derived from the PE+FP model removing the FP arm, taking input $\textbf{x}_{PE}$ and fitting parameters $\theta_{PE}$ and $\theta_{O}$. Similarly, the FP-only model can be constructed by using the PE+FP model but without the PE sub-network, taking input $\textbf{x}_{FP}$ and fitting parameters $\theta_{FP}$ and $\theta_{O}$. Obviously the first layer of the output sub-network needs to be modified to match the output from the previous layer.

In \cite{KyadigeLFCEIFPIBMD}, the authors fit all models using a binary cross entropy loss function. Therefore, denoting the output of the model as $f(\textbf{x}; \theta)$, where $\textbf{x}$ is the model input, $\theta$ are the model parameters and $y \in \{0,1\}$ are the ground truth labels, the loss is:
\begin{equation} \label{LearningFromContextLoss}
	L(\textbf{x}, y; \theta) = - y \log{(f(\textbf{x}; \theta))} + (1 - y) \log{(1 - f(\textbf{x}; \theta))}.
\end{equation}

During training, the equation is optimized for $\hat{\theta}$: the optimal set of parameters that minimize the combined loss over the dataset.
\begin{equation} \label{LearningFromContextParameters}
	\hat{\theta} =  \argmax_{\theta} \sum_{i = 1}^{M} L(\textbf{x}^{(i)}, y_i; \theta),
\end{equation}
where $M$ is the number of samples in the dataset, and $y_i$ and $\textbf{x}^{(i)}$ are the label and the feature vector of the \textit{i}th training sample respectively \cite{KyadigeLFCEIFPIBMD}.

\section{Malware Normalization}
In order to improve the detection rate of existing anti-malware techniques also against malware produced by advanced packers and toolkits, code \textit{normalization} techniques can be exploited. These techniques consist of a \textit{normalizer} which accepts obfuscated code as input and tries to eliminate obfuscation producing as output the normalized executable.

After \textit{normalization}, the usual signature-based techniques can be applied on the normalized sample \cite{Sharma_2014}.

\chapter{Datasets}
\color{Red}

\color{Black}
\section{Ember Dataset}
\color{Red}

(Abstract)
EMBER is a labelled benchmark dataset for training machine learning models to statically detect malicious Windows Portable Executable (PE) files. The dataset includes features extracted from 1.1M binary files: 900K training samples (300K malicious, 300K benign, 300K unlabelled) and 200K test samples (100K malicious, 100K benign). The authors also released open source code for extracting features from additional binaries so that additional sample features can be appended to the dataset. This dataset fills a void in the information security machine learning community: a benign/malicious dataset that is large, open and general enough to cover several interesting use cases \cite{AndersonEMBER}.

---

(Introduction)
Machine learning can be an attractive tool for either a primary detection capability or supplementary detection heuristics. Supervised learning models automatically exploit complex relationships between file attributes in training data that are discriminating between malicious and benign samples. Furthermore, properly regularized machine learning models generalize to new samples whose features and labels follow a similar distribution to the training data.

However, malware detection using machine learning has not received nearly the same attention in the open research community as other applications, where rich benchmark datasets exist. These include handwritten digit classification (e.g. MNIST), image labelling (e.g. CIFAR or ImageNet), traffic sign detection, speech recognition (e.g. TIMIT), sentiment analysis, and a host of other datasets suitable for training models to mimic human perception and cognition tasks. The challenges to releasing a benchmark dataset for malware detection are many, and may include the following: \textit{Labelling challenges}. Unlike images, text and speech - which may be labelled relatively quickly, and in many cases by a non-expert - determining whether a binary file is malicious benign can be a time-consuming process for even the well-trained. The work of labelling may be automated via anti-malware scanners that codify much of this human expertise, but the results may be proprietary or otherwise protected.

The authors address this issue with the release of the Endgame Malware BEnchmark for Research (EMBER) dataset, extracted from a large corpus of Windows Portable Executable (PE) malicious and benign files. Samples are released together with the sha256 hash of the original file, and a label to denote whether the file is deemed to be malicious or benign \cite{AndersonEMBER}.

\color{Black}
\subsection{PE File Format}
\color{Red}

The PE file format describes the predominant executable format for Microsoft Windows operating systems, and includes executables, dynamically-linked libraries (DLLs), and FON font files. The format is currently supported on Intel, AMD and variants of ARM instruction set architectures.

The file format is arranged with a number of standard headers (\ref{}), followed by one or more sections. Headers include the Common Object File Format (COFF) file header that contains important information such as the type of machine for which the file is intended, the nature of the file (DLL, EXE, OBJ), the number of sections, the number of symbols, etc. The optional header identifies the linker version, the size of the code, the size of initialized and uninitialized data, the address of the entry point, etc. Data directories within the optional header provide pointers to the sections that follow it. This includes tables for exports, imports, resources, exceptions, debug information, certificate information, and relocation tables. AS such, it provides a useful summary of the contents of an executable. Finally, the section table outlines the name, offset and size of each section in the PE file.

PE sections contain code and initialized data that the Windows loader is to map into executable or readable/write-able memory pages, respectively, as well as imports, exports and resources defined by the file. Each section contains a header that specifies the size and address. An import address table instructs the loader which functions to statically import. A resources section may contain resources such as required for user interfaces: cursors, fonts, bitmaps, icons, menus, etc. A basic PE file would normally contain a \textit{.text} code section and one or more data sections (\textit{.data}, \textit{.text} or \textit{.bss}). Relocation tables are typically stored in a \textit{.reloc} section, used by the Windows loader to reassign a base address from the executable's preferred base. A \textit{.tls} section contains special thread local storage (TLS) structure for storing thread-specific local variables, which has been exploited to redirect the entry point of an executable to first check if a debugger or other analysis tool are being run. Section names are arbitrary from the perspective of the Windows loader, but specific names have been adopted by precedent and are overwhelmingly common. Packers may create new sections, for example, the UPX packer creates \textit{UPX1} to house packed data and an empty section \textit{UPX0} that reserves an address range for runtime unpacking \cite{AndersonEMBER}.

\color{Black}
\subsection{Static PE Malware Detection}
\color{Red}

(to be moved)
Static malware detection attempts to classify samples as malicious or benign without executing them, in contrast to dynamic malware detection which detects malware based on its runtime behaviour including time-dependent sequences of system calls for analysis. Although static detection is well-known to be undecidable in general, it is an important protection layer in a security suite because when successful, it allows malicious files to be detected prior to execution.

Machine learning-based static PE malware detectors have been used since at least 2001, and owing largely to the structured file format and backwards-compatibility requirements, many concepts remain surprisingly similar in subsequent works. Schultz et al. \cite{} assembled a dataset and generated labels by running through a McAfee virus scanner. PE files were represented by features that included imported functions, strings and byte sequences. Various machine learning models were trained and validated on a holdout set. Models included rules induced from RIPPER \cite{}, naive Bayes and an ensemble classifier. Kolter et al. \cite{} extended this approach by including byte-level N-grams, and employed techniques from natural language processing, including \textit{tf-idf} weighting of strings. Shafiq et al. \cite{} proposed using just seven features from the PE header, motivated by the fact that most malware samples in their study typically exhibited those elements. Saxe and Berlin leveraged novel two dimensional byte entropy histograms that is fed into a multi-layer neural network for classification \cite{}.

Recent advances in end-to-end deep learning have dramatically improved the state of the art especially in object classification, machine translation and speech recognition. In many of these approaches, raw images, text or speech waveforms are used as input to a machine learning model which infers the most useful feature representation for the task at hand. However, despite successes in other domains, hand-crafted features apparently still represent the state of the art for malware detection in published literature. The state of the art may change to end-to-end deep learning in the ensuing months or years, but hand-crafted features derived from parsing the PE file may continue to be relevant indefinitely because of the structured format \cite{AndersonEMBER}.

\color{Black}
\subsection{Malicious and benign datasets}
\color{Red}

(to be moved)
PE-Miner aimed to produce a machine-learning based malware detector with high true positive rate (TPR) at low false positive rates (FPRs), with a runtime comparable to signature-based scanners of the day \cite{}. It was trained on a dataset of $\sim1K$ benign files on the operating system, $\sim10K$ malicious PE files from VXHeaven and $\sim5K$ malicious PE files from Malfease. Unfortunately, many of the features were not disclosed publicly, some being deemed sensitive and protected under NDA. Several model types were evaluated on the dataset, and of those, it was discovered that the J48 decision tree algorithm provided the best performance. Notably, although many papers cite this work as one of the first performant non-signature-based methods, the lack of public dataset has resulted no real comparative study.

Shortly following, the Adobe Malware Classifier aimed to produce a malware classifier from only seven features: debug size, image version, relative virtual address of the import address table, export size, resource size, virtual size of the second section, and the total number of sections. A decision tree algorithm was trained and the resulting classifier released as a freely available tool. It has been suggested, however, that since the benign dataset largely comprised of Windows binaries, the resulting models is strongly biased towards a non-Windows vs. Windows rather than a malicious vs. benign problem. Moreover, unfortunately, the dataset consisting of $\sim100K$ malicious and $\sim16K$ benign files was never released for comparative research.

In contrast, the Microsoft Malware Classification Challenge 500MB dataset consisted of disassembly and byte-code of $\sim20K$ malicious samples from 9 families. The largest family consisted of features from $3K$ samples, while the smallest family included only 42 samples. Since the conclusion of the competition, more than 50 research papers and theses cited the dataset. Unfortunately, the disassembly features are specific to IDA Pro disassembler, and the dataset contains no benign files.

Malware sharing services like VXHeaven provide an ample supply of malicious binaries. VirusTotal can be mined for supposed benign files using heuristics about the number of detections of vendor participants. However, large-scale file access rates in VirusTotal require a payed subscription. Regardless, an agreed-upon set of malicious and benign files for machine learning benchmark purposes is so far non-existent \cite{AndersonEMBER}.

\color{Black}
\subsection{Data Description}
\color{Red}

In crafting the EMBER dataset, the authors considered several practical use cases and research studies, including the following \cite{AndersonEMBER}.
\begin{itemize}
	\item Compare machine learning models for malware detection.
	
	\item Quantify model degradation and concept drift over time.
	
	\item Research interpretable machine learning.
	
	\item Compare features for malware classification, particularly novel features not represented in the EMBER dataset. This requires an extensible dataset.
	
	\item Compare to featureless end-to-end deep learning. This may require code to extract features from a new dataset, or sha256 hashes to build a raw binary dataset to match EMBER.
	
	\item Research adversarial attacks against machine learning malware, and subsequent defence strategies.
	
	\item Leverage unlabelled samples via unsupervised learning for PE file representation or semi-supervised learning for classification.
\end{itemize}

\color{Black}
\subsection{Data Layout}
\color{Red}

The EMBER dataset consists of a collection of JSON lines files, where each line contains a single JSON object. Each object includes the following types in data:
\begin{itemize}
	\item the sha256 hash of the original file as a unique identifier;
	
	\item coarse time information (month resolution) that establishes an estimate of when the file was first seen;
	
	\item a label, which may be 0 for benign, 1 for malicious or -1 for unlabelled;
	
	\item 8 groups of raw features that include both parsed values as well as format-agnostic histograms.
\end{itemize}

For convenience the dataset is comprised of raw features that are human readable. The code that produces a numeric feature vector required for model building from raw features is also provided.

The authors temporally split the training/test sets to mimic generational dependencies of both malicious and benign software. The coarse time stamps for one year of malicious and benign files may also allow for simple longitudinal studies. Including the sha256 hash of the original file allows researchers to link features to the raw binaries, including other metadata that may be available through file sharing sites like VirusShare or VirusTotal \cite{AndersonEMBER}.

\color{Black}
\subsection{Feature Set Description}
\color{Red}

The EMBER dataset consists of 8 groups of raw features that include both parsed features and format-agnostic histograms and counts of strings. The authors made a distinction between \textit{raw features} (the dataset provided) and \textit{model features} (or \textit{vectorized features}) derived from the dataset. \textit{Model features} represent a feature matrix of fixed size used for training a model, representing a numerical summary of the raw features, wherein strings, imported names, exported names, etc., are captured using the feature hashing trick \cite{}. The feature matrix is not explicitly provided in the published dataset, but code is provided to convert raw features to model features to train a model \cite{AndersonEMBER}.

\color{Black}
\subsubsection{Parsed features}
\color{Red}

The dataset includes 5 groups of features that are extracted after parsing the PE file. The authors leveraged the \textit{Library to Instrument Executable Formats} \cite{} as a convenient PE parser. \textit{LIEF} names are used for strings that represent symbolic objects, such as characteristics and properties \cite{AndersonEMBER}.

\color{Black}
\paragraph{General file information}
\color{Red}

The set of features in the general file information group includes the file size and basic information obtained from the PE header: the virtual size of the file, the number of imported and exported functions, whether the file has a debug section, thread local storage, resources, relocations, or a signature, and the number of symbols \cite{AndersonEMBER}.

\color{Black}
\paragraph{Header information}
\color{Red}

From the \textit{COFF} header, the authors reported the timestamp in the header, the target machine (string) and a list of image characteristics (list of strings). From the optional header, the authors provide the target subsystem (string), DLL characteristics (a list of strings), the file magic as a string (e.g. "PE32"), major and minor image versions, linker versions, system versions and subsystem versions, and the code, headers and commit sizes. TO create model features, string descriptors such as DLL characteristics, target machine, subsystem, etc. are summarized using the feature hashing trick prior to training a model, with 10 bins allotted for each noisy indicator vector \cite{AndersonEMBER}.

\color{Black}
\paragraph{Imported functions}
\color{Red}

The authors parse the import address table and report the imported functions by library. To create model features for the baseline model, the authors simply collect the set of unique libraries and use the hashing trick to sketch the set (256 bins). Similarly, they use the hashing trick (1024 bins) to capture individual functions, by representing each as a string such as \textit{library:FunctionName} pair (e.g. \textit{kernel32.dll:CreateFileMappingA}) \cite{AndersonEMBER}.

\color{Black}
\paragraph{Exported functions}
\color{Red}

The raw features include a list of the exported functions. These strings are summarized into model features using the hashing trick with 128 bins \cite{AndersonEMBER}.

\color{Black}
\paragraph{Section information}
\color{Red}

Properties of each section are provided and include the name, size, entropy, virtual size, and a list of strings representing section characteristics. The entry point is specified by name. To convert to model features, the authors used the hashing trick on (section name, value) pairs to create vectors containing section size, section entropy, and virtual size (50 bins each). They also used the hashing trick to capture the characteristics (list of strings) for the entry point \cite{AndersonEMBER}.

\color{Black}
\subsubsection{Format-agnostic features}
\color{Red}

The EMBER dataset also includes three groups of features that are format agnostic, in that they do not require parsing of the PE file for extraction: a raw byte histogram, byte entropy histogram based on work previously published in \cite{}, and string extraction \cite{AndersonEMBER}.

\color{Black}
\paragraph{Byte histogram}
\color{Red}

The byte histogram contains 256 integer values, representing the counts of each byte value within the file. When generating model features, this byte histogram is normalized to a distribution, since the file size is represented as a feature in the general file information \cite{AndersonEMBER}.

\color{Black}
\paragraph{Byte-entropy histogram}
\color{Red}

The byte entropy histogram approximates the joint distribution $p(H, X)$ of entropy $H$ and byte value $X$. This is done as described in \cite{}, by computing the scalar entropy $H$ for a fixed-length window and pairing it with each byte occurrence within the window. This is repeated as the window slides across the input bytes. In their implementation, the authors used a window size of 2048 and a step size of 1024 bytes, with $16 \times 16$ bins that quantize entropy and the byte value. Before training, these counts are normalized to sum to unity \cite{AndersonEMBER}.

\color{Black}
\paragraph{String information}
\color{Red}

The dataset includes simple statistics about printable strings (consisting of characters in the range \textit{0x20} to \textit{0x7f}, inclusive) that are at least five printable characters long. In particular, reported are the number of strings, their average length, a histogram of the printable characters within those strings, and the entropy of characters across all printable strings. The printable characters distribution provides distinct information from the byte histogram information above since it is derived only from strings containing at least five consecutive printable characters. In addition, the string feature group includes the number of strings that begin with \textit{C:\textbackslash} (case insensitive) that may indicate a path, the number of occurrences of \textit{http://} or \textit{http://} (case insensitive) that may indicate a \textit{URL}, the number of occurrences of \textit{HKEY\_} that may indicate a registry key, and the number of occurrences of the short string \textit{MZ} that may provide weak evidence of a Windows PE dropper or bundled executables. By providing a simple statistical summary of strings rather than a listing of raw strings, the authors mitigate privacy concerns that may exist for some benign files \cite{AndersonEMBER}.

\color{Black}
\section{Sorel 20M Dataset}
\color{Red}

(Abstract)
Sorel20M dataset is a large-scale dataset consisting of nearly 20 million files with pre-extracted features and metadata, high-quality labels derived from multiple source, information about vendor detections of the malware samples at the time of collection, and additional "tags" related to each malware sample to serve as additional targets. IN addition to features and metadata, the authors also provided approximately 10 million "disarmed" malware samples - samples with both the \textit{optional\_headers.subsystem} and \textit{file\_header.machine} flags set to zero - that may be used for further exploration of features and detection strategies \cite{HarangSOREL20M}.

---

(Introduction)
The use of machine learning for malware detection is now relatively widespread. The ability for modern machine learning models to learn complex relationships between a large number of both statistical and parse-based features has lead to their widespread adoption. However, the risks associated with working directly with malware, as well as the commercial nature of much research in this space, has meant that most ML-based malware models are evaluated on private or proprietary datasets. This makes measuring progress in the field difficult. Furthermore, many sources of malware are commercial in nature, placing a high barrier of entry to the field and leading to researchers evaluating their models on extremely small datasets.

In contrast, fields like image classification or natural language processing have arguably benefited immensely from large, publicly available datasets such as CIFAR and ImageNet, which allow researchers to apply different approaches on a common dataset, making a direct comparison of those approaches possible. In addition to providing a basis for comparison between approaches, the existence of these common datasets has also made the fields more accessible, allowing smaller organizations that lacked the ability to compile large training and validation sets to contribute to the development of those fields.

The first attempt to address this lack was the seminal EMBER dataset \cite{}, which SOREL20M dataset builds upon. The EMBER dataset was the first standard dataset to be used for malware detection, however it had some shortcomings that limited its utility as a malware benchmark set. First, EMBER was of limited size, containing 900,000 training samples and 200,000 test samples, while commercial malware models are trained on tens to hundreds of millions of samples. In addition to the training size being too small to compare to commercial scale, the small validation size makes evaluation of model performance at lower false positive rates (1 in 1000 or below) difficult due to variance issues. Perhaps due to the relatively small size of the dataset, performance of classifiers on EMBER is nearly saturated, with a baseline classifier capable of obtaining an AUC of over 0.999. In addition, the EMBER dataset provided only pre-extracted features, making further research in such topic as improvements in feature extraction or realizable adversarial sample generation difficult. Finally, EMBER provides only a single binary label based on a simple "thresholding" rule.

SOREL-20M attempts to address these issues in whole or in part. The issue of training size is addressed by providing an order of magnitude more samples for analysis. Internally, the authors found that while performance continues to improve with larger datasets, validation sizes on the order of 3 to 4 million examples are sufficient to establish a stable rank order between models as well as to assess performance at lower false positive rates. When using the recommended time splits to establish training, validation and test sets, there are 12,699,013 training samples, 2,495,822 validation samples and 4,195,042 test samples, respectively.

The issue of feature exploration is partially addressed by providing (disarmed) binary samples for the malware only. The authors provided 9,919,251 samples of malware (7,596,407 training samples, 962,222 validation samples and 1,360,622 test samples), which have been 'disarmed' by setting both the \textit{optional\_headers.subsystem} and \textit{file\_header.machine} to 0 in order to prevent execution. They also have provided complete PE metadata as obtained via the Python \textit{pefile} module using the \textit{dump\_dict} method.

Finally, the authors provided a number of additional targets (SMART tags) for the model that describe behaviour inferred from vendor labels \cite{HarangSOREL20M}.

The dataset is stored as a AWS bucket

\color{Black}
\subsection{Sorel 20M Dataset Description}
\color{Red}

The complete dataset consists of the following items:
\begin{itemize}
	\item The 9,919,251 original (disarmed) malware samples compressed via the Python \textit{zlib.compress} function
	
	\item A SQLite3 and two LMDB databases:
	\begin{itemize}
		\item The SQLite3 "meta.db" database contains malware labels, tags, detection counts, and first/last seen times
		
		\item The "ember\_features" LMDB database contains EMBER features (extracted with version 2 of the features)
		
		\item the "pe\_metadata" LMDB database contains the PE metadata extracted via the \textit{pefile} module, as described above
	\end{itemize}

	\item Some Pre-trained baseline models (a Pytorch feed-forward neural network (FFNN) model and a LightGBM gradient-boosted decision tree model) and their results are also provided, but will not be used in this document.
\end{itemize}

All samples are identified by their sha256 hash; in the case of the disarmed malware samples, the sha256 of the original (unmodified) file was used, and not the sha256 of the disarmed file. The sha256 hash serves as the primary key for the SQLite3 database, and the key for the two LMDB databases. LMDB entries are stored as arrays or dictionaries (for EMBER feature vectors or PE metadata. respectively) that are then serialized with \textit{msgpack} and compressed with \textit{zlib}.

The data was collected from January 1st, 2017 to April 10th, 2019. The authors suggested time-splits of the data - based upon the first-seen time in RL telemetry - as follows: training data from the beginning of collection until November 29th, 2018; validation data from then until January 12th, 2019; and testing data from January 12th, 2019 through the end of the data \cite{HarangSOREL20M}.

\color{Black}
\paragraph{LMDB database, what is it?}
\color{Red}

LMDB (Lightning Memory-Mapped Database) is a embedded database for key-value data based on B+trees. It is fully ACID transactional. The key features of LMDB are that it uses a single-level store based on memory-map files, which means that the OS is responsible for managing the pages (like caching frequently uses pages). It uses shared memory copy-on-write semantics with a single writer; readers do not block writers, writers do not block readers, and readers do not block readers. The system allows as many versions of data at any time as there are transactions (many read, one write). It also maintains a free list of pages to track and reuse pages instead of allocating memory each time.

---

LMDB is a Btree-based database management library modeled loosely on the BerkeleyDB API, but much simplified. The entire database is exposed in a memory map, and all data fetches return data directly from the mapped memory, so no malloc's or memcpy's occur during data fetches. As such, the library is extremely simple because it requires no page caching layer of its own, and it is extremely high performance and memory-efficient. It is also fully transactional with full ACID semantics, and when the memory map is read-only, the database integrity cannot be corrupted by stray pointer writes from application code.

The library is fully thread-aware and supports concurrent read/write access from multiple processes and threads. Data pages use a copy-on- write strategy so no active data pages are ever overwritten, which also provides resistance to corruption and eliminates the need of any special recovery procedures after a system crash. Writes are fully serialized; only one write transaction may be active at a time, which guarantees that writers can never deadlock. The database structure is multi-versioned so readers run with no locks; writers cannot block readers, and readers don't block writers.

Unlike other well-known database mechanisms which use either write-ahead transaction logs or append-only data writes, LMDB requires no maintenance during operation. Both write-ahead loggers and append-only databases require periodic checkpointing and/or compaction of their log or database files otherwise they grow without bound. LMDB tracks free pages within the database and re-uses them for new write operations, so the database size does not grow without bound in normal use.

The memory map can be used as a read-only or read-write map. It is read-only by default as this provides total immunity to corruption. Using read-write mode offers much higher write performance, but adds the possibility for stray application writes thru pointers to silently corrupt the database. Of course if your application code is known to be bug-free (...) then this is not an issue \cite{ChuLMDBDoc}.

---

Lightning Memory-Mapped Database (LMDB) is a software library that provides a high-performance embedded transactional database in the form of a key-value store. LMDB stores arbitrary key/data pairs as byte arrays, has a range-based search capability, supports multiple data items for a single key and has a special mode for appending records at the end of the database which gives a dramatic write performance increase over other similar stores. LMDB is not a relational database, it is strictly a key-value store.

LMDB may also be used concurrently in a multi-threaded or multi-processing environment, with read performance scaling linearly by design. LMDB databases may have only one writer at a time, however unlike many similar key-value databases, write transactions do not block readers, nor do readers block writers. LMDB is also unusual in that multiple applications on the same system may simultaneously open and use the same LMDB store, as a means to scale up performance. Also, LMDB does not require a transaction log (thereby increasing write performance by not needing to write data twice) because it maintains data integrity inherently by design.

\color{Black}
\subsection{Trying to improve Dataset Loading Speed}
\color{Red}

\color{Black}
\subsubsection{Dataset Pre-Processing}
\color{Red}

To speed up the code (particularly the trainig step) the dataset is pre-processed and saved to Google Drive in a easier (and faster) to read format. In particular the dataset is opened and read (and pre-processed), as was done in the original code every cycle, as it is saved 'as-is' to file. Doing so it is only needed to read it back into RAM 'as-is' during training, with no further processing. This greatly speeds up the overall training.

This however led to disk space problems since the pre-processed dataset is much bigger than the original one (which contained compressed features).

To speed up the code (specifically the training procedure, which is the one that takes longest), the dataset is pre-processed. Doing so speeded up the training execution: with the previous version I was able to train the model with a maximum of 400'000 samples in about 7:30h; now, instead, I managed to train the model with $2M$ samples in about 3:08h. This makes it feasable to run model training on $6M$ samples, which is a good amount of samples. However a new problem has now emerged: the pre-processed dataset occupies far more disk space than the original dataset (considering the same amount of samples). This is not a real problem for training, provided there is enough disk space for the pre-processed dataset alone (in fact I can pre-process the dataset separately and later import it without the need of downloding the original dataset).

I managed to pre-process $6M$ samples developing a variation of the pre-process function called "\textit{pre-process multi}". In particular I pre-processed the dataset creating multiple small files which were saved on a different hard drive (google drive) than the instance one. Then, on a new (clean) instance I merged downloaded and merged all those files together, compressed the resulting pre-processed dataset and uploaded it on google drive. The final dataset size is approximately 70 GB (containing $6M$ samples), but after compression it takes about 18 GB of space. The dataset can now be imported on new instances and de-compressed before training.
With this optimization I trained the model using $6M$ samples. The model took approximately 6 hours to complete just 1 training epoch. Considering 10 epochs I would need approximately 60 hours in total.

\color{Black}
\subsubsection{Alternative Generators (Dataloaders)}
\color{Red}

As a further optimization I tried implementing 2 new dataloader variants which could have been more efficient:

\color{Black}
\paragraph{Generator alt1}
\color{Red}

The alternative generator 1 ('$alt1$') was inspired by the '\textit{index select}' version of \textit{FastTensorDataLoader} suggested in this post. In this version the dataset is loaded as a set of memory-mapped numpy arrays (one array for the features, one for the labels and one for the sha256 hashes) from which batches of data are randomly sampled using the pytorch '$index\_select$' function. Moreover, my version (differently from the original suggested one) is able to work also with multiple workers (in \textit{multithreading}).

\begin{algorithm}
	\caption{Alt1 get\_batch function}\label{Alt1GetBatch}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Function{get\_batch}{\textit{tensors}, \textit{batch\_size}, \textit{i}, \textit{indices}, ...}
			\State \textit{batch} $\gets$ [ ]
			\If {\textit{indices} is provided}
			%\textcolor{codegreen}{\Comment{If \textit{indices} are provided use them}}
				\State \textit{indices} $\gets$ \textit{indices}[\textit{i}:(\textit{i} + \textit{batch\_size})]
				%\textcolor{codegreen}{\Comment{get current batch indices}}
				\State
				\If {len(\textit{tensors}) $= 3$}
				%\textcolor{codegreen}{\Comment{if \textit{tensors} contains also \textit{S} (shas) data}}
					\State \textit{batch}[0] $\gets$ \textit{tensors}[0][\textit{indices}]
					%\textcolor{codegreen}{\Comment{Select shas using \textit{indices}}}
				\EndIf
				\State
				\ForAll{\textit{t} $\in$ \textit{tensors}[$-2$:]}
				%\textcolor{codegreen}{\Comment{For the last 2 tensors in \textit{tensors} (\textit{X} and \textit{y})}}
					\State \textit{batch\_data} $\gets$ \textbf{index\_select}(\textit{t}, \textit{indices})
					%\textcolor{codegreen}{\Comment{Select data from the current tensor \textit{t}}}
					\State \textit{batch.}\textbf{append}(\textit{batch\_data})
					%\textcolor{codegreen}{\Comment{Append selected \textit{batch\_data} to \textit{batch} array}}
				\EndFor
			\Else
			%\textcolor{codegreen}{\Comment{Get the data in order}}
				\ForAll{\textit{t} $\in$ \textit{tensors}}
				%\textcolor{codegreen}{\Comment{For all tensors in \textit{tensors}}}
					\State \textit{batch\_data} $\gets$ \textit{t}[\textit{i}:(\textit{i} + \textit{batch\_size})]
					%\textcolor{codegreen}{\Comment{Select data from the current tensor \textit{t}}}
					\State \textit{batch.}\textbf{append}(\textit{batch\_data})
					%\textcolor{codegreen}{\Comment{Append selected \textit{batch\_data} to \textit{batch} array}}
				\EndFor
			\EndIf
			\State
			\State \textbf{return} \textit{batch}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Alt1 FastDataLoader class, Init}\label{Alt1FastDataLoaderInit}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Class{FastTensorDataloader}
			\Function{Init}{\textit{self}, \textit{tensors}, \textit{batch\_size}, \textit{shuffle}, \textit{num\_workers}, ...}
				\State \textit{self.tensors} $\gets$ \textit{tensors}
				\State \textit{self.batch\_size} $\gets$ \textit{batch\_size}
				\State \textit{self.shuffle} $\gets$ \textit{shuffle}
				\State \textit{self.num\_workers} $\gets$ \textit{num\_workers}
				\State \textit{self.dataset\_len} $\gets$ \textit{tensors}[0].\textbf{shape}[0]
				%\textcolor{codegreen}{\Comment{Get dataset total length}}
				\State
				\If{\textit{num\_workers} $> 1$}
					\State \textit{self.async\_results} $\gets$ [ ]
					%\textcolor{codegreen}{\Comment{Initialize async results list}}
					\State \textit{self.pool} $\gets$ \textbf{ThreadPool}()
					%\textcolor{codegreen}{\Comment{Initialize Thread pool}}
				\EndIf
				\State
				\State \textit{self.n\_batches} $\gets \lceil$\textit{self.dataset\_len} / \textit{self.batch\_size}$\rceil$
				%\textcolor{codegreen}{\Comment{Compute number of batches}}
			\EndFunction
			\algstore{bkbreak}
		\end{algorithmic}
	\end{algorithm}

\begin{algorithm}[h]
	\caption{Alt1 FastDataLoader class, Iter}\label{Alt1FastDataLoaderIter}
	\begin{algorithmic}[1]
		\algrestore{bkbreak}
			\Function{Iter}{\textit{self}}
				\If{\textit{self.shuffle} $=$ \textit{true}}
					\State \textit{self.indices} $\gets$ \textbf{randperm}(\textit{self.dataset\_len})
					%\textcolor{codegreen}{\Comment{Randomly create indices}}
				\Else
					\State \textit{self.indices} $\gets$ None
					%\textcolor{codegreen}{\Comment{No indices are created}}
				\EndIf
				\State
				\State \textit{self.i} $\gets$ 0
				%\textcolor{codegreen}{\Comment{Set current index to 0}}
				\State \textbf{return} \textit{self}			
			\EndFunction
			\algstore{bkbreak}
		\end{algorithmic}
	\end{algorithm}

\begin{algorithm}[h]
	\caption{Alt1 FastDataLoader class, Next}\label{Alt1FastDataLoaderNext}
	\begin{algorithmic}[1]
		\algrestore{bkbreak}
			\Function{Next}{\textit{self}}
				\If{\textit{self.i} $\ge$ \textit{self.dataset\_len}}
				%\textcolor{codegreen}{\Comment{If we are at the end of the dataset}}
					\If{(\textit{self.num\_workers} $= 1$ \textbf{or} \textbf{len}(\textit{self.async\_results}) $= 0$)}
					%\textcolor{codegreen}{\Comment{If just 1 worker was used or there are no async results to wait for in case of multiple workers}}
						\State \textbf{raise} \textit{StopIteration}
						%\textcolor{codegreen}{\Comment{Stop iteration}}
					\EndIf
				\EndIf
				\State
				\If{\textit{self.num\_workers} $= 1$}
					\State \textit{batch} $\gets$ \textbf{get\_batch}(\textit{self.tensors}, \textit{self.batch\_size}, \textit{self.i}, \textit{self.indices})
					%\textcolor{codegreen}{\Comment{Get batch of data}}
					\State \textit{self.i} $\gets$ \textit{self.i} + \textit{self.batch\_size}
					%\textcolor{codegreen}{\Comment{Update current index}}
					\State \textbf{return} \textit{batch}
				\Else
					%\textcolor{codegreen}{\Comment{Until there is data in the dataset and there is space in the \textit{async\_results} list}}
					\While{\textit{self.i} $<$ \textit{self.dataset\_len} \textbf{and} \textbf{len}(\textit{self.async\_results}) $<$ \textit{self.num\_workers}}
						\State \textit{arguments} $\gets$ (\textit{self.tensors}, \textit{self.batch\_size}, \textit{self.i}, \textit{self.indices})
						%\textcolor{codegreen}{\Comment{Set \textit{get\_batch} arguments}}
						\State \textit{async\_task} $\gets$ \textit{self.pool}.\textbf{apply\_async}(\textbf{get\_batch}, \textit{arguments})
						%\textcolor{codegreen}{\Comment{Asynchronously call \textbf{get\_batch} function}}
						\State \textit{self.async\_results}.\textbf{append}(\textit{async\_task})
						%\textcolor{codegreen}{\Comment{Append async task to \textit{async\_results}}}
						\State \textit{self.i} $\gets$ \textit{self.i} + \textit{self.batch\_size}
						%\textcolor{codegreen}{\Comment{Update current index}}
					\EndWhile
					\State
					\State \textit{current\_result} $\gets$ \textit{self.async\_results}.\textbf{pop}(0)
					%\textcolor{codegreen}{\Comment{Pop first element of \textit{async\_results}}}
					\State \textbf{return} \textit{current\_result}.\textbf{get}()
					%\textcolor{codegreen}{\Comment{Wait for task completion and return its value}}
				\EndIf
			\EndFunction
		\EndClass
	\end{algorithmic}
\end{algorithm}

\color{Black}
\paragraph{Generator alt2}
\color{Red}

The alternative generator 2 ('$alt2$') was inspired by the '\textit{shuffle in-place}' version of \textit{FastTensorDataLoader} suggested in this post. In this version the dataset is again loaded as a set of memory-mapped numpy arrays, as version 1. In this case, however, the arrays are randomly shuffled in place at each iteration, before sampling (in order) batches of data from them. Again, my version (differently from the original suggested one) is able to work also with multiple workers (in \textit{multithreading}).

\begin{algorithm}
	\caption{Alt2 get\_batch function}\label{Alt2GetBatch}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Function{get\_batch}{\textit{tensors}, \textit{batch\_size}, \textit{i}, ...}
			\State \textit{batch} $\gets$ [ ]
			%\textcolor{codegreen}{\Comment{Get the data in order}}
			\ForAll{\textit{t} $\in$ \textit{tensors}}
				%\textcolor{codegreen}{\Comment{For all tensors in \textit{tensors}}}
				\State \textit{batch\_data} $\gets$ \textit{t}[\textit{i}:(\textit{i} + \textit{batch\_size})]
				%\textcolor{codegreen}{\Comment{Select data from the current tensor \textit{t}}}
				\State \textit{batch}.\textbf{append}(\textit{batch\_data})
				%\textcolor{codegreen}{\Comment{Append selected \textit{batch\_data} to \textit{batch} array}}
			\EndFor
			\State
			\State \textbf{return} \textit{batch}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Alt2 FastDataLoader class, Init}\label{Alt2FastDataLoaderInit}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Class{FastTensorDataloader}
			\Function{Init}{\textit{self}, \textit{tensors}, \textit{batch\_size}, \textit{shuffle}, \textit{num\_workers}, ...}
				\State \textit{self.tensors} $\gets$ \textit{tensors}
				\State \textit{self.batch\_size} $\gets$ \textit{batch\_size}
				\State \textit{self.shuffle} $\gets$ \textit{shuffle}
				\State \textit{self.num\_workers} $\gets$ \textit{num\_workers}
				\State \textit{self.dataset\_len} $\gets$ \textit{tensors}[0].\textit{shape}[0]
				%\textcolor{codegreen}{\Comment{Get dataset total length}}
				\State
				\If{\textit{num\_workers} $> 1$}
					\State \textit{self.async\_results} $\gets$ [ ]					%\textcolor{codegreen}{\Comment{Initialize async results list}}
					\State \textit{self.pool} $\gets$ \textbf{ThreadPool}()
					%\textcolor{codegreen}{\Comment{Initialize Thread pool}}
				\EndIf
				\State
				\State \textit{self.n\_batches} $\gets \lceil$\textit{self.dataset\_len} / \textit{self.batch\_size}$\rceil$
				%\textcolor{codegreen}{\Comment{Compute number of batches}}
			\EndFunction
		\algstore{bkbreak}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
	\caption{Alt2 FastDataLoader class, Iter}\label{Alt2FastDataLoaderIter}
	\begin{algorithmic}[1]
		\algrestore{bkbreak}
			\Function{Iter}{\textit{self}}
				\If{\textit{self.shuffle} $=$ \textit{true}}
					\State \textit{r} $\gets$ \textbf{randperm}(\textit{self.dataset\_len})
					%\textcolor{codegreen}{\Comment{Randomly create indices}}
					\For{\textit{i}, \textit{t} $\in$ \textbf{enumerate}(\textit{self.tensors})}
						\State \textit{self.tensors}[\textit{i}] $\gets$ \textit{t}[\textit{r}]
						%\textcolor{codegreen}{\Comment{Permute (in-place) the data in tensors}}
					\EndFor
				\EndIf
				\State
				\State \textit{self.i} $\gets$ 0
				%\textcolor{codegreen}{\Comment{Set current index to 0}}
				\State \textbf{return} \textit{self}			
			\EndFunction
		\algstore{bkbreak}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
	\caption{Alt2 FastDataLoader class, Next}\label{Alt2FastDataLoaderNext}
	\begin{algorithmic}[1]
		\algrestore{bkbreak}
			\Function{Next}{\textit{self}}
				\If{\textit{self.i} $\ge$ \textit{self.dataset\_len}}
				%\textcolor{codegreen}{\Comment{If we are at the end of the dataset}}
					\If{(\textit{self.num\_workers} $= 1$ \textbf{or} \textbf{len}(\textit{self.async\_results}) $= 0$)}
					%\textcolor{codegreen}{\Comment{If just 1 worker was used or there are no async results to wait for in case of multiple workers}}
						\State \textbf{raise} \textit{StopIteration}
						%\textcolor{codegreen}{\Comment{Stop iteration}}
					\EndIf
				\EndIf
				\State
				\If{\textit{self.num\_workers} $= 1$}
					\State \textit{batch} $\gets$ \textbf{get\_batch}(\textit{self.tensors}, \textit{self.batch\_size}, \textit{self.i})
					%\textcolor{codegreen}{\Comment{Get batch of data}}
					\State \textit{self.i} $\gets$ \textit{self.i} + \textit{self.batch\_size}
					%\textcolor{codegreen}{\Comment{Update current index}}
					\State \textbf{return} \textit{batch}
				\Else
				%\textcolor{codegreen}{\Comment{Until there is data in the dataset and there is space in the \textit{async\_results} list}}
					\While{\textit{self.i} $<$ \textit{self.dataset\_len} \textbf{and} \textbf{len}(\textit{self.async\_results}) $<$ \textit{self.num\_workers}}
						\State \textit{arguments} $\gets$ (\textit{self.tensors}, \textit{self.batch\_size}, \textit{self.i})
						%\textcolor{codegreen}{\Comment{Set \textit{get\_batch} arguments}}
						\State \textit{async\_task} $\gets$ \textit{self.pool}.\textbf{apply\_async}(\textbf{get\_batch}, \textit{arguments})
						%\textcolor{codegreen}{\Comment{Asynchronously call \textbf{get\_batch} function}}
						\State \textit{self.async\_results}.\textbf{append}(\textit{async\_task})
						%\textcolor{codegreen}{\Comment{Append async task to \textit{async\_results}}}
						\State \textit{self.i} $\gets$ \textit{self.i} + \textit{self.batch\_size}
						%\textcolor{codegreen}{\Comment{Update current index}}
					\EndWhile
					\State
					\State \textit{current\_result} $\gets$ \textit{self.async\_results}.\textbf{pop}(0)
					%\textcolor{codegreen}{\Comment{Pop first element of \textit{async\_results}}}
					\State \textbf{return} \textit{current\_result}.\textbf{get}()
					%\textcolor{codegreen}{\Comment{Wait for task completion and return its value}}
				\EndIf
			\EndFunction
		\EndClass
	\end{algorithmic}
\end{algorithm}

\color{Black}
\paragraph{Generator alt3}
\color{Red}

Unfortunately, when considering $6M$ samples, the alternative generator version 1 ('$alt1$') was only slightly faster than the original Pytorch dataloader, while version 2 ('$alt2$') was considerably slower having to shuffle the entire memmap-ed dataset.

Since using a Google Cloud instance did not provide a significant speed-up, and since the model needed $\sim60$ hours to complete 1 training run, I had to think of another dataloader optimization. I thus developed a further alternative dataloader ('$alt3$') that managed to reduce the time needed for 1 training epoch (considering 6M samples) from $\sim6$ hours to $\sim15$ minutes. The time needed to complete a full training run is thus now $\sim2.5$ hours ($\sim3$ hours considering also model evaluation).
The optimization consists of a tradeoff between loading speed and samples dispersion. In fact, the new dataloader uses a pool of threads to asynchronously load the dataset into memory in chunks. In particular each thread loads into memory '$n\_chunks$' randomly chosen chunks. Each thread then proceeds to concatenate together its '$n\_chunks$' chunks, which contain '$chunk\_size$' malware samples each, generating each a '$chunk\_aggregate$', which is then randomly shuffled and returned by the thread. The $chunk\_aggregates$ are asynchronously inserted in a queue (the order depends on the threads instantiation order) of fixed length equal to the number of workers used. The main dataloader thread manages the $chunk\_aggregate$ queue, instantiating the parallel threads such that the queue is always full. Moreover, the main dataloader thread sequentially extracts, when possible, one $chunk\_aggregate$ at a time from the queue and then proceeds to return one batch of data at a time from it, when required.
Selecting different values for $chunk\_size$ and $n\_chunks$ has an impact on the speed of the dataloader and on the samples dispersion. In fact the samples are not anymore randomly chosen from the whole dataset, but from a random sub-part of it. This effectively decreases the amount of dispersion (and randomness) of batches possibly affecting the final model generalization. It is therefore better to consider a higher value for $n\_chunks$ possibly decreasing $chunk\_size$. Furhtermore, the values for $chunk\_size$ and $n\_chunks$) should be chosed carefully since their product results in the number of samples loaded into memory (RAM) at once for a single worker thread. Increasing too much this number (together with the number of workers used) will quickly saturate the available RAM.

\begin{algorithm}
	\caption{Alt3 get\_batch function}\label{Alt3GetBatch}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Function{get\_batch}{\textit{tensors}, \textit{batch\_size}, \textit{i}, ...}
			\State \textit{batch} $\gets$ [ ]
			%\textcolor{codegreen}{\Comment{Get the data in order}}
			\ForAll{\textit{t} $\in$ \textit{tensors}}
				%\textcolor{codegreen}{\Comment{For all tensors in \textit{chunk\_agg}}}
				\State \textit{batch\_data} $\gets$ \textit{t}[\textit{i}:(\textit{i} + \textit{batch\_size})]
				%\textcolor{codegreen}{\Comment{Select data from the current tensor \textit{t}}}
				\State \textit{batch}.\textbf{append}(\textit{batch\_data})
				%\textcolor{codegreen}{\Comment{Append selected \textit{batch\_data} to \textit{batch} array}}
			\EndFor
			\State
			\State \textbf{return} \textit{batch}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Alt3 get\_chunks function}\label{Alt3GetChunks}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Function{get\_chunks}{\textit{tensors}, \textit{chunk\_indices}, \textit{chunk\_size}, \textit{last\_chunk\_size}, \textit{n\_chunks}, \textit{shuffle}}
			\If{\textit{n\_chunks} $- 1$ \textbf{in} \textit{chunk\_indices}}
				\State \textit{chunk\_agg\_size} $\gets$ (\textbf{len}(\textit{chunk\_indices}) $- 1$) $\cdot$ \textit{chunk\_size} + \textit{last\_chunk\_size}
			\Else
				\State \textit{chunk\_agg\_size} $\gets$ \textbf{len}(\textit{chunk\_indices}) $\cdot$ \textit{chunk\_size}
			\EndIf
			\State
			\State \textit{chunk\_agg} $\gets$ [ ]
			\If {len(\textit{tensors}) = 3}
				%\textcolor{codegreen}{\Comment{if \textit{tensors} contains also \textit{S} (shas) data}}
				\State \textit{chunk\_agg}.\textbf{append}(\textbf{emptyNumpyArray})
				\ForAll{\textit{t} $\in$ \textit{tensors}[$-2$:]}
					\State \textit{chunk\_agg}.\textbf{append}(\textbf{emptyTensor})
				\EndFor
			\Else
				\ForAll{\textit{t} $\in$ \textit{tensors}}
					\State \textit{chunk\_agg}.\textbf{append}(\textbf{emptyTensor})
				\EndFor
			\EndIf
			\State
			\State \textit{c\_start} $\gets$ 0
			\ForAll{\textit{idx} $\in$ [0, ..., \textbf{len}(\textit{chunk\_indices})]}
				\State \textit{t\_start} $\gets$ \textit{chunk\_indices}[\textit{idx}] $\cdot$ \textit{chunk\_size}
				\If{\textit{chunk\_indices}[\textit{idx}] $\neq$ \textit{n\_chunks} $- 1$}
					\State \textit{c\_end} $\gets$ \textit{c\_start} + \textit{chunk\_size}
					\State \textit{t\_end} $\gets$ \textit{t\_start} + \textit{chunk\_size}
				\Else
					\State \textit{c\_end} $\gets$ \textit{c\_start} + \textit{last\_chunk\_size}
					\State \textit{t\_end} $\gets$ \textit{t\_start} + \textit{last\_chunk\_size}
				\EndIf
				
				\For{\textit{i}, \textit{t} $\in$ \textbf{enumerate}(\textit{tensors})}
					\State \textit{chunk\_agg}[\textit{i}][\textit{c\_start}:\textit{c\_end}] $\gets$ \textit{t}[\textit{t\_start}:\textit{t\_end}]
				\EndFor
				\State \textit{c\_start} $=$ \textit{c\_end}
			\EndFor
			\State
			\If{\textit{shuffle} $=$ \textit{true}}
				\State \textit{r} $=$ \textbf{randperm}(\textit{chunk\_agg\_size})
				\For{\textit{i}, \textit{t} $\in$ \textbf{enumerate}(\textit{chunk\_agg})}
					\State \textit{chunk\_agg}[\textit{i}] $=$ \textit{t}[\textit{r}]
				\EndFor
			\EndIf
			\State
			\State \textbf{return} \textit{chunk\_agg}, \textit{chunk\_agg\_size}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Alt3 FastDataLoader class, Init}\label{Alt3FastDataLoaderInit}
	\begin{algorithmic}[1] % uncomment [1] for line numbers
		\Class{FastTensorDataloader}
			\Function{Init}{\textit{self}, \textit{tensors}, \textit{batch\_size}, \textit{chunk\_size}, \textit{chunks}, \textit{shuffle}, \textit{num\_workers}, ...}
				\State \textit{self.tensors} $\gets$ \textit{tensors}
				\State \textit{self.batch\_size} $\gets$ \textit{batch\_size}
				\State \textit{self.chunk\_size} $\gets$ \textit{chunk\_size}
				\State \textit{self.chunks} $\gets$ \textit{chunks}
				\State \textit{self.shuffle} $\gets$ \textit{shuffle}
				\State \textit{self.num\_workers} $\gets$ \textit{num\_workers}
				\State \textit{self.dataset\_len} $\gets$ \textit{tensors}[0].\textit{shape}[0]
				%\textcolor{codegreen}{\Comment{Get dataset total length}}
				\State
				\If{\textit{num\_workers} $> 1$}
					\State \textit{self.async\_results} $\gets$ [ ]
					%\textcolor{codegreen}{\Comment{Initialize async results list}}
					\State \textit{self.pool} $\gets$ \textbf{ThreadPool}()
					%\textcolor{codegreen}{\Comment{Initialize Thread pool}}
				\EndIf
				\State
				\State \textit{self.n\_batches} $\gets \lceil$\textit{self.dataset\_len} / \textit{self.batch\_size}$\rceil$
				%\textcolor{codegreen}{\Comment{Compute number of batches}}
				\State \textit{self.n\_chunks} $\gets \lceil$\textit{self.dataset\_len} / \textit{self.chunk\_size}$\rceil$
				%\textcolor{codegreen}{\Comment{Compute number of chunks}}
				\State \textit{self.last\_chunk\_size} $\gets$ \textit{self.dataset\_len} $\%$ \textit{self.chunk\_size}
				%\textcolor{codegreen}{\Comment{Compute last chunk size}}
			\EndFunction
		\algstore{bkbreak}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
	\caption{Alt3 FastDataLoader class, Iter}\label{Alt3FastDataLoaderIter}
	\begin{algorithmic}[1]
		\algrestore{bkbreak}
			\Function{Iter}{\textit{self}}
				\If{\textit{self.shuffle} $=$ \textit{true}}
					\State \textit{self.chunk\_indices} $\gets$ \textbf{randperm}(\textit{self.dataset\_len})
					%\textcolor{codegreen}{\Comment{Randomly create indices}}
				\Else
					\State \textit{self.chunk\_indices} $\gets$ \textbf{arange}(\textit{self.n\_chunks})
					%\textcolor{codegreen}{\Comment{Create chunk indices linearly}}
				\EndIf
				\State
				\State \textit{self.chunk\_agg} $\gets$ None
				%\textcolor{codegreen}{\Comment{Initialize current \textit{chunk\_agg} to Null value}}
				\State \textit{self.chunk\_agg\_size} $\gets$ 0
				%\textcolor{codegreen}{\Comment{Set current \textit{chunk\_agg} size to 0}}
				\State \textit{self.chunk\_i} $\gets$ 0
				%\textcolor{codegreen}{\Comment{Set current index to 0}}
				\State \textbf{return} \textit{self}			
			\EndFunction
		\algstore{bkbreak}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
	\caption{Alt3 FastDataLoader class, Next}\label{Alt3FastDataLoaderNext}
	\begin{algorithmic}[1]
		\algrestore{bkbreak}
			\Function{Next}{\textit{self}}
				\If{\textit{self.num\_workers} $= 1$}
					\If{\textit{self.chunk\_agg} \textbf{is} None \textbf{or} \textit{self.i} $\ge$ \textit{self.chunk\_agg\_size}}
						\If{\textit{self.chunk\_i} $\ge$ \textit{self.n\_chunks}}
							\State \textbf{raise} \textit{StopIteration}
						\EndIf
						\State
						\State \textit{start\_i} $\gets$ \textit{self.chunk\_i}
						\State \textit{end\_i} $\gets$ \textit{start\_i} + \textit{self.chunks}
						\State \textit{self.chunk\_agg}, \textit{self.chunk\_agg\_size} $\gets$ \textbf{get\_chunks}(\textit{self.tensor}, \textit{self.chunk\_indices}[\textit{start\_i}:\textit{end\_i}], \textit{self.chunk\_size}, \textit{self.last\_chunk\_size}, \textit{self.n\_chunks}, \textit{self.shuffle})
						\State \textit{self.chunk\_i} $\gets$ \textit{end\_i}
						\State \textit{self.i} $\gets$ 0
					\EndIf
				\Else
					\While{\textit{self.chunk\_i} $<$ \textit{self.n\_chunks} \textbf{and} \textbf{len}(\textit{self.async\_results}) $<$ \textit{self.num\_workers}}
						\State \textit{start\_i} $\gets$ \textit{self.chunk\_i}
						\State \textit{end\_i} $\gets$ \textit{start\_i} + \textit{self.chunks}
						\State \textit{arguments} $\gets$ (\textit{self.tensors}, \textit{self.chunk\_indices}[\textit{start\_i}:\textit{end\_i}], \textit{self.chunk\_size}, \textit{self.last\_chunk\_size}, \textit{self.n\_chunks}, \textit{self.shuffle})
						\State \textit{async\_task} $\gets$ \textit{self.pool}.\textbf{apply\_async}(\textit{get\_chunks}, \textit{arguments})
						\State \textit{self.async\_results}.\textbf{append}(\textit{async\_task})
						\State \textit{self.chunk\_i} = \textit{end\_i}
					\EndWhile
					\State
					\If{\textit{self.chunk\_agg} \textbf{is} None \textbf{or} \textit{self.i} $>=$ \textit{self.chunk\_agg\_size}}
						\If{\textbf{len}(\textit{self.async\_results}) $= 0$}
							\State \textbf{raise} \textit{StopIteration}
						\EndIf
						\State
						\State \textit{current\_result} = \textit{self.async\_results}.\textbf{pop}(0)
						\State \textit{self.chunk\_agg}, \textit{self.chunk\_agg\_size} $\gets$ \textit{current\_result}.\textbf{get}()
						\State \textit{self.i} $\gets$ 0
					\EndIf
				\EndIf
				\State
				\State \textit{batch} $\gets$ \textbf{get\_batch}(\textit{self.chunk\_agg}, \textit{self.batch\_size}, \textit{self.i})
				\State \textit{self.i} $\gets$ \textit{self.i} + \textit{batch}[0].\textbf{shape}[0]
				\State \textbf{return} \textit{batch}
			\EndFunction
		\EndClass
	\end{algorithmic}
\end{algorithm}

\color{Black}
\subparagraph{Generator parameters optimization}
\color{Red}

To understand the behaviour of the new dataloader and choose the best combination of values possible using 8 threads (which is double the amount of cores I have at my disposal in the Colab instance and I found is a good number of threads to use) I cross evaluated it using powers of 2 for both values. In particular I developed a function to be used to evaluate the new alternative generator on the target machine. This function performs 'epochs' model training epochs using values for $chunk\_size$ and $n\_chunks$ got from two intervals and plots 2 heatmaps: the first containing the average elapsed times and the second the average speeds.
In my evaluation run I hard-coded for $chunk\_size$ the powers of 2 ranging from $2^4$ to $2^14$ (included) and for $n\_chunks$ the powers of 2 ranging from $2^3$ to $2^13$.
Moreover, two further parameters have to be set in order to constrain the evaluation to meaningful values: $min\_mul$ and $max\_mul$. In fact, as previously mentioned, the product of $chunk\_size \times n\_chunks$ gives the total number of samples in one $chunk\_aggregate$ (which resides in main memory). $min\_mul$ and $max\_mul$ indicate the minimum and maximum number of batches retrievable from the resulting $chunk\_aggregate$.
In my run I considered for $min\_mul$ the value 1 and for $max\_mul$ the value 32. This was done in order to be able to retrieve at least one batch from the $chunk\_aggregate$ without saturating the available RAM (having for $max\_mul$ a value greater than $32 * batch\_size$ would be too mutch for my instance).
Given the results I got (available at the end of this document), I decided to stick with the following values for all the model training runs since they seemed to be a good compromise between loading speed and samples dispersion: $chunk\_size = 256$ and $n\_chunks = 256$.

\color{Black}
\section{Fresh Dataset}
\color{Red}

To properly evaluate the model there is the need of a dataset with malware family labels. Malware Bazaar provides examples of malware executables for different malware families and it could therefore be a good source for creating a new (fresh) dataset. I therefore created a function which, given:
\begin{itemize}
	\item a series of malware families in order of importance
	
	\item the number '$x$' (default: 100) of samples per family to download
	
	\item the number '$m$' (default: 10) of families to consider
\end{itemize}
downloads from Malware Bazaar '$x$' samples per malware family (if possible, otherwise it skips the malware family and considers the next), extracts the features from each sample and creates the new dataset (which I call '$fresh\_dataset$' in the code) with '$n = x * m$' (default: 1000) samples compatible with the model.

\color{Black}
\subsection{Model Evaluation with Fresh Dataset}
\color{Red}

I implemented a model evaluation function using the $fresh\_dataset$. This function randomly samples '$q$' (default: 100) query samples among the ones in the $fresh\_dataset$, it computes the similarity between each of these samples with the other '$n-1$' (default: 999), and orders these '$n-1$' samples by similarity. It then calcluates the \textit{MRR} (Mean Reciprocal Rank) and \textit{MAP} (Mean Average Precision) scores for the model. The rankings for the '$q$' (100) query samples are saved as a single json file. Moreover, 5 particular rankings are saved as csv files. These 5 rankings are those that produced:
\begin{itemize}
	\item the maximum \textit{RR} (Reciprocal Rank)
	
	\item the minimum \textit{RR} (Reciprocal Rank)
	
	\item the maximum \textit{AP} (Average Precision)
	
	\item the minimum \textit{AP} (Average Precision)
	
	\item the last ranking is randomly sampled between all the other rankings
\end{itemize}

The model fresh dataset evaluation computes both the \textit{MRR} and \textit{MAP} scores. The Mean Reciprocal Rank (\textit{MRR}) is the average of the Reciprocal Ranks (\textit{RR}) of a series of queries. The Reciprocal Rank (\textit{RR}) of a query response is the multiplicative inverse of the rank (position in the ranking) of the single sample, belonging to the family of interest, which calssified as closest (highest rank). The \textit{MAP} score instead takes into account, with proper weights, all the sampels in the family of interest. Therefore a model will have a higher \textit{MRR} score if it classifies a single sample belonging to the family of interest higher in the ranking; and it will have a higher \textit{MAP} score if it classifies all the samples belonging to the family of interest higher in the ranking.

\color{Black}
\chapter{Experimenting with ML based Malware Detection/Description methods}
\color{Red}

\color{Black}
\chapter{Proposed Tool}
\color{Red}

Description of the proposed tool..

\color{Black}
\chapter{Experiments with the proposed tool}
\color{Red}

\color{Black}
\chapter{Results}
\color{Red}

Results analysis..

\color{Black}
\chapter{Conclusions}
\color{Red}

Qui si inseriscono brevi conclusioni sul lavoro svolto, senza ripetere inutilmente il sommario.

Si possono evidenziare i punti di forza e quelli di debolezza, nonché i possibili sviluppi futuri o attività da svolgere per migliorare i risultati.

\color{Black}
\chapter{Appendix}
\section{Notable Examples of Malware in Recent History}\label{NotableMalwareExamples}

Here is an overview of the most famous malware or malware-related events in recent history:
\begin{itemize}
	\item \textbf{\textit{Melissa}} (1999) - Considered to be one of the first cases of social engineering in history, the Melissa mass-mailing macro virus infected thousands of computers worldwide by the end of 1999. The virus was spread via e-mail, using a malicious Word attachment named "list.doc" and as subject: "Important message from", followed by the victim's username. Once opened, the attachment would execute a macro that mass-mailed the virus to the first 50 people in the user's contact list and disabled multiple security features on Microsoft Word and Microsoft Outlook.
	
	\item \textbf{\textit{ILOVEYOU}} (2000) - \textit{ILOVEYOU}, sometimes referred to as \textit{Love Bug} or \textit{Love Letter for you}, was a computer worm that infected over ten million Windows personal computers in 2000. It spread as an email message with the subject line "ILOVEYOU" and the attachment "LOVE-LETTER-FOR-YOU.txt.vbs". Opening the attachment would activate the Visual Basic script which caused damages on the local machine, overwriting random files. Finally, the worm sent a copy of itself to all addresses in the Windows Address Book used by Microsoft Outlook.
	
	\item \textbf{\textit{SQL Slammer}} (2003) - This malware exploited a buffer overflow bug in Microsoft's SQL Server and Desktop Engine database products, causing a denial of service on some Internet hosts and dramatically slowing general Internet traffic. It spread rapidly, infecting most of its 75,000 victims within ten minutes.
	
	\item \textbf{\textit{MyDoom}} (2004) - Also known as \textit{W32.MyDoom@mm}, \textit{Novarg}, \textit{Mimail.R} and \textit{Shimgapi}, it was a computer worm which affected Microsoft Windows systems. It became known mostly because it tried hitting major technology companies, such as Google and Microsoft. It spread by email using attention-grabbing subjects, such as ?Error?, ?Test? and ?Mail Delivery System?. It became the fastest-spreading e-mail worm ever, exceeding previous records set by the Sobig worm and ILOVEYOU, a record which as of 2021 has yet to be surpassed.
	
	\item \textbf{\textit{Conficker}} (2008) - Also known as \textit{Downup}, \textit{Downadup} and \textit{Kido}, this computer worm targeted the Microsoft Windows operating system. It used flaws in Windows OS software and dictionary attacks on administrator passwords to propagate while forming a botnet. The Conficker worm infected over 15 million Windows systems including government, business and home computers in more than 190 countries. This made it the largest known computer worm infection since the 2003 \textit{Welchia}.
	
	\item \textbf{\textit{Zeus}} (2007-2009) - Also known as \textit{ZeuS}, or \textit{Zbot}, \textit{Zeus} was a Trojan horse malware that ran on Microsoft Windows. It was able to carry out many malicious and criminal tasks. However, it was most often used to steal banking information through the use of man-in-the-browser keystroke logging and form grabbing. It was also often used to install the \textit{CryptoLocker} ransomware. Zeus spread mainly through drive-by downloads and phishing mails. First identified in mid 2007, it became more widespread in 2009.
	
	\item \textbf{\textit{Stuxnet Worm}} (2010) - \textit{Stuxnet} was an extremely sophisticated worm that infected computers worldwide. It was allegedly developed by US and Israeli intelligence to hinder the Iranian nuclear program. It was introduced into the target environment (Iran's nuclear power plant) via a flash drive. Stuxnet's escape from the target environment, which was air-gapped, was not expected. Once in the wild, Stuxnet spread aggressively but mostly harmed the target Iranian nuclear facility, where it damaged uranium-enrichment centrifuges, causing little damage outside of its intended target environment \cite{BakerMCTM}.
	
	\item \textbf{\textit{CryptoLocker}} (2013) - It is considered to be one of the first widespread ransomware attacks. It targeted computers running Microsoft Windows and it propagated via infected email attachments. When activated, it encrypted certain types of files stored on local and mounted network drives using RSA public-key cryptography. The private key was stored only on the malware's control servers. A message was then displayed offering to decrypt the data if a payment (through either bitcoin or other means) was made before a certain deadline. After such deadline the private key was deleted. However, paying the ransom did not always lead to the files being decrypted.
	
	Its code now keeps getting repurposed in similar malware projects.
	
	\item \textbf{\textit{Mirai}} (2016) - \textit{Mirai} is an infamous malware which compromised vulnerable IoT (Internet of Things) devices - such as IP cameras and home routers - turning them into remotely controlled bots.
	
	The Mirai botnet, one of the biggest (and worse) botnets in existence, was first found in August 2016 and has been used in some of the largest and most disruptive distributed denial of service (DDoS) attacks, including an attack on computer security journalist Brian Krebs' web site. The source code for Mirai has been published on Hack Forums as open-source, as a result its techniques have been adapted in many other malware projects.
	
	\item \textit{\textbf{Petya} and \textbf{NotPetya}} (2016-2017) - These malware attacks spread globally, however their damages particularly targeted Ukraine, where the national bank was hit. The Petya ransomware family caused an estimated \$10 billion in damages worldwide \cite{ReganWIM}. \textit{Petya} targeted Microsoft Windows-based systems, infecting the Master Boot Record (MBR) to execute a payload that encrypted the hard drive's file system table preventing Windows from booting. It subsequently demanded a ransom in Bitcoin to the user in order to regain access to the system.
	
	Many variants of Petya were created in the subsequent months. In mid 2017, a new variant of Petya was used for a global cyber-attack, again primarily targeting Ukraine. The new variant spread using the EternalBlue exploit, the same one used by the WannaCry ransomware. This new version was called \textit{NotPetya} to distinguish it from the 2016 variants.
	
	\item \textbf{\textit{WannaCry}} (2017) - WannaCry is considered to be one of largest ransomware attacks in history. It targeted computers running Microsoft Windows by encrypting data and demanding ransom payments in Bitcoin. It mainly propagated through EternalBlue, an exploit developed by the U.S. National Security Agency (NSA) for older Windows systems. This exploit was stolen from NSA and leaked approximately one year before the attack. While Microsoft had released security patches against this exploit, some organizations had not applied them, or were using older Windows systems when the attack occurred.
	
	The attack was stopped within a few days of its discovery thanks to emergency patches released by Microsoft and the discovery of a kill switch. Before being stopped, WannaCry was spread infecting systems at a terrifying rate of 10,000 PCs per hour \cite{ReganWIM}. In the end, the attack was estimated to have affected more than 200,000 computers across 150 countries, with total damages ranging from hundreds of millions to billions of dollars.
	
	\item \textbf{\textit{Emotet}} (2018) - This malware, also known as \textit{Heodo}, was first detected in 2014 as a banking trojan aimed at stealing banking credentials from infected hosts. Throughout 2016 and 2017, its creators updated and reconfigured it to work primarily as a "loader" - a type of malware that gains access to a system, and then allows its operators to download and execute additional payloads. These payloads can be any type of executable code, from Emotet's own modules to malware developed by other cybercriminals.
	
	This malware usually makes its way on target systems via a macro virus attached to an email. The infected email appears to be a legitimate reply to an earlier message sent by the victim. When on the system, it is particularly difficult to combat because it evades signature-based detection, is persistent, and includes advanced spreader modules used to propagate effectively. 
	Emotet authors have often used the malware to create a botnet of infected computers to which they sell access in Malware-as-a-Service to other cybercriminals, such as the Ryuk gang.
	
	In 2020, Emotet spread again globally, infecting its victims with TrickBot and Qbot, which are used to steal banking credentials and spread inside networks. In January 2021, Europol and Eurojust coordinated international actions allowed investigators to take control of and disrupt the Emotet infrastructure.
	
	\item \textbf{\textit{COVID-19 related attacks}} (2020) - In 2020, many cybercriminals shamelessly took advantage of the people's fear of coronavirus during the COVID-19 pandemic through COVID-19 related phishing scams. Using fake communications, for example spoofing the World Health Organization, attackers deployed malware and got access to targets' sensitive information among other nefarious actions \cite{ReganWIM}.
	
	Another COVID-19 attack was that of a malicious Android app called \textit{CovidLock}, which claimed to be a real-time coronavirus outbreak tracker but instead was a ransomware that attempted to trick the user into providing administrative access on their device and then locked it requesting a ransom.
\end{itemize}

% bibliografia scritta "a mano"
%\input{biblio.tex}

% se la bibliografia è stata scritta (usando Bibtex) nel file biblio.bib allora commentare la riga precedente e scommentare le due righe seguenti
\bibliographystyle{torsec}
\bibliography{biblio}

\end{document}
